<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>HW2P2 | XuRui-Blog</title><meta name="keywords" content="Deep Learning"><meta name="author" content="zxr"><meta name="copyright" content="zxr"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Introduction Problem Restatement è¿™æ¬¡ä½œä¸šçš„ä»»åŠ¡æ˜¯å›¾åƒåˆ†ç±»(classification)å’Œå›¾åƒè®¤è¯(verification)ï¼Œå€¼å¾—æ³¨æ„çš„æ˜¯è¿™ä¸ªåˆ†ç±»ä»»åŠ¡æ˜¯closed set problemï¼Œå›¾åƒä¸€å…±æœ‰7000ç§ç±»åˆ«ï¼Œæ¯ä¸ªå›¾åƒçš„ä¸»ä½“éƒ½ä¼šå‡ºç°åœ¨è®­ç»ƒé›†ä¸­ï¼Œåœ¨æµ‹è¯•é›†ä¸­è¯¥ä¸»ä½“çš„å›¾åƒä¼šå’Œæµ‹è¯•é›†ä¸­çš„æœ‰æ‰€ä¸åŒã€‚è®¤è¯çš„ä»»åŠ¡æ˜¯open set problemï¼Œä¸‹é¢çš„å›¾è§£é‡Šäº†è¿™ä¸¤ç§é—®">
<meta property="og:type" content="article">
<meta property="og:title" content="HW2P2">
<meta property="og:url" content="https://xurui314.github.io/2023/03/03/HW2P2/index.html">
<meta property="og:site_name" content="XuRui-Blog">
<meta property="og:description" content="Introduction Problem Restatement è¿™æ¬¡ä½œä¸šçš„ä»»åŠ¡æ˜¯å›¾åƒåˆ†ç±»(classification)å’Œå›¾åƒè®¤è¯(verification)ï¼Œå€¼å¾—æ³¨æ„çš„æ˜¯è¿™ä¸ªåˆ†ç±»ä»»åŠ¡æ˜¯closed set problemï¼Œå›¾åƒä¸€å…±æœ‰7000ç§ç±»åˆ«ï¼Œæ¯ä¸ªå›¾åƒçš„ä¸»ä½“éƒ½ä¼šå‡ºç°åœ¨è®­ç»ƒé›†ä¸­ï¼Œåœ¨æµ‹è¯•é›†ä¸­è¯¥ä¸»ä½“çš„å›¾åƒä¼šå’Œæµ‹è¯•é›†ä¸­çš„æœ‰æ‰€ä¸åŒã€‚è®¤è¯çš„ä»»åŠ¡æ˜¯open set problemï¼Œä¸‹é¢çš„å›¾è§£é‡Šäº†è¿™ä¸¤ç§é—®">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://s2.loli.net/2023/03/03/Qav93NjokKmWh7A.jpg">
<meta property="article:published_time" content="2023-03-03T03:08:13.000Z">
<meta property="article:modified_time" content="2023-04-13T14:57:41.012Z">
<meta property="article:author" content="zxr">
<meta property="article:tag" content="Deep Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2023/03/03/Qav93NjokKmWh7A.jpg"><link rel="shortcut icon" href="https://i.loli.net/2021/07/27/lSHRJbx7dYwTk8f.jpg"><link rel="canonical" href="https://xurui314.github.io/2023/03/03/HW2P2/"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'HW2P2',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-04-13 22:57:41'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    document.addEventListener('pjax:complete', detectApple)})(window)</script><link rel="stylesheet" href="/css/badge.css"><link rel="stylesheet" href="/css/modify.css"><link rel="stylesheet" href="/css/mouse.css"><link rel="stylesheet" href="/dist/APlayer.min.css"><link rel="stylesheet" href="/css/custom.css"><link rel="stylesheet" href="/css/bilibiliBanner.css" media="defer" onload="this.media='screen'"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper/swiper/swiper.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper/swiper/swiperstyle.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css">
<style>#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags:before {content:"\A";
  white-space: pre;}#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags > .article-meta__separator{display:none}</style>
<link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script async="" src="https://unpkg.zhimg.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://s2.loli.net/2021/12/08/yTYthVwXD4IPbJ9.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">79</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">35</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">16</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> ä¸»é¡µğŸ­</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> æ¡£æ¡ˆğŸŒŠ</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> æ ‡ç­¾ğŸ“‘</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> åˆ†ç±»ğŸŒˆ</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> å¥½åº·çš„âœ¨</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener" href="https://ocw.mit.edu/"><i class="fa-fw fas fa-link"></i><span> æ¥å­¦éº»å­¦</span></a></li><li><a class="site-page child" href="/bangumis/"><i class="fa-fw fas fa-video"></i><span> zxrã®è¿½ç•ªè®¡åˆ’</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=RyOyXsKuUgI"><i class="fa-fw fas fa-heart"></i><span> zxræœ€çˆ±æ»´upå˜‰å€©</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://oskarstalberg.com/game/planet/planet.html"><span> Planet</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> å‹é“¾ğŸ’•</span></a></div><div class="menus_item"><a class="site-page" href="https://xurui314.github.io/aboutme/"><span> AboutMeğŸ‚</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.foreverblog.cn/go.html"><span> è™«æ´</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://s2.loli.net/2023/03/03/Qav93NjokKmWh7A.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">XuRui-Blog</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> ä¸»é¡µğŸ­</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> æ¡£æ¡ˆğŸŒŠ</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> æ ‡ç­¾ğŸ“‘</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> åˆ†ç±»ğŸŒˆ</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> å¥½åº·çš„âœ¨</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener" href="https://ocw.mit.edu/"><i class="fa-fw fas fa-link"></i><span> æ¥å­¦éº»å­¦</span></a></li><li><a class="site-page child" href="/bangumis/"><i class="fa-fw fas fa-video"></i><span> zxrã®è¿½ç•ªè®¡åˆ’</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=RyOyXsKuUgI"><i class="fa-fw fas fa-heart"></i><span> zxræœ€çˆ±æ»´upå˜‰å€©</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://oskarstalberg.com/game/planet/planet.html"><span> Planet</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> å‹é“¾ğŸ’•</span></a></div><div class="menus_item"><a class="site-page" href="https://xurui314.github.io/aboutme/"><span> AboutMeğŸ‚</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.foreverblog.cn/go.html"><span> è™«æ´</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">HW2P2</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-03-03T03:08:13.000Z" title="Created 2023-03-03 11:08:13">2023-03-03</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-04-13T14:57:41.012Z" title="Updated 2023-04-13 22:57:41">2023-04-13</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/cmu/">cmu</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">5.1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>28min</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="HW2P2"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><div class="top-img" style="background-image: url('https://s2.loli.net/2023/03/03/Qav93NjokKmWh7A.jpg');"></div><article class="post-content" id="article-container"><h2 id="Introduction">Introduction</h2>
<h3 id="Problem-Restatement">Problem Restatement</h3>
<p>è¿™æ¬¡ä½œä¸šçš„ä»»åŠ¡æ˜¯å›¾åƒåˆ†ç±»(<code>classification</code>)å’Œå›¾åƒè®¤è¯(<code>verification</code>)ï¼Œå€¼å¾—æ³¨æ„çš„æ˜¯è¿™ä¸ªåˆ†ç±»ä»»åŠ¡æ˜¯<code>closed set problem</code>ï¼Œå›¾åƒä¸€å…±æœ‰7000ç§ç±»åˆ«ï¼Œæ¯ä¸ªå›¾åƒçš„ä¸»ä½“éƒ½ä¼šå‡ºç°åœ¨è®­ç»ƒé›†ä¸­ï¼Œåœ¨æµ‹è¯•é›†ä¸­è¯¥ä¸»ä½“çš„å›¾åƒä¼šå’Œæµ‹è¯•é›†ä¸­çš„æœ‰æ‰€ä¸åŒã€‚è®¤è¯çš„ä»»åŠ¡æ˜¯<code>open set problem</code>ï¼Œä¸‹é¢çš„å›¾è§£é‡Šäº†è¿™ä¸¤ç§é—®é¢˜çš„å·®åˆ«ã€‚å¯¹äº<code>verification</code>æˆ‘ä»¬å…³æ³¨çš„ç‚¹å¹¶ä¸æ˜¯æ‰€å±å“ªä¸ªç±»åˆ«ï¼Œè€Œæ˜¯è¿™ä¸ªdatapointèƒ½ä¸å…¶ä»–datapointæ¯”è¾ƒçš„metricå€¼ã€‚é™¤äº†è¿™ç‚¹å¤–ï¼Œ<code>verification</code>å’Œ<code>classification</code>çš„åŒºåˆ«è¿˜åœ¨äº<code>verification</code>æ˜¯å…è®¸ä¸€å¯¹å¤šmatchçš„ï¼Œä¹Ÿå°±æ˜¯ä¸€ä¸ªsampleå’Œå¤šä¸ªidentityåŒ¹é…ï¼Œè€Œ<code>classification</code>åªæ˜¯ä¸€å¯¹ä¸€ã€‚</p>
<blockquote>
<p>å…³äºè¿™ä¸¤ç§ä»»åŠ¡çš„å·®åˆ«ï¼ŒæŒ‡å¯¼ä¹¦è§£é‡Šäº†ä¸€å †ï¼Œæœ‰ç‚¹å†—ä½™ğŸ¤”</p>
</blockquote>
<img src="\image\HW2P2_image62.png" alt="image-20230307150049351" style="zoom:80%;">
<h3 id="Solving-Problems">Solving Problems</h3>
<p>åˆ†ç±»é—®é¢˜åˆ©ç”¨ä¼ ç»Ÿçš„æ–¹æ³•è§£å†³å°±è¡Œï¼š</p>
<p><strong>A face classifier that can extract feature vectors from face images.</strong> The face classifier consists of two main parts: the feature extractor and the classification layer.</p>
<p>Your model needs to be able to learn facial features (e.g., skin tone, hair color, nose size, etc.) from an image of a personâ€™s face and represent them as a fixed-length feature vector called <em>face embedding</em>. In order to do this, you will explore architectures consisting of multiple convolutional layers. Stacking several convolutional layers allows for hierarchical decomposition of the input image. For example, if the first layer extracts low-level features such as lines, then the second layer (that acts on the output of the first layer) may extract combinations of low-level features, such as features that comprise multiple lines to express shapes.</p>
<p>ä¸‹é¢è¯¦ç»†è®¨è®ºä¸€ä¸‹<code>verification</code>ã€‚</p>
<p>å¯èƒ½æœ€å®¹æ˜“æƒ³åˆ°çš„è§£å†³æ–¹æ³•å°±æ˜¯<code>multi-class classification</code>ï¼Œä¹Ÿå°±æ˜¯ç›´æ¥ç”¨softmaxå¾—åˆ°å„ä¸ªç±»åˆ«çš„matchç¨‹åº¦ï¼Œä½†æ˜¯è¿™æ ·å¤„ç†å¹¶æ²¡æœ‰è€ƒè™‘åˆ°<code>verification</code>ä»»åŠ¡æœ¬èº«çš„ç‰¹ç‚¹ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œåˆ©ç”¨cross-entropyåªæ˜¯å­¦ä¹ åˆ†ç•Œçº¿å’Œåˆ¤åˆ«çš„æ ‡å‡†ï¼Œå¯¹äºinstancesä¹‹é—´çš„metricå¹¶æ²¡æœ‰è¦æ±‚ï¼Œä¹Ÿå°±æ˜¯åƒå·¦å›¾æ‰€ç¤ºï¼Œè€Œæˆ‘ä»¬å¸Œæœ›çš„æ•ˆæœæ˜¯å³å›¾ï¼Œä¹Ÿå°±æ˜¯instance embeddingæ˜¯æœ‰ç»“æ„çš„ï¼Œå³ä½¿æ˜¯åŒä¸€ç±»åˆ«æœ€è¿œä¸¤ä¸ªinstanceçš„metric(PQ)ä¹Ÿä¼šæ¯”ä¸¤ä¸ªç±»åˆ«æœ€è¿‘çš„ä¸¤ä¸ªinstanceçš„metric(QR)å°ã€‚</p>
<img src="\image\HW2P2_image63.png" alt="image-20230307171743874" style="zoom:80%;">
<p>ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œå¢å¼ºç‰¹å¾å‘é‡çš„é‰´åˆ«èƒ½åŠ›ï¼Œéœ€è¦åŒæ—¶æœ€å¤§åŒ–å…¶ç±»å†…ç´§å‡‘æ€§å’Œç±»é—´è·¨åº¦ï¼Œæˆ‘ä»¬å¯ä»¥ç»“åˆä¸åŒçš„æŸå¤±å‡½æ•°è®¾è®¡æœ€ç»ˆçš„loss functionã€‚(Use Center loss, Sphere loss, Large-margin softmax loss, Large-margin Gaussian mixture loss etc)ã€‚Each of these losses is jointly used with cross-entropy loss to get high-quality feature vectors.</p>
<p>åœ¨å®é™…çš„é—®é¢˜ä¸­ï¼Œä»…ä»…è€ƒè™‘ä»¥ä¸Šçš„ç‚¹å¯èƒ½è¿˜ç®—ä¸å¤Ÿçš„ï¼Œå› ä¸ºæµ‹è¯•é›†å¾€å¾€æœ‰å¾ˆå¤šunseençš„classï¼Œä»…ä»…é è®­ç»ƒé›†å¾—åˆ°çš„ç‰¹å¾å‘é‡æ˜¯å¾ˆå±€é™çš„ï¼Œæ¯•ç«Ÿåªæ˜¯åœ¨è®­ç»ƒé›†çš„classå†…å¯ä»¥è¿›è¡Œæ˜æ˜¾çš„åŒºåˆ†ã€‚è¿™æ—¶å¯ä»¥ç›´æ¥æ„å»ºä»¥feature embeddingä¸ºç›®æ ‡çš„æ¨¡å‹ï¼Œè€Œä¸è€ƒè™‘classï¼Œè¿™æ ·å¾—åˆ°çš„æ•ˆæœå¾€å¾€ä¼šå¥½å¾ˆå¤šã€‚</p>
<p><strong>A verification system that computes the similarity between feature vectors of two images.</strong> The face verification consists of two steps:</p>
<ol>
<li>
<p>Extracting the feature vectors from the images.</p>
</li>
<li>
<p>Comparing the feature vectors using a similarity metric.</p>
</li>
</ol>
<p>A vanilla verification system looks like this:</p>
<ol>
<li>
<p>image1 =<em>â‡’</em> feature extractor =<em>â‡’</em> feature vector1</p>
</li>
<li>
<p>image2 =<em>â‡’</em> feature extractor =<em>â‡’</em> feature vector2</p>
</li>
<li>
<p>feature vector1, feature vector2 =<em>â‡’</em> similarity metric =<em>â‡’</em> similarity score</p>
</li>
</ol>
<p>ä»£ç ä¸Šï¼Œ<code>verification</code>æ˜¯è¿™æ ·åšçš„ï¼š</p>
<p>The verification task consists of the following generalized scenario:</p>
<ul>
<li>You are given X unknown identities</li>
<li>You are given Y known identities</li>
<li>Your goal is to match X unknown identities to Y known identities.</li>
</ul>
<p>We have given you a verification dataset, that consists of 1000 known identities, and 1000 unknown identities. The 1000 unknown identities are split into dev (200) and test (800). Your goal is to compare the unknown identities to the 1000 known identities and assign an identity to each image from the set of unknown identities.</p>
<p>Your will use/finetune your model trained for classification to compare images between known and unknown identities using a similarity metric and assign labels to the unknown identities.</p>
<p>This will judge your modelâ€™s performance in terms of the quality of embeddings/features it generates on images/faces it has never seen during training for classification.</p>
<h2 id="Data-Part">Data Part</h2>
<p>æœ¬æ¬¡ä½œä¸šé‡‡ç”¨çš„æ˜¯<code>VGGFace2 datasetd</code>çš„ä¸€éƒ¨åˆ†ï¼Œå±•ç¤ºçš„æƒ…å†µå¦‚ä¸‹ï¼š</p>
<img src="\image\HW2P2_image64.png" alt="image-20230307213533595" style="zoom:80%;">
<p>å¯¹äºè®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼ŒåŠ è½½æ•°æ®ç›´æ¥åˆ©ç”¨<code>torchvision.datasets.ImageFolder</code>å³å¯ï¼Œä»¥<code>train</code>ä¸ºä¾‹ï¼Œè¿™ä¸ªæ–¹æ³•å…¶å®å°±æ˜¯æŠŠ<code>train</code>ç›®å½•ä¸‹çš„æ‰€æœ‰å­ç›®å½•ä½œä¸ºä¸åŒ<code>label</code>çš„æ•°æ®é›†ï¼Œç¬¬ä¸€ä¸ªå­ç›®å½•<code>n000002</code>å¯¹åº”çš„å›¾åƒå°±å¯¹åº”<code>label 0</code>ï¼Œä»¥æ­¤ç±»æ¨ã€‚</p>
<p><code>ToTensor()</code>å°†<code>shape</code>ä¸º<code>(H, W, C)</code>çš„<code>nump.ndarray</code>æˆ–<code>img</code>è½¬ä¸º<code>shape</code>ä¸º<code>(C, H, W)</code>çš„<code>tensor</code>ï¼Œå…¶å°†æ¯ä¸€ä¸ªæ•°å€¼å½’ä¸€åŒ–åˆ°<code>[0,1]</code>ï¼Œå…¶å½’ä¸€åŒ–æ–¹æ³•æ¯”è¾ƒç®€å•ï¼Œç›´æ¥é™¤ä»¥255å³å¯ã€‚</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">DATA_DIR = <span class="string">'/content/11-785-f22-hw2p2-classification'</span><span class="comment"># <span class="doctag">TODO:</span> Path where you have downloaded the data</span></span><br><span class="line">TRAIN_DIR = os.path.join(DATA_DIR, <span class="string">"classification/train"</span>) </span><br><span class="line">VAL_DIR = os.path.join(DATA_DIR, <span class="string">"classification/dev"</span>)</span><br><span class="line">TEST_DIR = os.path.join(DATA_DIR, <span class="string">"classification/test"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Transforms using torchvision - Refer https://pytorch.org/vision/stable/transforms.html</span></span><br><span class="line"></span><br><span class="line">train_transforms = torchvision.transforms.Compose([ </span><br><span class="line">    <span class="comment"># Implementing the right transforms/augmentation methods is key to improving performance.</span></span><br><span class="line">                    torchvision.transforms.ToTensor(),</span><br><span class="line">                    ])</span><br><span class="line"><span class="comment"># Most torchvision transforms are done on PIL images. So you convert it into a tensor at the end with ToTensor()</span></span><br><span class="line"><span class="comment"># But there are some transforms which are performed after ToTensor() : e.g - Normalization</span></span><br><span class="line"><span class="comment"># Normalization Tip - Do not blindly use normalization that is not suitable for this dataset</span></span><br><span class="line"></span><br><span class="line">val_transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_dataset = torchvision.datasets.ImageFolder(TRAIN_DIR, transform = train_transforms)</span><br><span class="line">val_dataset = torchvision.datasets.ImageFolder(VAL_DIR, transform = val_transforms)</span><br><span class="line"><span class="comment"># You should NOT have data augmentation on the validation set. Why?</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create data loaders</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = config[<span class="string">'batch_size'</span>], </span><br><span class="line">                                           shuffle = <span class="literal">True</span>,num_workers = <span class="number">4</span>, pin_memory = <span class="literal">True</span>)</span><br><span class="line">val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = config[<span class="string">'batch_size'</span>], </span><br><span class="line">                                         shuffle = <span class="literal">False</span>, num_workers = <span class="number">2</span>)</span><br></pre></td></tr></tbody></table></figure>
<p>å¯¹äºæµ‹è¯•é›†ï¼Œå› ä¸ºæ²¡æœ‰æ ‡ç­¾è¿™ä¸ªä¿¡æ¯ï¼Œæ‰€ä»¥<code>test</code>ç›®å½•ä¸‹åªæœ‰å¯¹åº”æ•°é‡çš„å›¾åƒï¼Œæ²¡æœ‰å­ç›®å½•ã€‚å› æ­¤åŠ è½½æµ‹è¯•é›†å°±è¦ç”¨è‡ªå·±è®¾è®¡çš„æ–¹æ³•ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># You can do this with ImageFolder as well, but it requires some tweaking</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ClassificationTestDataset</span>(<span class="params">torch.utils.data.Dataset</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, data_dir, transforms</span>):</span></span><br><span class="line">        self.data_dir   = data_dir</span><br><span class="line">        self.transforms = transforms</span><br><span class="line"></span><br><span class="line">        <span class="comment"># This one-liner basically generates a sorted list of full paths to each image in the test directory</span></span><br><span class="line">        self.img_paths  = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> fname: os.path.join(self.data_dir, fname), <span class="built_in">sorted</span>(os.listdir(self.data_dir))))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.img_paths)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, idx</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.transforms(Image.<span class="built_in">open</span>(self.img_paths[idx]))</span><br><span class="line">    </span><br><span class="line">test_dataset = ClassificationTestDataset(TEST_DIR, transforms = val_transforms) </span><br><span class="line">test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = config[<span class="string">'batch_size'</span>], shuffle = <span class="literal">False</span>,</span><br><span class="line">                         drop_last = <span class="literal">False</span>, num_workers = <span class="number">2</span>)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="Model-Part">Model Part</h2>
<p>Now letâ€™s consider how do we take convolutions and assemble them into a strong architecture, considering layers, channel size, stride, kernel size etc. In this part, iâ€™ll first cover 3 aritectures:</p>
<ul>
<li><strong>MobileNetV2</strong>: A fast, parameter-efficient model</li>
<li><strong>ResNet</strong>: The â€œgo-toâ€ for CNNs</li>
<li><strong>ConvNeXt</strong>: The state of the art model</li>
</ul>
<p>CNN architectures are divided into stages, which are divided into blocks.</p>
<ul>
<li>Each â€œstageâ€ consists of (almost) equivalent â€œblocksâ€</li>
<li>Each â€œblockâ€ consists of a few CNN layers, BN, and ReLUs</li>
</ul>
<p>To understand an architecture, we mostly need to understand its <strong>blocks</strong>. All that changes for blocks in different stages is the base num of channels. We do need to piece these blocks together into a final model. The general flow is like this:</p>
<ul>
<li>Stem (some linear layers like project 3 channels to 64 channels and downsample)</li>
<li>Stage 1</li>
<li>â€¦</li>
<li>Stage n</li>
<li>Classification layer</li>
</ul>
<p>The stem usually downsamples the input by 4x. Some stages do downsample. If they do, generally, the first convolution in the stage downsamples by 2x. When you downsample by 2x, you usually increase channel dimension by 2x. So, later stages have smaller spatial resolution, higher num of channels.</p>
<h3 id="SimpleNet">SimpleNet</h3>
<p>è¿™ä¸ªå°±æ˜¯å…ˆäº¤ä¸ªèƒ½è·‘é€šçš„ç‰ˆæœ¬ï¼Œæ ¹æ®æç¤ºå®Œæˆ4-layerçš„CNNï¼Œä¸»è¦å°±æ˜¯channelçš„è®¾è®¡ä»¥åŠoutputsizeçš„è®¾è®¡ï¼Œchannelå°±æ˜¯æŒ‰ç…§<code>3-&gt;128-&gt;256-&gt;512</code>å¾ˆç®€å•ï¼Œoutputsizeåˆ™æ˜¯æŒ‰ç…§ä¸€å…±<code>downsample 32x</code>è¿™ä¸ªåŸåˆ™ï¼ŒæŒ‰ç…§çº¯å·ç§¯ä¹Ÿå°±æ˜¯strideä¸º1è¿›è¡Œpaddingè¡¥é½åï¼Œå†æŠŠstrideè®¾ç½®ä¸ºæƒ³è¦downsampleçš„å€æ•°ï¼Œå› ä¸ºæˆ‘ä»¬æœ‰å››å±‚ï¼Œæ‰€ä»¥ä¾æ¬¡strideä¸º4ï¼Œ2ï¼Œ2ï¼Œ2ã€‚</p>
<p>æœ€åå°†å¾—åˆ°çš„è¾“å‡ºé€šè¿‡<code>nn.AdaptiveAvgPool2d((1, 1))</code>ï¼Œè¿™ä¸ªå±‚çš„ä½œç”¨å°±æ˜¯æŒ‡å®šè¾“å‡ºçš„sizeï¼Œç„¶åè‡ªé€‚åº”è°ƒæ•´kernelå’Œstrideçš„å¤§å°ã€‚</p>
<p>ç»“æœå¤§æ¦‚æ˜¯10ä¸ªepoch 25%çš„å‡†ç¡®ç‡ï¼Œæ¯”è¾ƒä½ï¼Œä½†æ˜¯æˆ‘çœ‹è®­ç»ƒé›†ä¸Šå‡†ç¡®ç‡è¿˜æŒºé«˜çš„ï¼Œå¯èƒ½è¦å¤„ç†ä¸€ä¸‹æ‹Ÿåˆæ•ˆæœæ‰å¥½ã€‚</p>
<h3 id="MobileNetV2">MobileNetV2</h3>
<blockquote>
<p>reference: <a target="_blank" rel="noopener" href="https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728">link</a></p>
</blockquote>
<p>The goal of MobileNetV2 is to be parameter efficient. They do so by making extensive use of <strong>depth-wise convolutions</strong> and <strong>point-wise convolutions</strong>, which is the intuition that a normal convolution can be divided into these 2 parts but with cheaper params.</p>
<ul>
<li>
<p>A normal convolution mixes information from both different channels and different spatial locations(pixels).<img src="https://miro.medium.com/v2/resize:fit:875/1*XloAmCh5bwE4j1G7yk5THw.png" alt="img" style="zoom: 80%;"></p>
</li>
<li>
<p>A depth-wise convolution only mixes information over spatial locations: different channels donâ€™t interact. â€œDepthâ€ means each channel.</p>
</li>
</ul>
<img src="https://miro.medium.com/v2/resize:fit:875/1*yG6z6ESzsRW-9q5F_neOsg.png" alt="img" style="zoom:80%;">
<ul>
<li>A point-wise convolution only mixes information over different channels: different spatial locations donâ€™t interact. â€œpointâ€ means pixel.</li>
</ul>
<img src="https://miro.medium.com/v2/resize:fit:875/1*37sVdBZZ9VK50pcAklh8AQ.png" alt="img" style="zoom:80%;">
<p><strong>MobileNetV2 Block design</strong></p>
<p>First we apply a point-wise convolution to get more channels by an expansion ratio, then apply a depth-wise convolution that communicates information over different spatial locations. At last, we do a point-wise convolution but to reduce channels, which bottlenecks channels. The intuition is to distill a sparse space to a more condensed rich feature dimension.</p>
<img src="\image\HW2P2_image65.png" alt="image-20230411143953025" style="zoom:80%;">
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">InvertedResidualBlock</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Intuitively, layers in MobileNet can be split into "feature mixing" </span></span><br><span class="line"><span class="string">    and "spatial mixing" layers. You can think of feature mixing as each pixel</span></span><br><span class="line"><span class="string">    "thinking on its own" about its own featuers, and you can think of spatial</span></span><br><span class="line"><span class="string">    mixing as pixels "talking with each other". Alternating these two builds</span></span><br><span class="line"><span class="string">    up a CNN.</span></span><br><span class="line"><span class="string">    In a bit more detail:</span></span><br><span class="line"><span class="string">    - The purpose of the "feature mixing" layers is what you've already seen in </span></span><br><span class="line"><span class="string">    hw1p2. Remember, in hw1p2, we went from some low-level audio input to</span></span><br><span class="line"><span class="string">    semantically rich representations of phonemes. Featuring mixing is simply a </span></span><br><span class="line"><span class="string">    linear layer (a weight matrix) that transforms simpler features into </span></span><br><span class="line"><span class="string">    something more advanced.</span></span><br><span class="line"><span class="string">    - The purpose of the "spatial mixing" layers is to mix features from different</span></span><br><span class="line"><span class="string">    spatial locations. You can't figure out a face by looking at each pixel on</span></span><br><span class="line"><span class="string">    its own, right? So we need 3x3 convolutions to mix features from neighboring</span></span><br><span class="line"><span class="string">    pixels to build up spatially larger features.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,</span></span></span><br><span class="line"><span class="params"><span class="function">                 in_channels,</span></span></span><br><span class="line"><span class="params"><span class="function">                 out_channels,</span></span></span><br><span class="line"><span class="params"><span class="function">                 stride,</span></span></span><br><span class="line"><span class="params"><span class="function">                 expand_ratio</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__() <span class="comment"># Just have to do this for all nn.Module classes</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Can only do identity residual connection if input &amp; output are the</span></span><br><span class="line">        <span class="comment"># same channel &amp; spatial shape.</span></span><br><span class="line">        <span class="keyword">if</span> stride == <span class="number">1</span> <span class="keyword">and</span> in_channels == out_channels:</span><br><span class="line">            self.do_identity = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.do_identity = <span class="literal">False</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Expand Ratio is like 6, so hidden_dim &gt;&gt; in_channels</span></span><br><span class="line">        hidden_dim = in_channels * expand_ratio</span><br><span class="line"></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        What is this doing? It's a 1x1 convolutional layer that drastically</span></span><br><span class="line"><span class="string">        increases the # of channels (feature dimension). 1x1 means each pixel</span></span><br><span class="line"><span class="string">        is thinking on its own, and increasing # of channels means the network</span></span><br><span class="line"><span class="string">        is seeing if it can "see" more clearly in a higher dimensional space.</span></span><br><span class="line"><span class="string">        Some patterns are just more obvious/separable in higher dimensions.</span></span><br><span class="line"><span class="string">        Also, note that bias = False since BatchNorm2d has a bias term built-in.</span></span><br><span class="line"><span class="string">        As you go, note the relationship between kernel_size and padding. As you</span></span><br><span class="line"><span class="string">        covered in class, padding = kernel_size // 2 (kernel_size being odd) to</span></span><br><span class="line"><span class="string">        make sure input &amp; output spatial resolution is the same.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.feature_mixing = nn.Sequential(</span><br><span class="line">            <span class="comment"># <span class="doctag">TODO:</span> Fill this in!</span></span><br><span class="line">            nn.Conv2d(in_channels=in_channels,</span><br><span class="line">                      out_channels=hidden_dim,</span><br><span class="line">                      kernel_size=<span class="number">1</span>,</span><br><span class="line">                      stride=<span class="number">1</span>,</span><br><span class="line">                      padding=<span class="number">0</span>,</span><br><span class="line">                      bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(hidden_dim),</span><br><span class="line">            nn.ReLU6(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        What is this doing? Let's break it down.</span></span><br><span class="line"><span class="string">        - kernel_size = 3 means neighboring pixels are talking with each other.</span></span><br><span class="line"><span class="string">          This is different from feature mixing, where kernel_size = 1.</span></span><br><span class="line"><span class="string">        - stride. Remember that we sometimes want to downsample spatially. </span></span><br><span class="line"><span class="string">          Downsampling is done to reduce # of pixels (less computation to do), </span></span><br><span class="line"><span class="string">          and also to increase receptive field (if a face was 32x32, and now</span></span><br><span class="line"><span class="string">          it's 16x16, a 3x3 convolution covers more of the face, right?). It</span></span><br><span class="line"><span class="string">          makes sense to put the downsampling in the spatial mixing portion</span></span><br><span class="line"><span class="string">          since this layer is "in charge" of messing around spatially anyway.</span></span><br><span class="line"><span class="string">          Note that most of the time, stride is 1. It's just the first block of</span></span><br><span class="line"><span class="string">          every "stage" (layer \subsetof block \subsetof stage) that we have</span></span><br><span class="line"><span class="string">          stride = 2.</span></span><br><span class="line"><span class="string">        - groups = hidden_dim. Remember depthwise separable convolutions in </span></span><br><span class="line"><span class="string">          class? If not, it's fine. Usually, when we go from hidden_dim channels</span></span><br><span class="line"><span class="string">          to hidden_dim channels, they're densely connected (like a linear </span></span><br><span class="line"><span class="string">          layer). So you can think of every pixel/grid in an input</span></span><br><span class="line"><span class="string">          3 x 3 x hidden_dim block being connected to every single pixel/grid </span></span><br><span class="line"><span class="string">          in the output 3 x 3 x hidden_dim block.</span></span><br><span class="line"><span class="string">          What groups = hidden_dim does is remove a lot of these connections.</span></span><br><span class="line"><span class="string">          Now, each input 3 x 3 block/region is densely connected to the</span></span><br><span class="line"><span class="string">          corresponding output 3 x 3 block/region. This happens for each of the</span></span><br><span class="line"><span class="string">          hidden_dim input/output channel pairs independently.</span></span><br><span class="line"><span class="string">          So we're not even mixing different channels together - we're only </span></span><br><span class="line"><span class="string">          mixing spatial neighborhoods. </span></span><br><span class="line"><span class="string">          </span></span><br><span class="line"><span class="string">          Try to draw this out, or come to my (Jinhyung Park)'s OH if you want </span></span><br><span class="line"><span class="string">          a more in-depth explanation.</span></span><br><span class="line"><span class="string">          https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.spatial_mixing = nn.Sequential(</span><br><span class="line">            <span class="comment"># <span class="doctag">TODO:</span> Fill this in!</span></span><br><span class="line">            nn.Conv2d(in_channels=hidden_dim,</span><br><span class="line">                      out_channels=hidden_dim,</span><br><span class="line">                      kernel_size=<span class="number">3</span>,</span><br><span class="line">                      stride=stride,</span><br><span class="line">                      padding=<span class="number">1</span>,</span><br><span class="line">                      groups=hidden_dim,</span><br><span class="line">                      bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(hidden_dim),</span><br><span class="line">            nn.ReLU6(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        What's this? Remember that hidden_dim is quite large - six times the </span></span><br><span class="line"><span class="string">        in_channels. So it was nice to do the above operations in this high-dim</span></span><br><span class="line"><span class="string">        space, where some patterns might be more clear. But we still want to </span></span><br><span class="line"><span class="string">        bring it back down-to-earth.</span></span><br><span class="line"><span class="string">        Intuitively, you can takeaway two reasons for doing this:</span></span><br><span class="line"><span class="string">        - Reduces computational cost by a lot. 6x in &amp; out channels means 36x</span></span><br><span class="line"><span class="string">          larger weights, which is crazy. We're okay with just one of input or </span></span><br><span class="line"><span class="string">          output of a convolutional layer being large when mixing channels, but </span></span><br><span class="line"><span class="string">          not both.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        - We also want a residual connection from the input to the output. To </span></span><br><span class="line"><span class="string">          do that without introducing another convolutional layer, we want to</span></span><br><span class="line"><span class="string">          condense the # of channels back to be the same as the in_channels.</span></span><br><span class="line"><span class="string">          (out_channels and in_channels are usually the same).</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.bottleneck_channels = nn.Sequential(</span><br><span class="line">            <span class="comment"># <span class="doctag">TODO:</span> Fill this in!</span></span><br><span class="line">            nn.Conv2d(in_channels=hidden_dim,</span><br><span class="line">                      out_channels=out_channels,</span><br><span class="line">                      kernel_size=<span class="number">1</span>,</span><br><span class="line">                      stride=<span class="number">1</span>,</span><br><span class="line">                      padding=<span class="number">0</span>,</span><br><span class="line">                      bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels) </span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        out = self.feature_mixing(x)</span><br><span class="line">        out = self.spatial_mixing(out)</span><br><span class="line">        out = self.bottleneck_channels(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.do_identity:</span><br><span class="line">            <span class="keyword">return</span> x + out</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> out</span><br></pre></td></tr></tbody></table></figure>
<p>And the complete MobileNetV2:</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MobileNetV2</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    The heavy lifting is already done in InvertedBottleneck.</span></span><br><span class="line"><span class="string">    Why MobileNetV2 and not V3? V2 is the foundation for V3, which uses "neural</span></span><br><span class="line"><span class="string">    architecture search" to find better configurations of V2. If you understand</span></span><br><span class="line"><span class="string">    V2 well, you can totally implement V3!</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_classes= <span class="number">7000</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line"></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        First couple of layers are special, just do them here.</span></span><br><span class="line"><span class="string">        This is called the "stem". Usually, methods use it to downsample or twice.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.stem = nn.Sequential(</span><br><span class="line">            <span class="comment"># <span class="doctag">TODO:</span> Fill this in!</span></span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">32</span>),</span><br><span class="line">            nn.ReLU6(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, groups=<span class="number">32</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">32</span>),</span><br><span class="line">            nn.ReLU6(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">32</span>, <span class="number">16</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">16</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Since we're just repeating InvertedResidualBlocks again and again, we</span></span><br><span class="line"><span class="string">        want to specify their parameters like this.</span></span><br><span class="line"><span class="string">        The four numbers in each row (a stage) are shown below.</span></span><br><span class="line"><span class="string">        - Expand ratio: We talked about this in InvertedResidualBlock</span></span><br><span class="line"><span class="string">        - Channels: This specifies the channel size before expansion</span></span><br><span class="line"><span class="string">        - # blocks: Each stage has many blocks, how many?</span></span><br><span class="line"><span class="string">        - Stride of first block: For some stages, we want to downsample. In a</span></span><br><span class="line"><span class="string">          downsampling stage, we set the first block in that stage to have</span></span><br><span class="line"><span class="string">          stride = 2, and the rest just have stride = 1.</span></span><br><span class="line"><span class="string">        Again, note that almost every stage here is downsampling! By the time</span></span><br><span class="line"><span class="string">        we get to the last stage, what is the image resolution? Can it still</span></span><br><span class="line"><span class="string">        be called an image for our dataset? Think about this, and make changes</span></span><br><span class="line"><span class="string">        as you want.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.stage_cfgs = [</span><br><span class="line">            <span class="comment"># expand_ratio, channels, # blocks, stride of first block</span></span><br><span class="line">            [<span class="number">6</span>,  <span class="number">24</span>, <span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">            [<span class="number">6</span>,  <span class="number">32</span>, <span class="number">3</span>, <span class="number">2</span>],</span><br><span class="line">            [<span class="number">6</span>,  <span class="number">64</span>, <span class="number">4</span>, <span class="number">2</span>],</span><br><span class="line">            [<span class="number">6</span>,  <span class="number">96</span>, <span class="number">3</span>, <span class="number">1</span>],</span><br><span class="line">            [<span class="number">6</span>, <span class="number">160</span>, <span class="number">3</span>, <span class="number">2</span>],</span><br><span class="line">            [<span class="number">6</span>, <span class="number">320</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Remember that our stem left us off at 16 channels. We're going to </span></span><br><span class="line">        <span class="comment"># keep updating this in_channels variable as we go</span></span><br><span class="line">        in_channels = <span class="number">16</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Let's make the layers</span></span><br><span class="line">        layers = []</span><br><span class="line">        <span class="keyword">for</span> curr_stage <span class="keyword">in</span> self.stage_cfgs:</span><br><span class="line">            expand_ratio, num_channels, num_blocks, stride = curr_stage</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> block_idx <span class="keyword">in</span> <span class="built_in">range</span>(num_blocks):</span><br><span class="line">                out_channels = num_channels</span><br><span class="line">                layers.append(InvertedResidualBlock(</span><br><span class="line">                    in_channels=in_channels,</span><br><span class="line">                    out_channels=out_channels,</span><br><span class="line">                    <span class="comment"># only have non-trivial stride if first block</span></span><br><span class="line">                    stride=stride <span class="keyword">if</span> block_idx == <span class="number">0</span> <span class="keyword">else</span> <span class="number">1</span>, </span><br><span class="line">                    expand_ratio=expand_ratio</span><br><span class="line">                ))</span><br><span class="line">                <span class="comment"># In channels of the next block is the out_channels of the current one</span></span><br><span class="line">                in_channels = out_channels </span><br><span class="line">            </span><br><span class="line">        self.layers = nn.Sequential(*layers) <span class="comment"># Done, save them to the class</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Some final feature mixing</span></span><br><span class="line">        self.final_block = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, <span class="number">1280</span>, kernel_size=<span class="number">1</span>, padding=<span class="number">0</span>, stride=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">1280</span>),</span><br><span class="line">            nn.ReLU6()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Now, we need to build the final classification layer.</span></span><br><span class="line">        self.avgpool = nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        self.classifier = nn.Linear(<span class="number">1280</span>, self.num_classes)</span><br><span class="line"></span><br><span class="line">        self._initialize_weights()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_initialize_weights</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Usually, I like to use default pytorch initialization for stuff, but</span></span><br><span class="line"><span class="string">        MobileNetV2 made a point of putting in some custom ones, so let's just</span></span><br><span class="line"><span class="string">        use them.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">                n = m.kernel_size[<span class="number">0</span>] * m.kernel_size[<span class="number">1</span>] * m.out_channels</span><br><span class="line">                m.weight.data.normal_(<span class="number">0</span>, math.sqrt(<span class="number">2.</span> / n))</span><br><span class="line">                <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    m.bias.data.zero_()</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.BatchNorm2d):</span><br><span class="line">                m.weight.data.fill_(<span class="number">1</span>)</span><br><span class="line">                m.bias.data.zero_()</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">                m.weight.data.normal_(<span class="number">0</span>, <span class="number">0.01</span>)</span><br><span class="line">                m.bias.data.zero_()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, return_feats=<span class="literal">False</span></span>):</span></span><br><span class="line">        out = self.stem(x)</span><br><span class="line">        out = self.layers(out)</span><br><span class="line">        out = self.final_block(out)</span><br><span class="line"></span><br><span class="line">        avg_out = self.avgpool(out)</span><br><span class="line">        feats = avg_out.reshape(avg_out.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        classifier_out = self.classifier(feats)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> return_feats:</span><br><span class="line">            feats = nn.functional.normalize(feats, p=<span class="number">2.0</span>, dim=<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">return</span> feats</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> classifier_out</span><br></pre></td></tr></tbody></table></figure>
<h3 id="ResNet">ResNet</h3>
<p>ç®€è¦æ€»ç»“ä¸€ä¸‹ï¼šå¯¹äºstemå’Œstageçš„æ•°æ®æµåŠ¨</p>
<ul>
<li>è¾“å…¥çš„å›¾ç‰‡ä¸º<img src="https://math.now.sh?inline=3%20%5Ctimes%20224%20%5Ctimes%20224" style="display:inline-block;margin: 0;"></li>
<li>ç»è¿‡stemï¼Œè¾“å‡ºçš„å›¾ç‰‡ä¸º<img src="https://math.now.sh?inline=64%20%5Ctimes%20112%20%5Ctimes%20112" style="display:inline-block;margin: 0;"></li>
<li>ç»è¿‡max poolå±‚ï¼Œè¾“å‡ºçš„å›¾ç‰‡ä¸º<img src="https://math.now.sh?inline=64%20%5Ctimes%2056%20%5Ctimes%2056" style="display:inline-block;margin: 0;"></li>
</ul>
<p>è‡³æ­¤ç›¸å½“äº<code>downsample</code>äº†4å€ã€‚</p>
<p>å¯¹äº<code>Resnet 18</code>ã€<code>Resnet 34</code>ä¹Ÿå°±æ˜¯ä½¿ç”¨<code>BasicBlock</code>ï¼š</p>
<ul>
<li>å›¾ç‰‡ç»è¿‡<code>stage1</code>ï¼Œè¾“å‡ºå›¾ç‰‡çš„å¤§å°ä¸º<img src="https://math.now.sh?inline=64%20%5Ctimes%2056%20%5Ctimes%2056" style="display:inline-block;margin: 0;"> (ä¹Ÿå°±æ˜¯ä¸å˜)</li>
<li>å›¾ç‰‡ç»è¿‡<code>stage2</code>ï¼Œè¾“å‡ºå›¾ç‰‡çš„å¤§å°ä¸º<img src="https://math.now.sh?inline=128%20%5Ctimes%2028%20%5Ctimes%2028" style="display:inline-block;margin: 0;"></li>
<li>å›¾ç‰‡ç»è¿‡<code>stage3</code>ï¼Œè¾“å‡ºå›¾ç‰‡çš„å¤§å°ä¸º<img src="https://math.now.sh?inline=256%20%5Ctimes%2014%20%5Ctimes%2014" style="display:inline-block;margin: 0;"></li>
<li>å›¾ç‰‡ç»è¿‡<code>stage4</code>ï¼Œè¾“å‡ºå›¾ç‰‡çš„å¤§å°ä¸º<img src="https://math.now.sh?inline=512%20%5Ctimes%207%20%5Ctimes%207" style="display:inline-block;margin: 0;"></li>
<li>å›¾ç‰‡ç»è¿‡<code>avg pool</code>ï¼Œè¾“å‡ºå›¾ç‰‡çš„å¤§å°ä¸º<img src="https://math.now.sh?inline=512%20%5Ctimes%201%20%5Ctimes%201" style="display:inline-block;margin: 0;"></li>
</ul>
<p>å¯¹äº<code>Resnet 50</code>ã€<code>Resnet 101</code>ä¹Ÿå°±æ˜¯ä½¿ç”¨<code>Bottleneck</code>ï¼š</p>
<ul>
<li>å›¾ç‰‡ç»è¿‡<code>stage1</code>ï¼Œè¾“å‡ºå›¾ç‰‡çš„å¤§å°ä¸º<img src="https://math.now.sh?inline=256%20%5Ctimes%2056%20%5Ctimes%2056" style="display:inline-block;margin: 0;"> (ä¹Ÿå°±æ˜¯ä¸å˜)</li>
<li>å›¾ç‰‡ç»è¿‡<code>stage2</code>ï¼Œè¾“å‡ºå›¾ç‰‡çš„å¤§å°ä¸º<img src="https://math.now.sh?inline=512%20%5Ctimes%2028%20%5Ctimes%2028" style="display:inline-block;margin: 0;"></li>
<li>å›¾ç‰‡ç»è¿‡<code>stage3</code>ï¼Œè¾“å‡ºå›¾ç‰‡çš„å¤§å°ä¸º<img src="https://math.now.sh?inline=1024%20%5Ctimes%2014%20%5Ctimes%2014" style="display:inline-block;margin: 0;"></li>
<li>å›¾ç‰‡ç»è¿‡<code>stage4</code>ï¼Œè¾“å‡ºå›¾ç‰‡çš„å¤§å°ä¸º<img src="https://math.now.sh?inline=2048%20%5Ctimes%207%20%5Ctimes%207" style="display:inline-block;margin: 0;"></li>
<li>å›¾ç‰‡ç»è¿‡<code>avg pool</code>è¾“å‡ºå›¾ç‰‡çš„å¤§å°ä¸º<img src="https://math.now.sh?inline=2048%20%5Ctimes%201%20%5Ctimes%201" style="display:inline-block;margin: 0;"></li>
</ul>
<p>ä¸‹é¢åˆ†æstageä¸­çš„ç»“æ„ï¼Œä»¥<code>resnet 18</code>å’Œ<code>resnet 50</code>ä¸ºä¾‹ã€‚</p>
<p>å¯¹äº<code>resnet 18</code>ï¼Œstageé‡Œé¢åŒ…å«ä¸¤ä¸ª<code>basic block</code>ï¼Œæ¯ä¸ª<code>block</code>ç”±ä¸¤ä¸ªå·ç§¯å±‚ç»„æˆï¼Œå¯¹åº”æ•°æ®çš„æµåŠ¨ï¼š</p>
<ul>
<li>
<p>åœ¨stage1ä¸­ï¼Œä¸¤ä¸ªå·ç§¯å±‚çš„input channelå’Œoutput channeléƒ½æ˜¯64</p>
</li>
<li>
<p>åç»­çš„stageä¸­ï¼Œå› ä¸ºè¦ä¸‹é‡‡æ ·ï¼Œæ‰€ä»¥åœ¨ç¬¬ä¸€ä¸ªå·ç§¯å±‚ä¸­output channeléƒ½æ˜¯input channelçš„ä¸¤å€ï¼Œè€Œä¸”æ®‹å·®è¿æ¥ä¹Ÿè¦å¯¹åº”æŠŠè¾“å…¥çš„channelå˜æˆoutput channelçš„å½¢å¼</p>
</li>
</ul>
<p>å¯¹äº<code>resnet 50</code>ï¼Œä¸åŒçš„ç‚¹åœ¨äºæ¯ä¸ªblocké‡Œé¢æœ‰ä¸‰ä¸ªå·ç§¯å±‚ï¼Œå¯¹åº”çš„æ•°æ®æµåŠ¨å…¶å®æ˜¯ç»è¿‡äº†ä¸€ä¸ªbottleneckçš„è¿‡ç¨‹ï¼Œå…·ä½“å¯ä»¥çœ‹ä¸‹é¢çš„å›¾ã€‚</p>
<p>åœ¨ä»£ç ä¸Šçš„å®ç°ï¼Œä¹Ÿå°±æ˜¯<code>_make_stage</code>ä¸­ï¼Œå¯¹åº”è¦æŠŠç¬¬äºŒå—blockçš„inputè°ƒæ•´æˆç¬¬ä¸€å—blockä¸­é—´bottleneck outputå€ç‡åçš„è¾“å‡ºã€‚</p>
<img src="https://pic1.zhimg.com/v2-911cced38e5f56ce31a0140fa72583b8_r.jpg" style="zoom:50%;">
<img src="https://pic1.zhimg.com/v2-3ad523e2b78ee0499a0d35093879f570_r.jpg" style="zoom: 50%;">
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BasicBlock</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">"""Basic Block for resnet 18 and resnet 34</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#BasicBlock and BottleNeck block</span></span><br><span class="line">    <span class="comment">#have different output size</span></span><br><span class="line">    <span class="comment">#we use class attribute expansion</span></span><br><span class="line">    <span class="comment">#to distinct</span></span><br><span class="line">    expansion = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels, stride=<span class="number">1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment">#residual function</span></span><br><span class="line">        self.residual_function = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>, stride=stride, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels),</span><br><span class="line">            nn.GELU(),</span><br><span class="line">            nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels * BasicBlock.expansion)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment">#shortcut</span></span><br><span class="line">        self.shortcut = nn.Sequential()</span><br><span class="line"></span><br><span class="line">        <span class="comment">#the shortcut output dimension is not the same with residual function</span></span><br><span class="line">        <span class="comment">#use 1*1 convolution to match the dimension</span></span><br><span class="line">        <span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> in_channels != BasicBlock.expansion * out_channels:</span><br><span class="line">            self.shortcut = nn.Sequential(</span><br><span class="line">                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=<span class="number">1</span>, stride=stride, bias=<span class="literal">False</span>),</span><br><span class="line">                nn.BatchNorm2d(out_channels * BasicBlock.expansion)</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> nn.GELU()(self.residual_function(x) + self.shortcut(x))</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BottleNeck</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">"""Residual block for resnet over 50 layers</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    expansion = <span class="number">4</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels, stride=<span class="number">1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.residual_function = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels),</span><br><span class="line">            nn.GELU(),</span><br><span class="line">            nn.Conv2d(out_channels, out_channels, stride=stride, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels),</span><br><span class="line">            nn.GELU(),</span><br><span class="line">            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels * BottleNeck.expansion),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.shortcut = nn.Sequential()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> in_channels != out_channels * BottleNeck.expansion:</span><br><span class="line">            self.shortcut = nn.Sequential(</span><br><span class="line">                nn.Conv2d(in_channels, out_channels * BottleNeck.expansion, stride=stride, kernel_size=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">                nn.BatchNorm2d(out_channels * BottleNeck.expansion)</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> nn.GELU()(self.residual_function(x) + self.shortcut(x))</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, block, num_block, num_classes=<span class="number">7000</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.in_channels = <span class="number">64</span> <span class="comment"># stage1 input channels</span></span><br><span class="line"></span><br><span class="line">        self.stem = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">            nn.GELU()</span><br><span class="line">            )</span><br><span class="line">        </span><br><span class="line">        self.maxpool = nn.MaxPool2d(</span><br><span class="line">            kernel_size=<span class="number">3</span>, </span><br><span class="line">            stride=<span class="number">2</span>, </span><br><span class="line">            padding=<span class="number">1</span></span><br><span class="line">            )</span><br><span class="line">        </span><br><span class="line">        self.stage1 = self._make_stage(block, <span class="number">64</span>, num_block[<span class="number">0</span>], <span class="number">1</span>)</span><br><span class="line">        self.stage2 = self._make_stage(block, <span class="number">128</span>, num_block[<span class="number">1</span>], <span class="number">2</span>)</span><br><span class="line">        self.stage3 = self._make_stage(block, <span class="number">256</span>, num_block[<span class="number">2</span>], <span class="number">2</span>)</span><br><span class="line">        self.stage4 = self._make_stage(block, <span class="number">512</span>, num_block[<span class="number">3</span>], <span class="number">2</span>)     </span><br><span class="line"></span><br><span class="line">        self.avg_pool = nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        self.fc = nn.Linear(<span class="number">512</span> * block.expansion, num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_make_stage</span>(<span class="params">self, block, out_channels, num_blocks, stride</span>):</span></span><br><span class="line">        <span class="string">"""make resnet layers(by layer i didnt mean this 'layer' was the</span></span><br><span class="line"><span class="string">        same as a neuron netowork layer, ex. conv layer), one layer may</span></span><br><span class="line"><span class="string">        contain more than one residual block</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            block: block type, basic block or bottle neck block</span></span><br><span class="line"><span class="string">            out_channels: output depth channel number of this layer</span></span><br><span class="line"><span class="string">            num_blocks: how many blocks per layer</span></span><br><span class="line"><span class="string">            stride: the stride of the first block of this layer</span></span><br><span class="line"><span class="string">        Return:</span></span><br><span class="line"><span class="string">            return a resnet layer</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># we have num_block blocks per layer, the first block</span></span><br><span class="line">        <span class="comment"># could be 1 or 2, other blocks would always be 1</span></span><br><span class="line">        strides = [stride] + [<span class="number">1</span>] * (num_blocks - <span class="number">1</span>)</span><br><span class="line">        layers = []</span><br><span class="line">        <span class="keyword">for</span> stride <span class="keyword">in</span> strides:</span><br><span class="line">            layers.append(block(self.in_channels, out_channels, stride))</span><br><span class="line">            self.in_channels = out_channels * block.expansion</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, return_feats = <span class="literal">False</span></span>):</span></span><br><span class="line">        output = self.stem(x)</span><br><span class="line">        output = self.maxpool(output)</span><br><span class="line">        output = self.stage1(output)</span><br><span class="line">        output = self.stage2(output)</span><br><span class="line">        output = self.stage3(output)</span><br><span class="line">        output = self.stage4(output)</span><br><span class="line">        avg_out = self.avg_pool(output)</span><br><span class="line"></span><br><span class="line">        feats = avg_out.reshape(avg_out.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        classifier_out = self.fc(feats)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> return_feats:</span><br><span class="line">            feats = nn.functional.normalize(feats, p=<span class="number">2.0</span>, dim=<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">return</span> feats</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> classifier_out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resnet18</span>():</span></span><br><span class="line">    <span class="string">""" return a ResNet 18 object</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> ResNet(BasicBlock, [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resnet34</span>():</span></span><br><span class="line">    <span class="string">""" return a ResNet 34 object</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> ResNet(BasicBlock, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resnet50</span>():</span></span><br><span class="line">    <span class="string">""" return a ResNet 50 object</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> ResNet(BottleNeck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resnet101</span>():</span></span><br><span class="line">    <span class="string">""" return a ResNet 101 object</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> ResNet(BottleNeck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">23</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resnet152</span>():</span></span><br><span class="line">    <span class="string">""" return a ResNet 152 object</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> ResNet(BottleNeck, [<span class="number">3</span>, <span class="number">8</span>, <span class="number">36</span>, <span class="number">3</span>])</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h3 id="ConvNeXt">ConvNeXt</h3>
<p>SOTA architecture, its intuitions are very similar to MobileNetV2.</p>
<img src="\image\HW2P2_image66.png" alt="image-20230411154140241" style="zoom: 50%;">
<p>The differences:</p>
<ol>
<li>The depth-wise convolution in ConvNeXt is larger kernel size(7x7).</li>
<li>The order of spatial mixing &amp; feature mixing are flipped. In ConvNeXt, depth-wise convolution operates on lower num of channels. In MobileNetV2, operates on higher num of channels.</li>
<li>Channel Expansion Ratio in ConvNeXt is 4, MobileNetV2 is 6</li>
<li>ConvNeXt uses layer Norm, MobileNetV2 uses batch Norm</li>
<li>ConvNeXt recommends training via AdamW, MobileNetV2 recommends SGD</li>
</ol>
<blockquote>
<p>æœ¬æ¬¡å®éªŒç”¨çš„æ˜¯batchnorm</p>
</blockquote>
<img src="\image\HW2P2_image67.png" alt="image-20230413223920781" style="zoom:80%;">
<img src="\image\HW2P2_image68.png" alt="image-20230413223950024" style="zoom:80%;">
<img src="\image\HW2P2_image69.png" alt="image-20230413224024931" style="zoom:80%;">
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> timm.models.layers <span class="keyword">import</span> trunc_normal_</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BottleNeck</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line"></span><br><span class="line">    expansion = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        expanded_channels = dim * self.expansion</span><br><span class="line"></span><br><span class="line">        self.conv = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels=dim,</span><br><span class="line">                      out_channels=dim,</span><br><span class="line">                      kernel_size=<span class="number">3</span>,</span><br><span class="line">                      stride=<span class="number">1</span>,</span><br><span class="line">                      padding=<span class="number">1</span>,</span><br><span class="line">                      groups=dim,</span><br><span class="line">                      bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(dim),</span><br><span class="line">            nn.Conv2d(in_channels=dim, </span><br><span class="line">                      out_channels=expanded_channels,</span><br><span class="line">                      kernel_size=<span class="number">1</span>,</span><br><span class="line">                      stride=<span class="number">1</span>,</span><br><span class="line">                      bias=<span class="literal">False</span>),</span><br><span class="line">            nn.GELU(),</span><br><span class="line">            nn.Conv2d(in_channels=expanded_channels,</span><br><span class="line">                      out_channels=dim,</span><br><span class="line">                      kernel_size=<span class="number">1</span>,</span><br><span class="line">                      stride=<span class="number">1</span>,</span><br><span class="line">                      bias=<span class="literal">False</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.shortcut = nn.Sequential()</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment"># if self.conv(x).shape[1:] != self.shortcut(x).shape[1:]:</span></span><br><span class="line">        <span class="comment">#     import pdb; pdb.set_trace() </span></span><br><span class="line">        out = self.conv(x) + self.shortcut(x)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConvNext</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, block, block_nums, num_classes=<span class="number">7000</span>, dropout=<span class="number">0</span></span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line"></span><br><span class="line">        dims=[<span class="number">96</span>, <span class="number">192</span>, <span class="number">384</span>, <span class="number">768</span>]</span><br><span class="line"></span><br><span class="line">        self.downsampling = nn.ModuleList()</span><br><span class="line">        stem = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels=<span class="number">3</span>,</span><br><span class="line">                      out_channels=dims[<span class="number">0</span>],</span><br><span class="line">                      kernel_size=<span class="number">4</span>,</span><br><span class="line">                      stride=<span class="number">4</span>,</span><br><span class="line">                      bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(dims[<span class="number">0</span>]),</span><br><span class="line">        )</span><br><span class="line">        self.downsampling.append(stem)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">            downsample_layer = nn.Sequential(</span><br><span class="line">                    nn.BatchNorm2d(dims[i]),</span><br><span class="line">                    nn.Conv2d(dims[i], dims[i+<span class="number">1</span>], kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">            )</span><br><span class="line">            self.downsampling.append(downsample_layer)</span><br><span class="line"></span><br><span class="line">        stage1 = self._make_stage(dims[<span class="number">0</span>], block, block_nums[<span class="number">0</span>])</span><br><span class="line">        stage2 = self._make_stage(dims[<span class="number">1</span>], block, block_nums[<span class="number">1</span>])</span><br><span class="line">        stage3 = self._make_stage(dims[<span class="number">2</span>], block, block_nums[<span class="number">2</span>])</span><br><span class="line">        stage4 = self._make_stage(dims[<span class="number">3</span>], block, block_nums[<span class="number">3</span>])</span><br><span class="line">        self.stage = nn.ModuleList([stage1, stage2, stage3, stage4])</span><br><span class="line"></span><br><span class="line">        self.avgpool = nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        <span class="comment"># self.embedding = nn.Linear(dims[3], dims[3], bias=False)</span></span><br><span class="line">        <span class="comment"># if dropout == 0:</span></span><br><span class="line">        <span class="comment">#     self.classifier = nn.Sequential(</span></span><br><span class="line">        <span class="comment">#         nn.BatchNorm1d(dims[3]),</span></span><br><span class="line">        <span class="comment">#         nn.GELU(),</span></span><br><span class="line">        <span class="comment">#         nn.Linear(dims[3], self.num_classes)</span></span><br><span class="line">        <span class="comment">#     )</span></span><br><span class="line">        <span class="comment"># else:</span></span><br><span class="line">        <span class="comment">#     self.classifier = nn.Sequential(</span></span><br><span class="line">        <span class="comment">#         nn.BatchNorm1d(dims[3]),</span></span><br><span class="line">        <span class="comment">#         nn.GELU(),</span></span><br><span class="line">        <span class="comment">#         nn.Dropout(dropout),</span></span><br><span class="line">        <span class="comment">#         nn.Linear(dims[3], self.num_classes)</span></span><br><span class="line">        <span class="comment">#     )</span></span><br><span class="line">        <span class="keyword">if</span> dropout == <span class="number">0</span>:</span><br><span class="line">            self.classifier = nn.Linear(dims[<span class="number">3</span>], <span class="number">7000</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.classifier = nn.Sequential(</span><br><span class="line">                nn.Linear(dims[<span class="number">3</span>], dims[<span class="number">3</span>], bias=<span class="literal">False</span>),</span><br><span class="line">                nn.BatchNorm1d(dims[<span class="number">3</span>]),</span><br><span class="line">                nn.GELU(),</span><br><span class="line">                nn.Dropout(dropout),</span><br><span class="line">                nn.Linear(dims[<span class="number">3</span>], self.num_classes)</span><br><span class="line">            )</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        self.apply(self._initialize_weights)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_make_stage</span>(<span class="params">self, dim, block, block_num</span>):</span></span><br><span class="line">        stage = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(block_num):</span><br><span class="line">            stage.append(block(dim))</span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*stage)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_initialize_weights</span>(<span class="params">self, m</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, (nn.Conv2d, nn.Linear)):</span><br><span class="line">          <span class="comment"># trunc_normal_ï¼š https://juejin.cn/post/7129817668350050335</span></span><br><span class="line">            trunc_normal_(m.weight, std=<span class="number">.02</span>)</span><br><span class="line">            <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, (nn.BatchNorm2d, nn.BatchNorm1d)):</span><br><span class="line">            nn.init.ones_(m.weight)</span><br><span class="line">            nn.init.zeros_(m.bias)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, return_feats=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">            x = self.downsampling[i](x)</span><br><span class="line">            x = self.stage[i](x)</span><br><span class="line"></span><br><span class="line">        avg_out = self.avgpool(x)</span><br><span class="line">        feats = avg_out.reshape(avg_out.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># feats = self.embedding(feats)</span></span><br><span class="line">        classifier_out = self.classifier(feats)</span><br><span class="line">        <span class="keyword">if</span> return_feats:</span><br><span class="line">            feats = nn.functional.normalize(feats, p=<span class="number">2.0</span>, dim=<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">return</span> classifier_out, feats</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> classifier_out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convnext_t</span>(<span class="params">dropout=<span class="number">0</span></span>):</span></span><br><span class="line">    <span class="keyword">return</span> ConvNext(BottleNeck, [<span class="number">3</span>,<span class="number">3</span>,<span class="number">9</span>,<span class="number">3</span>], dropout=dropout)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_convnext</span>(<span class="params">dropout=<span class="number">0</span>, block_nums=[<span class="number">5</span>,<span class="number">9</span>,<span class="number">9</span>,<span class="number">2</span>]</span>):</span></span><br><span class="line">    <span class="keyword">return</span> ConvNext(BottleNeck, block_nums, dropout=dropout)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="Tuning-Part">Tuning Part</h2>
<h3 id="Data-Augmentation">Data Augmentation</h3>
<p>You will find that even when using a larger/more advanced model, that modal might have same/worse performance. Thatâ€™s because the larger model is severely overfitting.</p>
<h3 id="Label-Smoothing">Label Smoothing</h3>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">zxr</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://xurui314.github.io/2023/03/03/HW2P2/">https://xurui314.github.io/2023/03/03/HW2P2/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Deep-Learning/">Deep Learning</a></div><div class="post_share"><div class="social-share" data-image="https://s2.loli.net/2023/03/03/Qav93NjokKmWh7A.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer=""></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/03/08/HW3P1/"><img class="prev-cover" src="https://s2.loli.net/2023/03/08/CSvgBbyca1RNiEF.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">HW3P1</div></div></a></div><div class="next-post pull-right"><a href="/2023/03/03/HW1P2/"><img class="next-cover" src="https://s2.loli.net/2023/03/03/gFraLwmNBfkz9Dy.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">HW1P2</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2023/03/13/2023-deep-learning/" title="2023 deep learning"><img class="cover" src="https://www.csail.mit.edu/sites/default/files/2017-08/15473005358_576e646680_o.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-13</div><div class="title">2023 deep learning</div></div></a></div><div><a href="/2023/05/13/Contrastive-Learning-in-Multimodal/" title="Contrastive Learning in Multimodal"><img class="cover" src="https://cdn.jsdelivr.net/gh/wdm1732418365/CDN/New%20folder/daydream%20(11).png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-05-13</div><div class="title">Contrastive Learning in Multimodal</div></div></a></div><div><a href="/2023/03/03/HW1P2/" title="HW1P2"><img class="cover" src="https://s2.loli.net/2023/03/03/gFraLwmNBfkz9Dy.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-03</div><div class="title">HW1P2</div></div></a></div><div><a href="/2023/01/14/HW2P1/" title="HW2P1"><img class="cover" src="https://s2.loli.net/2023/01/14/wlGYSmRduNIpHCc.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-14</div><div class="title">HW2P1</div></div></a></div><div><a href="/2023/03/08/HW3P1/" title="HW3P1"><img class="cover" src="https://s2.loli.net/2023/03/08/CSvgBbyca1RNiEF.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-08</div><div class="title">HW3P1</div></div></a></div><div><a href="/2023/04/13/HW4P1/" title="HW4P1"><img class="cover" src="https://pbs.twimg.com/media/FHtPhbzXMAcEyGE.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-04-13</div><div class="title">HW4P1</div></div></a></div></div></div><hr><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div><div id="comment-switch"><span class="first-comment">Valine</span><span class="switch-btn"></span><span class="second-comment">Disqus</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div><div><div id="disqus_thread"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://s2.loli.net/2021/12/08/yTYthVwXD4IPbJ9.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"></div><div class="author-info__name">zxr</div><div class="author-info__description">Think and Do like an MIT student</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">79</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">35</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">16</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/XuRui314"><i class="fab fa-github"></i><span>This is zxr!ğŸš€</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/XuRui314" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://mail.qq.com/" target="_blank" title="Email-1977289398@qq.com"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">zxrçš„ç”Ÿæ´»ï¼Œmathï¼Œç¼–ç¨‹è®°å½•,<div class="twopeople"><div class="container" style="height:200px;"><canvas class="illo" width="800" height="800" style="max-width: 200px; max-height: 200px; touch-action: none; width: 640px; height: 640px;"></canvas></div><script src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/js/twopeople1.js"></script><script src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/js/zdog.dist.js"></script><script id="rendered-js" src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/js/twopeople.js"></script><style>.twopeople{margin: 0;align-items: center;justify-content: center;text-align: center;}canvas{display: block;margin: 0 auto;cursor: move;}</style></div><div class="twopeople"></div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduction"><span class="toc-number">1.</span> <span class="toc-text">Introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Problem-Restatement"><span class="toc-number">1.1.</span> <span class="toc-text">Problem Restatement</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Solving-Problems"><span class="toc-number">1.2.</span> <span class="toc-text">Solving Problems</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Data-Part"><span class="toc-number">2.</span> <span class="toc-text">Data Part</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Model-Part"><span class="toc-number">3.</span> <span class="toc-text">Model Part</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#SimpleNet"><span class="toc-number">3.1.</span> <span class="toc-text">SimpleNet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MobileNetV2"><span class="toc-number">3.2.</span> <span class="toc-text">MobileNetV2</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ResNet"><span class="toc-number">3.3.</span> <span class="toc-text">ResNet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ConvNeXt"><span class="toc-number">3.4.</span> <span class="toc-text">ConvNeXt</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Tuning-Part"><span class="toc-number">4.</span> <span class="toc-text">Tuning Part</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Data-Augmentation"><span class="toc-number">4.1.</span> <span class="toc-text">Data Augmentation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Label-Smoothing"><span class="toc-number">4.2.</span> <span class="toc-text">Label Smoothing</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/07/01/2023-7-1/" title="2023/7/1"><img src="https://www.tsinghua.edu.cn/__local/3/D6/43/55D1EDFDEEAC5CC4720BCF830F2_6E1BFFB2_C4429.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2023/7/1"></a><div class="content"><a class="title" href="/2023/07/01/2023-7-1/" title="2023/7/1">2023/7/1</a><time datetime="2023-07-01T06:01:07.000Z" title="Created 2023-07-01 14:01:07">2023-07-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/07/01/Diffusion-%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F/" title="Diffusion ä»å…¥é—¨åˆ°å…¥åœŸ"><img src="https://theaisummer.com/static/d007d60f773b61f4585cbec3869490d5/a878e/score-sde.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Diffusion ä»å…¥é—¨åˆ°å…¥åœŸ"></a><div class="content"><a class="title" href="/2023/07/01/Diffusion-%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F/" title="Diffusion ä»å…¥é—¨åˆ°å…¥åœŸ">Diffusion ä»å…¥é—¨åˆ°å…¥åœŸ</a><time datetime="2023-07-01T06:00:32.000Z" title="Created 2023-07-01 14:00:32">2023-07-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/06/25/MiniGPT-4/" title="MiniGPT-4"><img src="https://raw.githubusercontent.com/vision-cair/minigpt-4/master/figs/online_demo.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MiniGPT-4"></a><div class="content"><a class="title" href="/2023/06/25/MiniGPT-4/" title="MiniGPT-4">MiniGPT-4</a><time datetime="2023-06-25T11:14:25.000Z" title="Created 2023-06-25 19:14:25">2023-06-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/13/Multimodel-Pretrained-Model/" title="Multimodel Pretrained Model"><img src="https://cdn.jsdelivr.net/gh/wdm1732418365/CDN/New%20folder/daydream%20(1).png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Multimodel Pretrained Model"></a><div class="content"><a class="title" href="/2023/05/13/Multimodel-Pretrained-Model/" title="Multimodel Pretrained Model">Multimodel Pretrained Model</a><time datetime="2023-05-13T14:39:00.000Z" title="Created 2023-05-13 22:39:00">2023-05-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/13/Contrastive-Learning-in-Multimodal/" title="Contrastive Learning in Multimodal"><img src="https://cdn.jsdelivr.net/gh/wdm1732418365/CDN/New%20folder/daydream%20(11).png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Contrastive Learning in Multimodal"></a><div class="content"><a class="title" href="/2023/05/13/Contrastive-Learning-in-Multimodal/" title="Contrastive Learning in Multimodal">Contrastive Learning in Multimodal</a><time datetime="2023-05-13T14:38:33.000Z" title="Created 2023-05-13 22:38:33">2023-05-13</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">Â©2020 - 2023 By zxr</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="github-badge"><a style="color: #fff" rel="license" href="https://hexo.io/" target="_blank" title="ç”± Hexo å¼ºåŠ›é©±åŠ¨"><span class="badge-subject">Powered</span><span class="badge-value bg-blue">Hexo</span></a><a style="color: #fff" rel="license" href="https://gitee.com/" target="_blank" title="é™æ€ç½‘é¡µæ‰˜ç®¡äº GitHub Pages å’Œ Coding Pages å’Œ Gitee Pages"><span class="badge-subject">Hosted</span><span class="badge-value bg-brightgreen">GitHub &amp; Coding &amp; Gitee</span></a><a style="color: #fff" rel="license" href="https://www.jsdelivr.com/" target="_blank" title="jsDelivr æä¾› CDN åŠ é€ŸæœåŠ¡"><span class="badge-subject">CDN</span><span class="badge-value bg-orange">jsDelivr</span></a><a style="color: #fff" rel="license" href="https://jerryc.me" target="_blank" title="ç«™ç‚¹ä½¿ç”¨ Butterflyä¸»é¢˜"><span class="badge-subject">Theme</span><span class="badge-value bg-blue">Butterfly</span></a><a style="color: #fff" rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" title="æœ¬ç«™ç‚¹é‡‡ç”¨çŸ¥è¯†å…±äº«ç½²å-éå•†ä¸šæ€§ä½¿ç”¨-ç›¸åŒæ–¹å¼å…±äº« 4.0 å›½é™…è®¸å¯åè®®è¿›è¡Œè®¸å¯"><span class="badge-subject"><i class="fa fa-copyright"></i></span><span class="badge-value bg-lightgrey">BY-NC-SA 4.0  </span></a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="Increase font size"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="Decrease font size"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = '[object Object]'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: '',
      appKey: '',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script>function loadDisqus () {
  var disqus_config = function () {
    this.page.url = 'https://xurui314.github.io/2023/03/03/HW2P2/'
    this.page.identifier = '2023/03/03/HW2P2/'
    this.page.title = 'HW2P2'
  };

  window.disqusReset = () => {
    DISQUS.reset({
      reload: true,
      config: disqus_config
    })
  }

  if (window.DISQUS) disqusReset()
  else {
    (function() { 
      var d = document, s = d.createElement('script');
      s.src = 'https://.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  }
}

if ('Valine' === 'Disqus' || !false) {
  if (false) btf.loadComment(document.getElementById('disqus_thread'), loadDisqus)
  else loadDisqus()
} else {
  function loadOtherComment () {
    loadDisqus()
  }
}
</script></div><script src="https://cdn.jsdelivr.net/gh/XuRui314/live2d-widget@1.0.1/autoload.js"></script><script src="/js/title.js"></script><script src="/dist/nochocolate.js"></script><div id="aplayer"></div><script type="text/javascript" src="/dist/APlayer.min.js"></script><script type="text/javascript" src="/dist/music.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/gh/metowolf/MetingJS@1.2/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = [
  'title',
  '#config-diff',
  '#body-wrap',
  '#rightside-config-hide',
  '#rightside-config-show',
  '.js-pjax'
]

if (false) {
  pjaxSelectors.unshift('meta[property="og:image"]', 'meta[property="og:title"]', 'meta[property="og:url"]')
}

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.removeEventListener('scroll', window.tocScrollFn)
  window.removeEventListener('scroll', scrollCollect)

  typeof preloader === 'object' && preloader.initLoading()
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // Analytics
  if (false) {
    MtaH5.pgv()
  }

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async="" data-pjax="" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax="">if(document.getElementById('recent-posts') && (location.pathname ==='all'|| 'all' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/Math/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">ğŸ“š zxrã®æ•°å­¦ä¸–ç•Œ (12)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/ç®—æ³•å­¦ä¹ /"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">ğŸ® zxrã®ç®—æ³•å­¦ä¹  (6)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/ç”Ÿæ´»è¶£é—»/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">ğŸ±â€ğŸ‘“ zxrã®ç”Ÿæ´»è¶£é—» (4)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/ç¼–ç¨‹å®ä¾‹/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">ğŸ‘©â€ğŸ’» zxrã®ç¼–ç¨‹å­¦ä¹  (4)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/ç”Ÿæ´»æ„Ÿæ‚Ÿ/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">ğŸš´â€â™‚ zxrã®ç”Ÿæ´»æ„Ÿæ‚Ÿ (11)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/Hexo/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">ğŸ’Œ zxrã®Blogè®°å½• (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="https://XuRui314.github.io/categories" style="flex:1;text-align: center;margin-bottom: 10px;">æŸ¥çœ‹æ›´å¤š...</a></div></div>';
    console.log('å·²æŒ‚è½½magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style> <script data-pjax="">if(document.getElementById('recent-posts') && location.pathname =='/'){
    
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/09/17/9H5WSbTrVejOdkz.jpg" alt="https://i.loli.net/2021/09/17/9H5WSbTrVejOdkz.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-09-17</span><a class="blog-slider__title" href="2021/09/17/æ¦‚ç‡å’Œæµ‹åº¦/">æ¦‚ç‡å’Œæµ‹åº¦(ZJUå¤§ä½¬)</a><div class="blog-slider__text">æ¥çœ‹çœ‹ZJUè®¡ç§‘å¤§ä½¬è§£é‡Šæ¦‚ç‡å’Œæµ‹åº¦ğŸ¥™</div><a class="blog-slider__button" href="2021/09/17/æ¦‚ç‡å’Œæµ‹åº¦/">è¯¦æƒ…</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/25/bPy5m3j9QAilwr2.jpg" alt="https://i.loli.net/2021/08/25/bPy5m3j9QAilwr2.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-08-26</span><a class="blog-slider__title" href="2021/08/26/ç®—æ³•é¢˜ç›®ç»ƒä¹ /">AcWing-Oj-åˆ·é¢˜å­¦ä¹ è®°å½•(åŸºç¡€ç®—æ³•)</a><div class="blog-slider__text">æ¥çœ‹ç®—æ³•è’Ÿè’»çš„ä¸¢äººæ—¥å¸¸å•ŠğŸ‘©â€ğŸ¦½</div><a class="blog-slider__button" href="2021/08/26/ç®—æ³•é¢˜ç›®ç»ƒä¹ /">è¯¦æƒ…</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/15/NYcSXrECnvzOiLP.jpg" alt="https://i.loli.net/2021/08/15/NYcSXrECnvzOiLP.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-08-15</span><a class="blog-slider__title" href="2021/08/15/ä¸¤å±‚ç¥ç»ç½‘ç»œè¯†åˆ«æ‰‹å†™æ•°å­—/">ä¸¤å±‚ç¥ç»ç½‘ç»œè¯†åˆ«æ‰‹å†™æ•°å­—</a><div class="blog-slider__text">è¯†åˆ«æ‰‹å†™æ•°å­—æœ€ç®€å•çš„å®ç°ğŸ§¦</div><a class="blog-slider__button" href="2021/08/15/ä¸¤å±‚ç¥ç»ç½‘ç»œè¯†åˆ«æ‰‹å†™æ•°å­—/">è¯¦æƒ…</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/15/F8aP7R36IidpCt5.jpg" alt="https://i.loli.net/2021/08/15/F8aP7R36IidpCt5.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-08-14</span><a class="blog-slider__title" href="2021/08/14/ç¥ç»ç½‘ç»œæ­å»ºå‡†å¤‡å†…å®¹/">ç¥ç»ç½‘ç»œæ­å»ºå‡†å¤‡å†…å®¹</a><div class="blog-slider__text">å¦‚ä½•è¯†åˆ«æ‰‹å†™ğŸ”¢ï¼Œzxrå¸¦ä½ ä¸€æ­¥ä¸€æ­¥å®ç°ğŸ¼</div><a class="blog-slider__button" href="2021/08/14/ç¥ç»ç½‘ç»œæ­å»ºå‡†å¤‡å†…å®¹/">è¯¦æƒ…</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/12/SJs3MgYC7x8IU26.jpg" alt="https://i.loli.net/2021/08/12/SJs3MgYC7x8IU26.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-08-12</span><a class="blog-slider__title" href="2021/08/12/xuperchain-solidity/">xuperchain&solidity</a><div class="blog-slider__text">åŒºå—é“¾ä¸æ­¢æ˜¯æŒ–å¸ï¼Œè¿˜æœ‰vç¥å’ŒsolidityğŸˆ</div><a class="blog-slider__button" href="2021/08/12/xuperchain-solidity/">è¯¦æƒ…</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/07/27/6fy8mTCbAOWPkrq.png" alt="https://i.loli.net/2021/07/27/6fy8mTCbAOWPkrq.png"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-07-26</span><a class="blog-slider__title" href="2021/07/26/FFT/">FFTçš„è¯¦è§£</a><div class="blog-slider__text">è¿™ä¹ˆå¥½çœ‹çš„FFTï¼Œä¿¡å·ç‹—éƒ½é¦‹å“­äº†ğŸ’¦</div><a class="blog-slider__button" href="2021/07/26/FFT/">è¯¦æƒ…</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/09/zdt4YKoehQvR96S.jpg" alt="https://i.loli.net/2021/08/09/zdt4YKoehQvR96S.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-08-09</span><a class="blog-slider__title" href="2021/08/09/ç‚’é¸¡å¥½ç†è§£çš„æµ‹åº¦è®º/">ç‚’é¸¡å¥½ç†è§£çš„æµ‹åº¦è®º</a><div class="blog-slider__text">ä¸‰æ®µå­—ï¼Œè®©ä½ è¯»æ‡‚æµ‹åº¦è®º</div><a class="blog-slider__button" href="2021/08/09/ç‚’é¸¡å¥½ç†è§£çš„æµ‹åº¦è®º/">è¯¦æƒ…</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/12/wF7TJlqxOLEWGQk.png" alt="https://i.loli.net/2021/08/12/wF7TJlqxOLEWGQk.png"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-07-27</span><a class="blog-slider__title" href="2021/07/27/FT/">å‚…é‡Œå¶å­¦ä¹ èµ„æ–™</a><div class="blog-slider__text">ç®€å•å¥½å­¦çš„å‚…é‡Œå¶å­¦ä¹ èµ„æ–™</div><a class="blog-slider__button" href="2021/07/27/FT/">è¯¦æƒ…</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/07/27/f7jO8hlNpzWVXSP.jpg" alt="https://i.loli.net/2021/07/27/f7jO8hlNpzWVXSP.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-07-26</span><a class="blog-slider__title" href="2021/07/26/hello-world/">å¤§é¸Ÿè½¬è½¬è½¬é…’å§å†…éƒ¨ç»å¯†æ¡£æ¡ˆ</a><div class="blog-slider__text">ä¸è¦ç‚¹è¿›æ¥QAQï¼</div><a class="blog-slider__button" href="2021/07/26/hello-world/">è¯¦æƒ…</a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('å·²æŒ‚è½½swiper')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script>
<script data-pjax="" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper/swiper/swiper.min.js"></script>
<script data-pjax="" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper@0.18/swiper/swiperindex.js"></script>
<style></style><script data-pjax="">function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('å·²æŒ‚è½½electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // æ— æŠ¥é”™ï¼Œä½†ä¸å½±å“ä½¿ç”¨(æ”¯æŒpjaxè·³è½¬)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // æœ‰æŠ¥é”™ï¼Œä½†ä¸å½±å“ä½¿ç”¨(æ”¯æŒpjaxè·³è½¬)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax="" src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script>
  <script data-pjax="" src="https://cdn.jsdelivr.net/gh/Zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script>
  <script data-pjax="">
        function GithubCalendarConfig(){
            var git_githubapiurl ="https://python-github-calendar-api.vercel.app/api?XuRui314";
            var git_color =['#ebedf0', '#fdcdec', '#fc9bd9', '#fa6ac5', '#f838b2', '#f5089f', '#c4067e', '#92055e', '#540336', '#48022f', '#30021f'];
            var git_user ="XuRui314";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="height:100%;display: flex;align-items: center;justify-content: center;"><svg style="height:50px" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>';
            if(parent_div_git && location.pathname =='/'){
                console.log('å·²æŒ‚è½½github calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // æ— æŠ¥é”™ï¼Œä½†ä¸å½±å“ä½¿ç”¨(æ”¯æŒpjaxè·³è½¬)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // æœ‰æŠ¥é”™ï¼Œä½†ä¸å½±å“ä½¿ç”¨(æ”¯æŒpjaxè·³è½¬)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:248px}@media screen and (max-width:650px) {#github_container{background-image:;min-height:0px}}</style>
    <style></style><script async="" src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"live2d-widget-model-wanko"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.7},"log":false});</script></body></html>