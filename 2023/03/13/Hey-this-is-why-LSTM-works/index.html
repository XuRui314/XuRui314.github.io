<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Hey, this is why LSTM works! | XuRui-Blog</title><meta name="keywords" content="Deep Learning"><meta name="author" content="zxr"><meta name="copyright" content="zxr"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Introduction 首先谈一谈我对于神经网络结构改造的想法，其实和物理、化学这些理科不一样，很难说有什么支撑性的理论基础来引导模型的设计，深度学习更看重的是实际工程效果怎么样。据我所知对于文本和图像这种数据，人们还并没有那种完全式的掌握和理解，其实也是通过各种模型工具来窥知一二。所以深度学习的理论分析大多都是很泛的，因为针对某类具体问题压根没有对应的完备理论性知识。 深度学习的思维是针对已有">
<meta property="og:type" content="article">
<meta property="og:title" content="Hey, this is why LSTM works!">
<meta property="og:url" content="https://xurui314.github.io/2023/03/13/Hey-this-is-why-LSTM-works/index.html">
<meta property="og:site_name" content="XuRui-Blog">
<meta property="og:description" content="Introduction 首先谈一谈我对于神经网络结构改造的想法，其实和物理、化学这些理科不一样，很难说有什么支撑性的理论基础来引导模型的设计，深度学习更看重的是实际工程效果怎么样。据我所知对于文本和图像这种数据，人们还并没有那种完全式的掌握和理解，其实也是通过各种模型工具来窥知一二。所以深度学习的理论分析大多都是很泛的，因为针对某类具体问题压根没有对应的完备理论性知识。 深度学习的思维是针对已有">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://i.pinimg.com/originals/eb/f4/3c/ebf43c10b242f73d8dfc5e4545ecc63e.jpg">
<meta property="article:published_time" content="2023-03-13T14:19:27.000Z">
<meta property="article:modified_time" content="2023-06-06T10:08:24.947Z">
<meta property="article:author" content="zxr">
<meta property="article:tag" content="Deep Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.pinimg.com/originals/eb/f4/3c/ebf43c10b242f73d8dfc5e4545ecc63e.jpg"><link rel="shortcut icon" href="https://i.loli.net/2021/07/27/lSHRJbx7dYwTk8f.jpg"><link rel="canonical" href="https://xurui314.github.io/2023/03/13/Hey-this-is-why-LSTM-works/"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Hey, this is why LSTM works!',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-06-06 18:08:24'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    document.addEventListener('pjax:complete', detectApple)})(window)</script><link rel="stylesheet" href="/css/badge.css"><link rel="stylesheet" href="/css/modify.css"><link rel="stylesheet" href="/css/mouse.css"><link rel="stylesheet" href="/dist/APlayer.min.css"><link rel="stylesheet" href="/css/custom.css"><link rel="stylesheet" href="/css/bilibiliBanner.css" media="defer" onload="this.media='screen'"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper/swiper/swiper.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper/swiper/swiperstyle.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css">
<style>#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags:before {content:"\A";
  white-space: pre;}#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags > .article-meta__separator{display:none}</style>
<link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script async="" src="https://unpkg.zhimg.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://s2.loli.net/2021/12/08/yTYthVwXD4IPbJ9.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">80</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">35</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">16</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页🍭</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 档案🌊</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签📑</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类🌈</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 好康的✨</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener" href="https://ocw.mit.edu/"><i class="fa-fw fas fa-link"></i><span> 来学麻学</span></a></li><li><a class="site-page child" href="/bangumis/"><i class="fa-fw fas fa-video"></i><span> zxrの追番计划</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=RyOyXsKuUgI"><i class="fa-fw fas fa-heart"></i><span> zxr最爱滴up嘉倩</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://oskarstalberg.com/game/planet/planet.html"><span> Planet</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链💕</span></a></div><div class="menus_item"><a class="site-page" href="https://xurui314.github.io/aboutme/"><span> AboutMe🏂</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.foreverblog.cn/go.html"><span> 虫洞</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://i.pinimg.com/originals/eb/f4/3c/ebf43c10b242f73d8dfc5e4545ecc63e.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">XuRui-Blog</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页🍭</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 档案🌊</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签📑</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类🌈</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 好康的✨</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener" href="https://ocw.mit.edu/"><i class="fa-fw fas fa-link"></i><span> 来学麻学</span></a></li><li><a class="site-page child" href="/bangumis/"><i class="fa-fw fas fa-video"></i><span> zxrの追番计划</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=RyOyXsKuUgI"><i class="fa-fw fas fa-heart"></i><span> zxr最爱滴up嘉倩</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://oskarstalberg.com/game/planet/planet.html"><span> Planet</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链💕</span></a></div><div class="menus_item"><a class="site-page" href="https://xurui314.github.io/aboutme/"><span> AboutMe🏂</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.foreverblog.cn/go.html"><span> 虫洞</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Hey, this is why LSTM works!</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-03-13T14:19:27.000Z" title="Created 2023-03-13 22:19:27">2023-03-13</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-06-06T10:08:24.947Z" title="Updated 2023-06-06 18:08:24">2023-06-06</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Deep-Learning/">Deep Learning</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">4.5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>19min</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Hey, this is why LSTM works!"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><div class="top-img" style="background-image: url('https://i.pinimg.com/originals/eb/f4/3c/ebf43c10b242f73d8dfc5e4545ecc63e.jpg');"></div><article class="post-content" id="article-container"><h2 id="Introduction">Introduction</h2>
<p>首先谈一谈我对于神经网络结构改造的想法，其实和物理、化学这些理科不一样，很难说有什么支撑性的理论基础来引导模型的设计，深度学习更看重的是实际工程效果怎么样。据我所知对于文本和图像这种数据，人们还并没有那种完全式的掌握和理解，其实也是通过各种模型工具来窥知一二。所以深度学习的理论分析大多都是很泛的，因为针对某类具体问题压根没有对应的完备理论性知识。</p>
<p>深度学习的思维是针对已有模型的问题，通过引入一些归纳偏置（可能来源于数据的特性，可能来源于对模型的理解）来增加结构，去尝试work不work，如果确实有效再看看是不是真的符合预期假设的那样。所以这个过程更类似于engineer，而不是theory analysis。因此就会导致有些有效的网络模型看起来就感觉没有物理学中的美感，更像是各种naive idea和trick叠加的产物，研究的流程就是先跑个好结果然后再编个好故事，老是被其他专业诟病成炼丹。（摊手┑(￣-￣)┍）</p>
<p>平时接触最多的是把已有的网络模型魔改去解决具体问题，而设计一个全新的网络结构去解决一类问题看起来显然更有趣也是难度最大的，目前已有的网络大致可以分为MLP、CNN、RNN、Transformer、GNN、GAN、VAE 这几类，这篇blog将会详细讨论RNN中最具有代表性的LSTM网络设计。</p>
<p>不知道其他人有没有这种感觉，当接触除LSTM以外的模型时，学起来都感觉很自然，学LSTM的时候，就像进入了magical world一样（cmu经典配图meme），完全不觉得make sense，以至于我隔了一段时间没看网络结构，再回过头一看还是觉得很怪。每当我有这种感觉，我就知道是时候该和相应部分知识正义切割了，于是在搜集大量资料paper后，我将我的思考呈现在这篇博客中，不仅仅只是理解how lstm works，更是<strong>why</strong> lstm works。</p>
<h2 id="So-What’s-wrong-with-RNN">So What’s wrong with RNN?</h2>
<p>RNN是一个图灵完备模型，理论上是可以模拟任意可计算函数的，详细的解释可以看<a target="_blank" rel="noopener" href="https://stats.stackexchange.com/a/221142">(link)</a>，这和MLP是通用函数拟合器很类似，上限都是天花板，但是就训练不出那么好的效果。这主要是由两部分因素引起的：</p>
<ul>
<li>第一是采用BPTT的训练算法对于普通RNN梯度更新会出现问题</li>
<li>第二是模型没有特别针对时序任务的特性加结构，并不能很好的捕捉到特征，而且利用已有的梯度对参数更新时，会出现weight conflict，feature capture和memorization冲突的问题。</li>
</ul>
<p>关于第二点再来解释一下，RNN这个模型本身就是利用不断迭代来模拟时序，也就是把时序不同远近对于输出/参数更新的影响反映到了这种耦合了很多因素的过程中，实际这样没有明确结构设计的策略对于某些具体的任务表现还是很弱的。</p>
<blockquote>
<p>这里值得提一下的是，不显示的加结构还想获得足够好的效果，在实践中一般是不太可能的，cmu的教授也是这么说的。毕竟No Free Lunch :)</p>
</blockquote>
<h3 id="Vanishing-and-Exploding-Gradients">Vanishing and Exploding Gradients</h3>
<p>首先可以给出a mathematical proof of a sufficient condition for vanishing sensitivity in vanilla RNNs: <a target="_blank" rel="noopener" href="https://r2rt.com/written-memories-understanding-deriving-and-extending-the-lstm.html#a-mathematically-sufficient-condition-for-vanishing-sensitivity">(link)</a>，总结起来就是权重矩阵的二范数不能太小，由此可以引出一个weight initialization的技术，也是上面link中提到的，用来缓解一下梯度消失的问题。</p>
<p>对于DNN，梯度消失和爆炸作为反向传播链式法则的产物同样也会出现在RNN中，而RNN的shared parameter结构更加深了梯度更新的弊病，因为会出现weight conflict的现象，也就是序列前后对同一参数的更新作用可能是相反的，比如memory和forget操作。</p>
<p>对于梯度爆炸可以采用clip的方法，而梯度消失的解决方法则要困难得多，比较常用的方法是增加regularization term(batch norm等)，但是在RNN实际问题中我们并不希望梯度是一直受regularizer的限制，有时我们希望梯度表现为vanish或者increase，而仅仅利用regularization的效果也确实不是特别好。所以问题就变得tricky起来了。</p>
<h3 id="Information-morphing">Information morphing</h3>
<p>首先需要思考的是，在RNN中information morphing是被怎么定义的，我认为至少可以从两个角度来看，也就是forward和backward part。</p>
<p>在cmu的课上有对RNN进行stability analysis，同时也提到了RNN的记忆问题，也就是在forward的过程中，由于activation和weight的不断迭代，网络会逐渐遗忘input的信息，最后的输出表现为只和weight、activation相关，而不是和input相关。所以一个优化的思路是：既然如此干脆就直接不加weight和activation直接造一条memory line，然后针对不同的功能进行解耦，增加新的结构。</p>
<p>此外在cmu的课上，professor还强调tanh作为激活函数是可以memorize最久的，也就是Bipolar activation function，所以后面关于"write"信息增量的时候，采用的就是tanh函数。</p>
<p>在backward part中会出现经常听说的weight conflict现象，对不同方向的变化并不能很好分开处理，但在这里我更推荐看这篇论文的例子：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1903.00906.pdf">(link)</a>，比较直观反映由于模型本身的缺陷造成的information morphing。</p>
<h3 id="More-detail-explanation">More detail explanation</h3>
<p>上面说的一些概念可能看这篇博客的人会不熟，包括我自己后面大概率也会忘，所以这里来举个例子：</p>
<blockquote>
<p>引用 Quokka 大佬的回答，问题来源：<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/38338959/answer/765127031">(link)</a></p>
</blockquote>
<p>input weight conflict大概意思就是说普通的RNN无法长期保持信息。因为不同时间步里输入到隐层之间的变换矩阵是共享的（相同的），但是不同时间步的输入一般不同，所以对某个隐层神经元 j 来说，它不太可能在很多时间步里都保持激活的状态，所以就没法长期保存信息。</p>
<p>举个例子，假设我们想用RNN来检测引用（其实就是一个序列标注问题：输入一句话，把引号里的部分标记为正类，引号外的部分标记为负类），当遇到左引号时，某个神经元被激活，此后我们希望这个神经元一直能保持激活状态，因为它的激活可以告诉我们此时模型正在处理左引号后面的内容（也就是在引号里面）。但是因为每一个时间步都有输入，所以它的状态就会被这些输入影响，而左引号对它的影响慢慢减弱，相当于它“忘了”自己曾经遇到过一个左引号。</p>
<p>而如果使用LSTM的话，因为有一个 input gate 的存在，在左引号之后的输入都被 input gate 屏蔽掉，直到右引号出现才把 input gate 打开，写入新信息，熄灭这个神经元，从而输出状态就可以由这个神经元的状态直接对应得到（神经元点亮说明当前单词是被引用的话，熄灭说明当前单词不在引文里），实现准确的标注。</p>
<h2 id="Core-idea">Core idea</h2>
<p>大部分的教程都在强调从梯度的角度来改进RNN，并把这点当成work的根本原因。很显然这是很naive的想法，正确的思路是发现了RNN出现这种问题，并通过增加information invariant结构时考虑到gradient的传播问题。</p>
<p><strong>Core idea</strong>：模型需要做到具有information invariant的能力，同时也能根据输入的变化进行相应的调整，也就是我自己总结的如下两点：</p>
<ul>
<li>
<p>information invariant = invariant + selectivity</p>
</li>
<li>
<p>learning ability = valid gradient update</p>
</li>
</ul>
<p>第一点为了保持信息不变性，采取的策略是<strong>write</strong>，也就是增量机制：</p>
<blockquote>
<p><strong>The fundamental principle: Write it down.</strong></p>
<p>To ensure the integrity of our messages in the real world, we write them down. Writing is an incremental change that can be additive (pen on paper) or subtractive (carving in rock), and which remains unchanged absent outside interference. In LSTMs, everything is written down and, assuming no interference from other state units or external inputs, carries its prior state forward.</p>
<p>Practically speaking, this means that any state changes are incremental, so that <img src="https://math.now.sh?inline=s_%7Bt%20%2B%201%7D%20%3D%20s_t%20%2B%20%5CDelta%20s_%7Bt%2B1%7D" style="display:inline-block;margin: 0;"></p>
</blockquote>
<p>但是在实际的问题中，仅仅是把所有变化以增量的方式记录也是不够的：</p>
<blockquote>
<p><strong>The fundamental challenge: Uncontrolled and uncoordinated writing.</strong></p>
<p>Uncontrolled and uncoordinated writes, particularly at the start of training when writes are completely random, create a chaotic state that leads to bad results and from which it can be difficult to recover.</p>
</blockquote>
<p>事实证明效果也确实不好，因为我们想要模型做到对于输入和state传递的信息有特征选择和记忆保持的功能，但实际还是会出现“input weight conflict”, “output weight conflict”, the “abuse problem”, and “internal state drift”这几个问题（这几个术语来自lstm原始论文<a target="_blank" rel="noopener" href="https://readpaper.com/paper/2064675550">(link)</a>），下面我搬了原论文的解释。</p>
<p><strong>Input weight conflict</strong>: For simplicity, let us focus on a single additional input weight <img src="https://math.now.sh?inline=w_%7Bji%7D" style="display:inline-block;margin: 0;">. Assume that the total error can be reduced by switching on unit j in response to a certain input and keeping it active for a long time (until it helps to compute a desired output). Provided i is nonzero, since the same incoming weight has to be used for <strong>both storing certain inputs and ignoring others</strong>, <img src="https://math.now.sh?inline=w_%7Bji%7D" style="display:inline-block;margin: 0;"> will often receive conflicting weight update signals during this time (recall that j is linear). These signals will attempt to make <img src="https://math.now.sh?inline=w_%7Bji%7D" style="display:inline-block;margin: 0;"> participate in (1) storing the input (by switching on j) and (2) protecting the input (by preventing j from being switched off by irrelevant later inputs). This conflict makes learning difficult and calls for a more context-sensitive mechanism for controlling write operations through input weights.</p>
<p><strong>Output weight conflict</strong>: Assume j is switched on and currently stores some previous input. For simplicity, let us focus on a single additional outgoing weight <img src="https://math.now.sh?inline=w_%7Bkj%7D" style="display:inline-block;margin: 0;">. The same <img src="https://math.now.sh?inline=w_%7Bkj%7D" style="display:inline-block;margin: 0;"> has to be used for <strong>both retrieving j’s content at certain times and preventing j from disturbing k at other times</strong>. As long as unit j is nonzero, <img src="https://math.now.sh?inline=w_%7Bkj%7D" style="display:inline-block;margin: 0;"> will attract conflicting weight update signals generated during sequence processing. These signals will attempt to make <img src="https://math.now.sh?inline=w_%7Bkj%7D" style="display:inline-block;margin: 0;"> participate in accessing the information stored in j and—at different times—protecting unit k from being perturbed by j. For instance, with many tasks there are certain short time-lag errors that can be reduced in early training stages. However,at later training stages, j may suddenly start to cause avoidable errors in situations that already seemed under control by attempting to participate in reducing more difficult long-time-lag errors. Again, this conflict makes learning difficult and calls for a more context-sensitive mechanism for controlling read operations through output weights.</p>
<p>Input and output weight conflicts are not specific for long time lags; they occur for short time lags as well. Their effects, however, become particularly pronounced in the long-time-lag case. As the time lag increases, stored information must be protected against perturbation for longer and longer periods, and, especially in advanced stages of learning, more and more already correct outputs also require protection against perturbation</p>
<p>所以采取的策略是把不同的功能解耦，通过加入新的结构来解决这个冲突问题，也就是下文将详细介绍的具有选择性的门机制。</p>
<blockquote>
<p>先要获得更多insights，可以看这篇文章：RNN 中学习长期依赖的三种机制 - Quokka的文章 - 知乎 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/34490114">https://zhuanlan.zhihu.com/p/34490114</a></p>
</blockquote>
<h2 id="Building-up-LSTM">Building up LSTM</h2>
<blockquote>
<p>Cambridge按照原始论文的思路整理的很好的PPT：<a target="_blank" rel="noopener" href="http://cbl.eng.cam.ac.uk/pub/Intranet/MLG/ReadingGroup/DLTS_DavidZ.pdf">(link)</a></p>
</blockquote>
<h2 id="Math-of-LSTM">Math of LSTM</h2>
<p>主要介绍Backprop的part，比较好的资料推荐：<a target="_blank" rel="noopener" href="https://datascience.stackexchange.com/q/19614">(link 1)</a>，<a target="_blank" rel="noopener" href="https://blog.aidangomez.ca/2016/04/17/Backpropogating-an-LSTM-A-Numerical-Example/">(link 2)</a> 以及cmu 21年的lecture <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=cVX2bLvP6mI&amp;list=PLp-0K3kfddPxQw7-vYNu4OG9vLu3qBw4t&amp;index=16">(link)</a></p>
<p>此外就是为什么LSTM通过门机制能解决梯度消失的问题：<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/34878706/answer/665429718">(link)</a> and <a target="_blank" rel="noopener" href="https://weberna.github.io/blog/2017/11/15/LSTM-Vanishing-Gradients.html">(link)</a></p>
<h2 id="Explanation">Explanation</h2>
<p>对于模型的表达能力，要从两方面去看：理论上分析和实际的效果。</p>
<h3 id="Theory-Explanation">Theory Explanation</h3>
<p>我们聚焦于Gate机制的表达能力，</p>
<blockquote>
<p>暂时没找到很好的资料，鸽一会</p>
</blockquote>
<p>word -&gt; 信号？</p>
<h3 id="Experiments-Explanation">Experiments Explanation</h3>
<p>我想强调的是即使上面我们分析并构建LSTM的idea都很合理，那也是先经过实验不断尝试得到的结果，不仅仅靠理论上的intuition，此外还需验证结果确实符合我们的假设。</p>
<p>首先介绍一个toy example，是李宏毅老师的，大概在28分钟的时候：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1GF411M7ua/?spm_id_from=333.337.search-card.all.click&amp;vd_source=78821760a099022a284c04eeb639e1ae">(link)</a></p>
<p>其次是Harvard nlp组的LSTM可视化工作：<a target="_blank" rel="noopener" href="https://lstmvis.vizhub.ai/">(link)</a>，中文解释：<a target="_blank" rel="noopener" href="http://vis.pku.edu.cn/blog/lstmvis/">(link)</a></p>
<p>以及Inner-process visualization of hidden states in recurrent neural networks <a target="_blank" rel="noopener" href="https://vciba.springeropen.com/articles/10.1186/s42492-021-00090-0">(link)</a> or <a target="_blank" rel="noopener" href="https://dl.acm.org/doi/pdf/10.1145/3430036.3430047">(link)</a></p>
<p>此外补充关于RNN解释的工作：<a target="_blank" rel="noopener" href="http://162.243.131.178/projects/rnnvis/">(link)</a> and <a target="_blank" rel="noopener" href="https://blog.acolyer.org/2019/02/25/understanding-hidden-memories-of-recurrent-neural-networks/">(link)</a></p>
<h2 id="Improvements">Improvements</h2>
<p>介绍一下LSTM变体的改进思路。</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/34500721">https://zhuanlan.zhihu.com/p/34500721</a></p>
<h2 id="Code-of-GRU">Code of GRU</h2>
<blockquote>
<p>来自CMU的hw，给出的是GRU的例子，LSTM类似：</p>
</blockquote>
<p>值得说明的是，博客介绍反向传播的部分虽然是给出了完整的数学推导，但是实际写代码的时候还是采取了迭代的策略，没有复杂的公式，只有精简的逻辑。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> activation <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GRUCell</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">"""GRU Cell class."""</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_dim, hidden_dim</span>):</span></span><br><span class="line">        self.d = in_dim</span><br><span class="line">        self.h = hidden_dim</span><br><span class="line">        h = self.h</span><br><span class="line">        d = self.d</span><br><span class="line">        self.x_t = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        self.r = np.zeros((h, ))</span><br><span class="line">        self.z = np.zeros((h, ))</span><br><span class="line">        self.n = np.zeros((h, ))</span><br><span class="line"></span><br><span class="line">        self.Wrx = np.random.randn(h, d)</span><br><span class="line">        self.Wzx = np.random.randn(h, d)</span><br><span class="line">        self.Wnx = np.random.randn(h, d)</span><br><span class="line"></span><br><span class="line">        self.Wrh = np.random.randn(h, h)</span><br><span class="line">        self.Wzh = np.random.randn(h, h)</span><br><span class="line">        self.Wnh = np.random.randn(h, h)</span><br><span class="line"></span><br><span class="line">        self.brx = np.random.randn(h)</span><br><span class="line">        self.bzx = np.random.randn(h)</span><br><span class="line">        self.bnx = np.random.randn(h)</span><br><span class="line"></span><br><span class="line">        self.brh = np.random.randn(h)</span><br><span class="line">        self.bzh = np.random.randn(h)</span><br><span class="line">        self.bnh = np.random.randn(h)</span><br><span class="line"></span><br><span class="line">        self.dWrx = np.zeros((h, d))</span><br><span class="line">        self.dWzx = np.zeros((h, d))</span><br><span class="line">        self.dWnx = np.zeros((h, d))</span><br><span class="line"></span><br><span class="line">        self.dWrh = np.zeros((h, h))</span><br><span class="line">        self.dWzh = np.zeros((h, h))</span><br><span class="line">        self.dWnh = np.zeros((h, h))</span><br><span class="line">        </span><br><span class="line">        self.dr = np.zeros((h))</span><br><span class="line">        self.dz = np.zeros((h))</span><br><span class="line">        self.dn = np.zeros((h))</span><br><span class="line"></span><br><span class="line">        self.dbrx = np.zeros((h))</span><br><span class="line">        self.dbzx = np.zeros((h))</span><br><span class="line">        self.dbnx = np.zeros((h))</span><br><span class="line"></span><br><span class="line">        self.dbrh = np.zeros((h))</span><br><span class="line">        self.dbzh = np.zeros((h))</span><br><span class="line">        self.dbnh = np.zeros((h))</span><br><span class="line"></span><br><span class="line">        self.r_act = Sigmoid()</span><br><span class="line">        self.z_act = Sigmoid()</span><br><span class="line">        self.h_act = Tanh()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Define other variables to store forward results for backward here</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_weights</span>(<span class="params">self, Wrx, Wzx, Wnx, Wrh, Wzh, Wnh, brx, bzx, bnx, brh, bzh, bnh</span>):</span></span><br><span class="line">        self.Wrx = Wrx</span><br><span class="line">        self.Wzx = Wzx</span><br><span class="line">        self.Wnx = Wnx</span><br><span class="line">        self.Wrh = Wrh</span><br><span class="line">        self.Wzh = Wzh</span><br><span class="line">        self.Wnh = Wnh</span><br><span class="line">        self.brx = brx</span><br><span class="line">        self.bzx = bzx</span><br><span class="line">        self.bnx = bnx</span><br><span class="line">        self.brh = brh</span><br><span class="line">        self.bzh = bzh</span><br><span class="line">        self.bnh = bnh</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, x, h_prev_t</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.forward(x, h_prev_t)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, h_prev_t</span>):</span></span><br><span class="line">        <span class="string">"""GRU cell forward.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Input</span></span><br><span class="line"><span class="string">        -----</span></span><br><span class="line"><span class="string">        x: (input_dim)</span></span><br><span class="line"><span class="string">            observation at current time-step.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        h_prev_t: (hidden_dim)</span></span><br><span class="line"><span class="string">            hidden-state at previous time-step.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        h_t: (hidden_dim)</span></span><br><span class="line"><span class="string">            hidden state at current time-step.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.x = x</span><br><span class="line">        self.hidden = h_prev_t</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Add your code here.</span></span><br><span class="line">        <span class="comment"># Define your variables based on the writeup using the corresponding</span></span><br><span class="line">        <span class="comment"># names below.</span></span><br><span class="line"></span><br><span class="line">        self.r = self.r_act(self.Wrx @ x + self.brx + self.Wrh @ h_prev_t + self.brh).reshape(self.h, )</span><br><span class="line">        self.z = self.z_act(self.Wzx @ x + self.bzx + self.Wzh @ h_prev_t + self.bzh).reshape(self.h, )</span><br><span class="line">        self.n = self.h_act(self.Wnx @ x + self.bnx + self.r * (self.Wnh @ h_prev_t + self.bnh) ).reshape(self.h, )</span><br><span class="line">        h_t = (<span class="number">1</span> - self.z) * self.n + self.z * h_prev_t</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        <span class="keyword">assert</span> self.x.shape == (self.d,)</span><br><span class="line">        <span class="keyword">assert</span> self.hidden.shape == (self.h,)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> self.r.shape == (self.h,)</span><br><span class="line">        <span class="keyword">assert</span> self.z.shape == (self.h,)</span><br><span class="line">        <span class="keyword">assert</span> self.n.shape == (self.h,)</span><br><span class="line">        <span class="keyword">assert</span> h_t.shape == (self.h,) <span class="comment"># h_t is the final output of you GRU cell.</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> h_t</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">self, delta</span>):</span></span><br><span class="line">        <span class="string">"""GRU cell backward.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        This must calculate the gradients wrt the parameters and return the</span></span><br><span class="line"><span class="string">        derivative wrt the inputs, xt and ht, to the cell.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Input</span></span><br><span class="line"><span class="string">        -----</span></span><br><span class="line"><span class="string">        delta: (hidden_dim)</span></span><br><span class="line"><span class="string">                summation of derivative wrt loss from next layer at</span></span><br><span class="line"><span class="string">                the same time-step and derivative wrt loss from same layer at</span></span><br><span class="line"><span class="string">                next time-step.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        dx: (1, input_dim)</span></span><br><span class="line"><span class="string">            derivative of the loss wrt the input x.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        dh_prev_t: (1, hidden_dim)</span></span><br><span class="line"><span class="string">            derivative of the loss wrt the input hidden h.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 1) Reshape self.x and self.hidden to (input_dim, 1) and (hidden_dim, 1) respectively</span></span><br><span class="line">        <span class="comment">#    when computing self.dWs...</span></span><br><span class="line">        <span class="comment"># 2) Transpose all calculated dWs...</span></span><br><span class="line">        <span class="comment"># 3) Compute all of the derivatives</span></span><br><span class="line">        <span class="comment"># 4) Know that the autograder grades the gradients in a certain order, and the</span></span><br><span class="line">        <span class="comment">#    local autograder will tell you which gradient you are currently failing.</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># ADDITIONAL TIP:</span></span><br><span class="line">        <span class="comment"># Make sure the shapes of the calcu</span></span><br><span class="line">        <span class="comment"># lated dWs and dbs  match the</span></span><br><span class="line">        <span class="comment"># initalized shapes accordingly</span></span><br><span class="line"></span><br><span class="line">        self.dz = (-delta * self.n + delta * self.hidden).reshape(-<span class="number">1</span>, )</span><br><span class="line">        self.dn = (delta * (<span class="number">1</span> - self.z)).reshape(-<span class="number">1</span>, )</span><br><span class="line">        self.dr = self.dn * self.h_act.backward() * (self.Wnh @ self.hidden + self.bnh)</span><br><span class="line"></span><br><span class="line">        self.dbzh += self.dz * self.z_act.backward()</span><br><span class="line">        self.dbzx += self.dz * self.z_act.backward()</span><br><span class="line"></span><br><span class="line">        self.dWzh += (self.dz * self.z_act.backward()).reshape(-<span class="number">1</span>, <span class="number">1</span>) @ self.hidden.reshape(<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">        self.dWzx += (self.dz * self.z_act.backward()) .reshape(-<span class="number">1</span>, <span class="number">1</span>)  @ self.x.reshape(<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.dbnh += self.dn * self.h_act.backward() * self.r</span><br><span class="line">        self.dbnx += self.dn * self.h_act.backward()</span><br><span class="line"></span><br><span class="line">        self.dWnh += (self.dn * self.h_act.backward() * self.r).reshape(-<span class="number">1</span>, <span class="number">1</span>) @ self.hidden.reshape(<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">        self.dWnx += (self.dn * self.h_act.backward()).reshape(-<span class="number">1</span>, <span class="number">1</span>) @ self.x.reshape(<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.dbrh += self.dr * self.r_act.backward()</span><br><span class="line">        self.dbrx += self.dr * self.r_act.backward()</span><br><span class="line"></span><br><span class="line">        self.dWrh += (self.dr * self.r_act.backward()).reshape(-<span class="number">1</span>, <span class="number">1</span>) @ self.hidden.reshape(<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">        self.dWrx += (self.dr * self.r_act.backward()).reshape(-<span class="number">1</span>, <span class="number">1</span>)  @ self.x.reshape(<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        dx =  self.Wrx.T @ (self.r_act.backward() * self.dr) + \</span><br><span class="line">        self.Wzx.T @ (self.z_act.backward() * self.dz) + \</span><br><span class="line">        self.Wnx.T @ (self.h_act.backward() * self.dn)</span><br><span class="line"></span><br><span class="line">        dh_prev_t = self.Wrh.T @ (self.r_act.backward() * self.dr) + \</span><br><span class="line">        self.Wzh.T @ (self.z_act.backward() * self.dz) + \</span><br><span class="line">        self.Wnh.T @ (self.r * self.h_act.backward() * self.dn) + \</span><br><span class="line">        delta * self.z</span><br><span class="line">        </span><br><span class="line">        dx = dx.reshape(<span class="number">1</span>, self.d)</span><br><span class="line">        dh_prev_t = dh_prev_t.reshape(<span class="number">1</span>, self.h)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">assert</span> dx.shape == (<span class="number">1</span>, self.d)</span><br><span class="line">        <span class="keyword">assert</span> dh_prev_t.shape == (<span class="number">1</span>, self.h)</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> dx, dh_prev_t</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<p>再贴一个GRU使用的案例：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">sys.path.append(<span class="string">"mytorch"</span>)</span><br><span class="line"><span class="keyword">from</span> gru_cell <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> linear <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CharacterPredictor</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">"""CharacterPredictor class.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    This is the neural net that will run one timestep of the input</span></span><br><span class="line"><span class="string">    You only need to implement the forward method of this class.</span></span><br><span class="line"><span class="string">    This is to test that your GRU Cell implementation is correct when used as a GRU.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, input_dim, hidden_dim, num_classes</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(CharacterPredictor, self).__init__()</span><br><span class="line">        <span class="string">"""The network consists of a GRU Cell and a linear layer."""</span></span><br><span class="line">        self.rnn = GRUCell(input_dim, hidden_dim) <span class="comment"># TODO</span></span><br><span class="line">        self.projection = Linear(hidden_dim, num_classes) <span class="comment"># TODO</span></span><br><span class="line">        self.projection.W = np.random.rand(num_classes, hidden_dim)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_rnn_weights</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self, Wrx, Wzx, Wnx, Wrh, Wzh, Wnh, brx, bzx, bnx, brh, bzh, bnh</span></span></span><br><span class="line"><span class="params"><span class="function">    </span>):</span></span><br><span class="line">        <span class="comment"># DO NOT MODIFY</span></span><br><span class="line">        self.rnn.init_weights(</span><br><span class="line">            Wrx, Wzx, Wnx, Wrh, Wzh, Wnh, brx, bzx, bnx, brh, bzh, bnh</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, x, h</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.forward(x, h)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, h</span>):</span></span><br><span class="line">        <span class="string">"""CharacterPredictor forward.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        A pass through one time step of the input</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Input</span></span><br><span class="line"><span class="string">        -----</span></span><br><span class="line"><span class="string">        x: (feature_dim)</span></span><br><span class="line"><span class="string">            observation at current time-step.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        h: (hidden_dim)</span></span><br><span class="line"><span class="string">            hidden-state at previous time-step.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        logits: (num_classes)</span></span><br><span class="line"><span class="string">            hidden state at current time-step.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        hnext: (hidden_dim)</span></span><br><span class="line"><span class="string">            hidden state at current time-step.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        hnext = self.rnn.forward(x, h) <span class="comment"># TODO</span></span><br><span class="line">        <span class="comment"># self.projection expects input in the form of batch_size * input_dimension</span></span><br><span class="line">        <span class="comment"># Therefore, reshape the input of self.projection as (1,-1)</span></span><br><span class="line">        logits = self.projection.forward(hnext.reshape(<span class="number">1</span>, -<span class="number">1</span>)) <span class="comment"># TODO</span></span><br><span class="line">        logits = logits.reshape(-<span class="number">1</span>,) <span class="comment"># uncomment once code implemented</span></span><br><span class="line">        <span class="keyword">return</span> logits, hnext</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inference</span>(<span class="params">net, inputs</span>):</span></span><br><span class="line">    <span class="string">"""CharacterPredictor inference.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    An instance of the class defined above runs through a sequence of inputs to</span></span><br><span class="line"><span class="string">    generate the logits for all the timesteps.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Input</span></span><br><span class="line"><span class="string">    -----</span></span><br><span class="line"><span class="string">    net:</span></span><br><span class="line"><span class="string">        An instance of CharacterPredictor.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    inputs: (seq_len, feature_dim)</span></span><br><span class="line"><span class="string">            a sequence of inputs of dimensions.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">    logits: (seq_len, num_classes)</span></span><br><span class="line"><span class="string">            one per time step of input..</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># This code should not take more than 10 lines. </span></span><br><span class="line">    logits = []</span><br><span class="line">    inputs = np.array(inputs)</span><br><span class="line">    hidden = np.zeros((net.rnn.h))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(inputs.shape[<span class="number">0</span>]):</span><br><span class="line">        logit, hidden = net.forward(inputs[i], hidden)</span><br><span class="line">        logits.append(logit)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> np.array(logits)</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h2 id="Reference">Reference</h2>
<p>cmu 11-785</p>
<p>知乎很多大佬的回答</p>
<p><a target="_blank" rel="noopener" href="https://r2rt.com/written-memories-understanding-deriving-and-extending-the-lstm.html">https://r2rt.com/written-memories-understanding-deriving-and-extending-the-lstm.html</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">zxr</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://xurui314.github.io/2023/03/13/Hey-this-is-why-LSTM-works/">https://xurui314.github.io/2023/03/13/Hey-this-is-why-LSTM-works/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Deep-Learning/">Deep Learning</a></div><div class="post_share"><div class="social-share" data-image="https://i.pinimg.com/originals/eb/f4/3c/ebf43c10b242f73d8dfc5e4545ecc63e.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer=""></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/03/17/%E9%A3%9E%E6%A1%A8%E5%AD%A6%E4%B9%A0%E8%B5%9B%EF%BC%9A%E4%BA%A7%E5%93%81%E8%AF%84%E8%AE%BA%E8%A7%82%E7%82%B9%E6%8F%90%E5%8F%96/"><img class="prev-cover" src="https://pic1.zhimg.com/v2-1583bb0421d71bf07ed0897f4186da82_xl.jpg?source=32738c0c" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">飞桨学习赛：产品评论观点提取</div></div></a></div><div class="next-post pull-right"><a href="/2023/03/13/2023-deep-learning/"><img class="next-cover" src="https://www.csail.mit.edu/sites/default/files/2017-08/15473005358_576e646680_o.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">2023 deep learning</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2023/03/13/2023-deep-learning/" title="2023 deep learning"><img class="cover" src="https://www.csail.mit.edu/sites/default/files/2017-08/15473005358_576e646680_o.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-13</div><div class="title">2023 deep learning</div></div></a></div><div><a href="/2023/05/13/Contrastive-Learning-in-Multimodal/" title="Contrastive Learning in Multimodal"><img class="cover" src="https://cdn.jsdelivr.net/gh/wdm1732418365/CDN/New%20folder/daydream%20(11).png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-05-13</div><div class="title">Contrastive Learning in Multimodal</div></div></a></div><div><a href="/2023/03/03/HW1P2/" title="HW1P2"><img class="cover" src="https://s2.loli.net/2023/03/03/gFraLwmNBfkz9Dy.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-03</div><div class="title">HW1P2</div></div></a></div><div><a href="/2023/01/14/HW2P1/" title="HW2P1"><img class="cover" src="https://s2.loli.net/2023/01/14/wlGYSmRduNIpHCc.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-14</div><div class="title">HW2P1</div></div></a></div><div><a href="/2023/03/08/HW3P1/" title="HW3P1"><img class="cover" src="https://s2.loli.net/2023/03/08/CSvgBbyca1RNiEF.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-08</div><div class="title">HW3P1</div></div></a></div><div><a href="/2023/04/13/HW4P1/" title="HW4P1"><img class="cover" src="https://pbs.twimg.com/media/FHtPhbzXMAcEyGE.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-04-13</div><div class="title">HW4P1</div></div></a></div></div></div><hr><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div><div id="comment-switch"><span class="first-comment">Valine</span><span class="switch-btn"></span><span class="second-comment">Disqus</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div><div><div id="disqus_thread"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://s2.loli.net/2021/12/08/yTYthVwXD4IPbJ9.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"></div><div class="author-info__name">zxr</div><div class="author-info__description">Think and Do like an MIT student</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">80</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">35</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">16</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/XuRui314"><i class="fab fa-github"></i><span>This is zxr!🚀</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/XuRui314" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://mail.qq.com/" target="_blank" title="Email-1977289398@qq.com"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">zxr的生活，math，编程记录,<div class="twopeople"><div class="container" style="height:200px;"><canvas class="illo" width="800" height="800" style="max-width: 200px; max-height: 200px; touch-action: none; width: 640px; height: 640px;"></canvas></div><script src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/js/twopeople1.js"></script><script src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/js/zdog.dist.js"></script><script id="rendered-js" src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/js/twopeople.js"></script><style>.twopeople{margin: 0;align-items: center;justify-content: center;text-align: center;}canvas{display: block;margin: 0 auto;cursor: move;}</style></div><div class="twopeople"></div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduction"><span class="toc-number">1.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#So-What%E2%80%99s-wrong-with-RNN"><span class="toc-number">2.</span> <span class="toc-text">So What’s wrong with RNN?</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Vanishing-and-Exploding-Gradients"><span class="toc-number">2.1.</span> <span class="toc-text">Vanishing and Exploding Gradients</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Information-morphing"><span class="toc-number">2.2.</span> <span class="toc-text">Information morphing</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#More-detail-explanation"><span class="toc-number">2.3.</span> <span class="toc-text">More detail explanation</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Core-idea"><span class="toc-number">3.</span> <span class="toc-text">Core idea</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Building-up-LSTM"><span class="toc-number">4.</span> <span class="toc-text">Building up LSTM</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Math-of-LSTM"><span class="toc-number">5.</span> <span class="toc-text">Math of LSTM</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Explanation"><span class="toc-number">6.</span> <span class="toc-text">Explanation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Theory-Explanation"><span class="toc-number">6.1.</span> <span class="toc-text">Theory Explanation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Experiments-Explanation"><span class="toc-number">6.2.</span> <span class="toc-text">Experiments Explanation</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Improvements"><span class="toc-number">7.</span> <span class="toc-text">Improvements</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Code-of-GRU"><span class="toc-number">8.</span> <span class="toc-text">Code of GRU</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reference"><span class="toc-number">9.</span> <span class="toc-text">Reference</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/07/07/Stable-Diffusion/" title="Stable Diffusion"><img src="https://scholar.harvard.edu/sites/scholar.harvard.edu/files/styles/os_files_xxlarge/public/binxuw/files/stablediffusion_overview.jpg?m=1667438590&amp;itok=n2gM0Xba" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Stable Diffusion"></a><div class="content"><a class="title" href="/2023/07/07/Stable-Diffusion/" title="Stable Diffusion">Stable Diffusion</a><time datetime="2023-07-07T14:31:01.000Z" title="Created 2023-07-07 22:31:01">2023-07-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/07/01/2023-7-1/" title="2023/7/1"><img src="https://www.tsinghua.edu.cn/__local/3/D6/43/55D1EDFDEEAC5CC4720BCF830F2_6E1BFFB2_C4429.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2023/7/1"></a><div class="content"><a class="title" href="/2023/07/01/2023-7-1/" title="2023/7/1">2023/7/1</a><time datetime="2023-07-01T06:01:07.000Z" title="Created 2023-07-01 14:01:07">2023-07-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/07/01/Diffusion-%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F/" title="Diffusion 从入门到入土"><img src="https://theaisummer.com/static/d007d60f773b61f4585cbec3869490d5/a878e/score-sde.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Diffusion 从入门到入土"></a><div class="content"><a class="title" href="/2023/07/01/Diffusion-%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F/" title="Diffusion 从入门到入土">Diffusion 从入门到入土</a><time datetime="2023-07-01T06:00:32.000Z" title="Created 2023-07-01 14:00:32">2023-07-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/06/25/MiniGPT-4/" title="MiniGPT-4"><img src="https://raw.githubusercontent.com/vision-cair/minigpt-4/master/figs/online_demo.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MiniGPT-4"></a><div class="content"><a class="title" href="/2023/06/25/MiniGPT-4/" title="MiniGPT-4">MiniGPT-4</a><time datetime="2023-06-25T11:14:25.000Z" title="Created 2023-06-25 19:14:25">2023-06-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/13/Multimodel-Pretrained-Model/" title="Multimodel Pretrained Model"><img src="https://cdn.jsdelivr.net/gh/wdm1732418365/CDN/New%20folder/daydream%20(1).png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Multimodel Pretrained Model"></a><div class="content"><a class="title" href="/2023/05/13/Multimodel-Pretrained-Model/" title="Multimodel Pretrained Model">Multimodel Pretrained Model</a><time datetime="2023-05-13T14:39:00.000Z" title="Created 2023-05-13 22:39:00">2023-05-13</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">©2020 - 2023 By zxr</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="github-badge"><a style="color: #fff" rel="license" href="https://hexo.io/" target="_blank" title="由 Hexo 强力驱动"><span class="badge-subject">Powered</span><span class="badge-value bg-blue">Hexo</span></a><a style="color: #fff" rel="license" href="https://gitee.com/" target="_blank" title="静态网页托管于 GitHub Pages 和 Coding Pages 和 Gitee Pages"><span class="badge-subject">Hosted</span><span class="badge-value bg-brightgreen">GitHub &amp; Coding &amp; Gitee</span></a><a style="color: #fff" rel="license" href="https://www.jsdelivr.com/" target="_blank" title="jsDelivr 提供 CDN 加速服务"><span class="badge-subject">CDN</span><span class="badge-value bg-orange">jsDelivr</span></a><a style="color: #fff" rel="license" href="https://jerryc.me" target="_blank" title="站点使用 Butterfly主题"><span class="badge-subject">Theme</span><span class="badge-value bg-blue">Butterfly</span></a><a style="color: #fff" rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" title="本站点采用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议进行许可"><span class="badge-subject"><i class="fa fa-copyright"></i></span><span class="badge-value bg-lightgrey">BY-NC-SA 4.0  </span></a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="Increase font size"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="Decrease font size"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = '[object Object]'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: '',
      appKey: '',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script>function loadDisqus () {
  var disqus_config = function () {
    this.page.url = 'https://xurui314.github.io/2023/03/13/Hey-this-is-why-LSTM-works/'
    this.page.identifier = '2023/03/13/Hey-this-is-why-LSTM-works/'
    this.page.title = 'Hey, this is why LSTM works!'
  };

  window.disqusReset = () => {
    DISQUS.reset({
      reload: true,
      config: disqus_config
    })
  }

  if (window.DISQUS) disqusReset()
  else {
    (function() { 
      var d = document, s = d.createElement('script');
      s.src = 'https://.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  }
}

if ('Valine' === 'Disqus' || !false) {
  if (false) btf.loadComment(document.getElementById('disqus_thread'), loadDisqus)
  else loadDisqus()
} else {
  function loadOtherComment () {
    loadDisqus()
  }
}
</script></div><script src="https://cdn.jsdelivr.net/gh/XuRui314/live2d-widget@1.0.1/autoload.js"></script><script src="/js/title.js"></script><script src="/dist/nochocolate.js"></script><div id="aplayer"></div><script type="text/javascript" src="/dist/APlayer.min.js"></script><script type="text/javascript" src="/dist/music.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/gh/metowolf/MetingJS@1.2/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = [
  'title',
  '#config-diff',
  '#body-wrap',
  '#rightside-config-hide',
  '#rightside-config-show',
  '.js-pjax'
]

if (false) {
  pjaxSelectors.unshift('meta[property="og:image"]', 'meta[property="og:title"]', 'meta[property="og:url"]')
}

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.removeEventListener('scroll', window.tocScrollFn)
  window.removeEventListener('scroll', scrollCollect)

  typeof preloader === 'object' && preloader.initLoading()
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // Analytics
  if (false) {
    MtaH5.pgv()
  }

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async="" data-pjax="" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax="">if(document.getElementById('recent-posts') && (location.pathname ==='all'|| 'all' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/Math/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 zxrの数学世界 (12)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/算法学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 zxrの算法学习 (6)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/生活趣闻/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱‍👓 zxrの生活趣闻 (4)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/编程实例/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">👩‍💻 zxrの编程学习 (4)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/生活感悟/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🚴‍♂ zxrの生活感悟 (11)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/Hexo/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">💌 zxrのBlog记录 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="https://XuRui314.github.io/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style> <script data-pjax="">if(document.getElementById('recent-posts') && location.pathname =='/'){
    
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/09/17/9H5WSbTrVejOdkz.jpg" alt="https://i.loli.net/2021/09/17/9H5WSbTrVejOdkz.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-09-17</span><a class="blog-slider__title" href="2021/09/17/概率和测度/">概率和测度(ZJU大佬)</a><div class="blog-slider__text">来看看ZJU计科大佬解释概率和测度🥙</div><a class="blog-slider__button" href="2021/09/17/概率和测度/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/25/bPy5m3j9QAilwr2.jpg" alt="https://i.loli.net/2021/08/25/bPy5m3j9QAilwr2.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-08-26</span><a class="blog-slider__title" href="2021/08/26/算法题目练习/">AcWing-Oj-刷题学习记录(基础算法)</a><div class="blog-slider__text">来看算法蒟蒻的丢人日常啊👩‍🦽</div><a class="blog-slider__button" href="2021/08/26/算法题目练习/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/15/NYcSXrECnvzOiLP.jpg" alt="https://i.loli.net/2021/08/15/NYcSXrECnvzOiLP.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-08-15</span><a class="blog-slider__title" href="2021/08/15/两层神经网络识别手写数字/">两层神经网络识别手写数字</a><div class="blog-slider__text">识别手写数字最简单的实现🧦</div><a class="blog-slider__button" href="2021/08/15/两层神经网络识别手写数字/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/15/F8aP7R36IidpCt5.jpg" alt="https://i.loli.net/2021/08/15/F8aP7R36IidpCt5.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-08-14</span><a class="blog-slider__title" href="2021/08/14/神经网络搭建准备内容/">神经网络搭建准备内容</a><div class="blog-slider__text">如何识别手写🔢，zxr带你一步一步实现🎼</div><a class="blog-slider__button" href="2021/08/14/神经网络搭建准备内容/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/12/SJs3MgYC7x8IU26.jpg" alt="https://i.loli.net/2021/08/12/SJs3MgYC7x8IU26.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-08-12</span><a class="blog-slider__title" href="2021/08/12/xuperchain-solidity/">xuperchain&solidity</a><div class="blog-slider__text">区块链不止是挖币，还有v神和solidity🎈</div><a class="blog-slider__button" href="2021/08/12/xuperchain-solidity/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/07/27/6fy8mTCbAOWPkrq.png" alt="https://i.loli.net/2021/07/27/6fy8mTCbAOWPkrq.png"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-07-26</span><a class="blog-slider__title" href="2021/07/26/FFT/">FFT的详解</a><div class="blog-slider__text">这么好看的FFT，信号狗都馋哭了💦</div><a class="blog-slider__button" href="2021/07/26/FFT/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/09/zdt4YKoehQvR96S.jpg" alt="https://i.loli.net/2021/08/09/zdt4YKoehQvR96S.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-08-09</span><a class="blog-slider__title" href="2021/08/09/炒鸡好理解的测度论/">炒鸡好理解的测度论</a><div class="blog-slider__text">三段字，让你读懂测度论</div><a class="blog-slider__button" href="2021/08/09/炒鸡好理解的测度论/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/12/wF7TJlqxOLEWGQk.png" alt="https://i.loli.net/2021/08/12/wF7TJlqxOLEWGQk.png"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-07-27</span><a class="blog-slider__title" href="2021/07/27/FT/">傅里叶学习资料</a><div class="blog-slider__text">简单好学的傅里叶学习资料</div><a class="blog-slider__button" href="2021/07/27/FT/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/07/27/f7jO8hlNpzWVXSP.jpg" alt="https://i.loli.net/2021/07/27/f7jO8hlNpzWVXSP.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-07-26</span><a class="blog-slider__title" href="2021/07/26/hello-world/">大鸟转转转酒吧内部绝密档案</a><div class="blog-slider__text">不要点进来QAQ！</div><a class="blog-slider__button" href="2021/07/26/hello-world/">详情</a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载swiper')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script>
<script data-pjax="" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper/swiper/swiper.min.js"></script>
<script data-pjax="" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper@0.18/swiper/swiperindex.js"></script>
<style></style><script data-pjax="">function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax="" src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script>
  <script data-pjax="" src="https://cdn.jsdelivr.net/gh/Zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script>
  <script data-pjax="">
        function GithubCalendarConfig(){
            var git_githubapiurl ="https://python-github-calendar-api.vercel.app/api?XuRui314";
            var git_color =['#ebedf0', '#fdcdec', '#fc9bd9', '#fa6ac5', '#f838b2', '#f5089f', '#c4067e', '#92055e', '#540336', '#48022f', '#30021f'];
            var git_user ="XuRui314";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="height:100%;display: flex;align-items: center;justify-content: center;"><svg style="height:50px" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>';
            if(parent_div_git && location.pathname =='/'){
                console.log('已挂载github calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // 有报错，但不影响使用(支持pjax跳转)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:248px}@media screen and (max-width:650px) {#github_container{background-image:;min-height:0px}}</style>
    <style></style><script async="" src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"live2d-widget-model-wanko"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.7},"log":false});</script></body></html>