<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Ê¶ÇÁéáÂ∞èËÆ∞ | XuRui-Blog</title><meta name="keywords" content="Ê¶ÇÁéáËÆ∫"><meta name="author" content="zxr"><meta name="copyright" content="zxr"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Using the mathematic tools to build up a model which stands for our beliefs towards the world. Discrete case corresponds to the counting measure. (concentrating on the number of elements)  Continuous">
<meta property="og:type" content="article">
<meta property="og:title" content="Ê¶ÇÁéáÂ∞èËÆ∞">
<meta property="og:url" content="https://xurui314.github.io/2021/10/20/%E6%A6%82%E7%8E%87%E5%B0%8F%E8%AE%B0/index.html">
<meta property="og:site_name" content="XuRui-Blog">
<meta property="og:description" content="Using the mathematic tools to build up a model which stands for our beliefs towards the world. Discrete case corresponds to the counting measure. (concentrating on the number of elements)  Continuous">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://i.loli.net/2021/10/19/hEVDO4xG7U38y6s.jpg">
<meta property="article:published_time" content="2021-10-20T06:39:17.000Z">
<meta property="article:modified_time" content="2021-11-19T04:52:53.752Z">
<meta property="article:author" content="zxr">
<meta property="article:tag" content="Ê¶ÇÁéáËÆ∫">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/10/19/hEVDO4xG7U38y6s.jpg"><link rel="shortcut icon" href="https://i.loli.net/2021/07/27/lSHRJbx7dYwTk8f.jpg"><link rel="canonical" href="https://xurui314.github.io/2021/10/20/%E6%A6%82%E7%8E%87%E5%B0%8F%E8%AE%B0/"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Ê¶ÇÁéáÂ∞èËÆ∞',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-11-19 12:52:53'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    document.addEventListener('pjax:complete', detectApple)})(window)</script><link rel="stylesheet" href="/css/badge.css"><link rel="stylesheet" href="/css/modify.css"><link rel="stylesheet" href="/css/mouse.css"><link rel="stylesheet" href="/dist/APlayer.min.css"><link rel="stylesheet" href="/css/custom.css"><link rel="stylesheet" href="/css/theme.css"><link rel="stylesheet" href="/css/bilibiliBanner.css" media="defer" onload="this.media='screen'"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper/swiper/swiper.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper/swiper/swiperstyle.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css">
<style>#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags:before {content:"\A";
  white-space: pre;}#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags > .article-meta__separator{display:none}</style>
<link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script async="" src="https://unpkg.zhimg.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://s2.loli.net/2021/12/08/yTYthVwXD4IPbJ9.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">39</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">20</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">10</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> ‰∏ªÈ°µüç≠</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Ê°£Ê°àüåä</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Ê†áÁ≠æüìë</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> ÂàÜÁ±ªüåà</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> Â•ΩÂ∫∑ÁöÑ‚ú®</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener" href="https://ocw.mit.edu/"><i class="fa-fw fas fa-link"></i><span> Êù•Â≠¶È∫ªÂ≠¶</span></a></li><li><a class="site-page child" href="/bangumis/"><i class="fa-fw fas fa-video"></i><span> zxr„ÅÆËøΩÁï™ËÆ°Âàí</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=RyOyXsKuUgI"><i class="fa-fw fas fa-heart"></i><span> zxrÊúÄÁà±Êª¥upÂòâÂÄ©</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://oskarstalberg.com/game/planet/planet.html"><span> Planet</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> ÂèãÈìæüíï</span></a></div><div class="menus_item"><a class="site-page" href="https://xurui314.github.io/aboutme/"><span> AboutMeüèÇ</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.foreverblog.cn/go.html"><span> Ëô´Ê¥û</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://i.loli.net/2021/10/19/hEVDO4xG7U38y6s.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">XuRui-Blog</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> ‰∏ªÈ°µüç≠</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Ê°£Ê°àüåä</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Ê†áÁ≠æüìë</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> ÂàÜÁ±ªüåà</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> Â•ΩÂ∫∑ÁöÑ‚ú®</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener" href="https://ocw.mit.edu/"><i class="fa-fw fas fa-link"></i><span> Êù•Â≠¶È∫ªÂ≠¶</span></a></li><li><a class="site-page child" href="/bangumis/"><i class="fa-fw fas fa-video"></i><span> zxr„ÅÆËøΩÁï™ËÆ°Âàí</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=RyOyXsKuUgI"><i class="fa-fw fas fa-heart"></i><span> zxrÊúÄÁà±Êª¥upÂòâÂÄ©</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://oskarstalberg.com/game/planet/planet.html"><span> Planet</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> ÂèãÈìæüíï</span></a></div><div class="menus_item"><a class="site-page" href="https://xurui314.github.io/aboutme/"><span> AboutMeüèÇ</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.foreverblog.cn/go.html"><span> Ëô´Ê¥û</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Ê¶ÇÁéáÂ∞èËÆ∞</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2021-10-20T06:39:17.000Z" title="Created 2021-10-20 14:39:17">2021-10-20</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2021-11-19T04:52:53.752Z" title="Updated 2021-11-19 12:52:53">2021-11-19</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Math/">Math</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">7.9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>49min</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Ê¶ÇÁéáÂ∞èËÆ∞"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><div class="top-img" style="background-image: url('https://i.loli.net/2021/10/19/hEVDO4xG7U38y6s.jpg');"></div><article class="post-content" id="article-container"><blockquote>
<p>Using the mathematic tools to build up a model which stands for our beliefs towards the world.</p>
<p>Discrete case corresponds to the counting measure. (concentrating on the number of elements) </p>
<p>Continuous case corresponds to the Lebesgue measure.</p>
<p>In general, probability is the measure of events, encodes our belief how likely it may happen.</p>
</blockquote>
<p><img src="https://i.loli.net/2021/09/17/9H5WSbTrVejOdkz.jpg" style="zoom:80%;"></p>
<h1 id="General-ideas"><a href="#General-ideas" class="headerlink" title="General ideas"></a>General ideas</h1><h2 id="Probability-and-Measure-theory"><a href="#Probability-and-Measure-theory" class="headerlink" title="Probability and Measure theory"></a>Probability and Measure theory</h2><p>This part will talk the relation between probability and measure in brief to build an intuitive understanding and a clear thread of thought.</p>
<h3 id="Probability-Space"><a href="#Probability-Space" class="headerlink" title="Probability Space"></a>Probability Space</h3><p>We begin with the undefined basic concept of  random experiment and outcome to define other entities. </p>
<p>First, let‚Äôs focus on the sample space, it can be classified as follows:</p>
<ol>
<li>Finite sample space</li>
<li>Countably infinite sample space</li>
<li>Uncountable sample space</li>
</ol>
<p>the sample space can be different for the same experiment and you can get different answers based on which sample space you decide to choose. Bertrand‚Äôs Paradox is a typical case.</p>
<p>Based on the concept of sample space, we can define the concept of event. An event is a subset of the sample space, to which probabilities will be assigned, and not all subsets of the sample space are necessarily considered event. </p>
<p>We will see later that whenever $‚Ñ¶$ is finite or countable, all subsets of the sample space can be considered as events, and be assigned probabilities. However, when $‚Ñ¶ $ is uncountable, it is often not possible to assign probabilities to all subsets of $‚Ñ¶$, for reasons that will not be clear now. And we will formally define the definition of event soon.</p>
<p>Next, after looking at some nice properties that we would expect events to satisfy, we raise the concept of ‚ÄòAlgebra‚Äô.</p>
<p>It can be shown that an algebra is closed under finite union and finite intersection, and it‚Äôs quiet intuitive. However, algebra is not enough to study events of typical interest for it‚Äôs only finite intersection or union.</p>
<p>So we put forward $\sigma-$algebra. Note that unlike an algebra, a $œÉ$-algebra is closed under countable union and countable intersection.</p>
<p>A collection $\mathcal{F}$ of subsets of $\Omega$ is called a $\sigma-$algebra if:</p>
<ol>
<li>$\varnothing \in \mathcal{F}$</li>
<li>$A \in \mathcal{F}, implies \ A^c \in\mathcal{F}$</li>
<li>$if \  A<em>1,A_2,A_3‚Ä¶\ is \ a \ countable \ collection \ of \ subsets \ in \ \mathcal{F},then \ \cup^{\infty}</em>{1} A_i \in \mathcal{F}$</li>
</ol>
<p>The 2-tuple $(‚Ñ¶, \mathcal{F})$ is called a measurable space. Also, every member of the œÉ-algebra $\mathcal{F}$ is called an $\mathcal{F}-measurable$ set in the context of measure theory. In the specific context of probability theory, $\mathcal{F}-measurable$ sets are called events. Thus, whether or not a subset of $‚Ñ¶$ is considered an event depends on the $œÉ-$algebra that is under consideration.</p>
<p>We now proceed to define measures and measure spaces. We will see that a probability space is indeed a special case of a measure space.</p>
<p><strong>$Definition$ </strong> Let $(‚Ñ¶,  \mathcal{F})$ be a measurable space. A measure on $(‚Ñ¶, \mathcal{F})$ is a function $\mu: \mathcal{F} \to [0,‚àû]$ such that:</p>
<ol>
<li><p>$\mu(‚àÖ) = 0$ </p>
</li>
<li><p>If ${Ai , i ‚â• 1}$ is a sequence of disjoint sets in $\mathcal{F}$, then the measure of the union (of countably infinite disjoint sets) is equal to the sum of measures of individual sets, i.e.</p>
<script type="math/tex; mode=display">
\mu\left(\bigcup_{i=1}^{\infty} A_{i}\right)=\sum_{i=1}^{\infty} \mu\left(A_{i}\right)</script><p>The second property stated above is known as the countable additivity property of measures. From the definition, it is clear that a measure can only be assigned to elements of $\mathcal{F}$. The triplet $(‚Ñ¶, \mathcal{F}, \mu) $is called a measure space. $\mu$ is said to be a finite measure if $\mu(‚Ñ¶) &lt; ‚àû$; otherwise, $\mu$ is said to be an infinite measure. In particular, if $\mu(‚Ñ¶)= 1$ , then $\mu$ is said to be a probability measure. Next, we state this explicitly for pedagogical completeness.</p>
</li>
</ol>
<p><img src="https://i.loli.net/2021/10/25/dW3jsaXkh5mMziV.png" style="zoom:80%;"></p>
<h3 id="Discrete-probability-space"><a href="#Discrete-probability-space" class="headerlink" title="Discrete probability space"></a>Discrete probability space</h3><p><img src="https://i.loli.net/2021/10/25/CkdgbTlBWGx9pAF.png" style="zoom:80%;"></p>
<h3 id="Continuous-probability-space"><a href="#Continuous-probability-space" class="headerlink" title="Continuous probability space"></a>Continuous probability space</h3><p><a target="_blank" rel="noopener" href="http://www.ee.iitm.ac.in/~krishnaj/EE5110_files/notes/lecture7_Borel%20Sets%20and%20Lebesgue%20Measure.pdf">http://www.ee.iitm.ac.in/~krishnaj/EE5110_files/notes/lecture7_Borel%20Sets%20and%20Lebesgue%20Measure.pdf</a></p>
<p>Consider the experiment of picking a real number at random from $‚Ñ¶ = [0, 1]$, such that every number is ‚Äúequally likely‚Äù(In fact, not equally likely) to be picked. It is quite apparent that a simple strategy of assigning probabilities to singleton subsets of the sample space gets into difficulties quite quickly.</p>
<p>Thus, we need a different approach to assign probabilities when the sample space is uncountable, such as $‚Ñ¶ = [0, 1]$. In particular, we need to assign probabilities directly to specific subsets of $‚Ñ¶$.</p>
<h3 id="Random-variable"><a href="#Random-variable" class="headerlink" title="Random variable"></a>Random variable</h3><h4 id="General"><a href="#General" class="headerlink" title="General"></a>General</h4><p>The study of random variables is motivated by the fact that in many scenarios, one might not be interested in the precise elementary outcome of a random experiment, but rather in some numerical function of the outcome. For example, in an experiment involving ten coin tosses, the experimenter may only want to know the total number of heads, rather than the precise sequence of heads and tails. </p>
<p>The term random variable is a misnomer, because a random variable is neither random, nor is it a variable. A random variable $X$ is a function from the sample space $‚Ñ¶ $ to real field $\mathbb R$. The term ‚Äòrandom‚Äô actually signifies the underlying randomness in picking an element $œâ$ from the sample space $‚Ñ¶$. Once the elementary outcome $œâ$ is fixed, the random variable takes a fixed real value, $X(œâ)$. It is important to remember that the probability measure is associated with subsets (events), whereas a random variable is associated with each elementary outcome $œâ$. Just as not all subsets of the sample space are not necessarily considered events, not all functions from $‚Ñ¶$ to $\R$ are considered random variables. In particular, a random variable is an $\mathcal F-measurable$ function, as we define below.</p>
<p><a target="_blank" rel="noopener" href="http://www.ee.iitm.ac.in/~krishnaj/EE5110_files/notes/lecture11_rvs.pdf">http://www.ee.iitm.ac.in/~krishnaj/EE5110_files/notes/lecture11_rvs.pdf</a></p>
<h4 id="Discrete"><a href="#Discrete" class="headerlink" title="Discrete"></a>Discrete</h4><p>A random variable $X$ is said to be discrete if it takes values in a countable subset of $\mathbb R$ with probability $1$.</p>
<h4 id="Continuous"><a href="#Continuous" class="headerlink" title="Continuous"></a>Continuous</h4><p>Formally, a continuous random variable is a random variable whose <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Cumulative_distribution_function">cumulative distribution function</a> is <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Continuous_function">continuous</a> everywhere.<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Random_variable#cite_note-:0-11">[11]</a> There are no ‚Äú<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Discontinuity_(mathematics">gaps</a>#Jump<em>discontinuity)‚Äù, which would correspond to numbers which have a finite probability of [occurring](<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Outcome">https://en.wikipedia.org/wiki/Outcome</a></em>(probability)).</p>
<p>Consistent with the definition here:<a target="_blank" rel="noopener" href="http://www.ee.iitm.ac.in/~krishnaj/EE5110_files/notes/lecture11_Part_Two_Types_Of_Random_Variables.pdf">http://www.ee.iitm.ac.in/~krishnaj/EE5110_files/notes/lecture11_Part_Two_Types_Of_Random_Variables.pdf</a></p>
<h2 id="Study-model"><a href="#Study-model" class="headerlink" title="Study model"></a>Study model</h2><ol>
<li>Know the theory behind the concepts and formulas.</li>
<li>Get familiar with the concepts and formulas. Also need to have an intuitive understanding of them.</li>
<li>For different formulas, remember in mind some typical examples supporting  respectively.  </li>
</ol>
<h2 id="Thinkings-about-Probability-and-The-History-of-Probability"><a href="#Thinkings-about-Probability-and-The-History-of-Probability" class="headerlink" title="Thinkings about Probability and The History of Probability"></a>Thinkings about Probability and The History of Probability</h2><p>We start with an interesting story about what is probability. Yeah, What is probability? It seems like a Philosophical question that involves the connection between subjective thinkings and the objective world. </p>
<p>Indeed, the development of probability is full of controversy(‰∫âËÆÆ) at first , because at that time, probability looks like just a common sense of our mind, without complete math theory. Many years later, probability theory turned the corner, scientists such as Laplace, Markov pushed the subject forward greatly, and probability is largely viewed as a natural science, interpreted as limits of relative frequencies in the context of repeatable experiments. </p>
<p>And now, with the great work of Kolmogorov, relative frequency is abandoned as the conceptual foundation of probability theory in favor of a now universally used axiomatic system. Similar to other branches of mathematics, the development of probability theory from the axioms relies only on logical correctness, regardless of its relevance to physical phenomena. Nonetheless, probability theory is used pervasively in science and engineering because of its ability to describe and interpret most types of uncertain phenomena in the real world. </p>
<blockquote>
<p><strong>And Now, let‚Äôs dive into the world of Probability!</strong></p>
</blockquote>
<p><img src="https://i.loli.net/2021/10/19/WpjUb83giZQSBa1.jpg" alt="1514.jpg"></p>
<h1 id="1-Sample-Space-and-Probability"><a href="#1-Sample-Space-and-Probability" class="headerlink" title="1. Sample Space and Probability"></a>1. Sample Space and Probability</h1><h2 id="Overlook-the-Chapter"><a href="#Overlook-the-Chapter" class="headerlink" title="Overlook the Chapter"></a>Overlook the Chapter</h2><p>In this Chapter, the subject is to describe the generic structure of probabilistic models and their properties. We first talk about Sets, because the models we consider assign probabilities to collections(sets) of possible outcomes.(Maybe a little measure theory added here is better) And then, to complete a probability model, we need sample space(set) and probability law(measure).After the definition of the two, we will talk about the properties of them. For sample space, we need to know how to choose an appropriate sample space. To be an example, we introduced the sequential Models. Then we come to the probability law , and probability axioms. After that, we modeled two basic models with our belief.</p>
<p>After introducing the model components, we come to the core of probability‚Äî‚Äî‚Äî‚Äî‚Äî-conditional and independence, which encode our thinkings towards the experiment and events. And for sequential character(logic sequential) experiments , we can use conditional probability to model.</p>
<p>Last, for a specific and most common case, we will introduce counting, and really interesting. </p>
<p>Supplement: </p>
<p>(In my point of view, using measure theory as the base of probability is a quiet intuitive approach.=_= </p>
<p>Maybe someone will ask: To describe the measure of sets, why do we use the measure theory? Can we use other tools?</p>
<p>In fact, measure theory is so powerful a tool and is so intuitive, consistent with our mind,besides, there are indeed some non-measurable cases and some paradoxes. And if we don‚Äôt use the complete math theory, it can‚Äôt be solved in a reasonable way. </p>
<p>See more :</p>
<p><a target="_blank" rel="noopener" href="https://www.countbayesie.com/blog/2015/8/17/a-very-brief-and-non-mathematical-introduction-to-measure-theory-for-probability">https://www.countbayesie.com/blog/2015/8/17/a-very-brief-and-non-mathematical-introduction-to-measure-theory-for-probability</a></p>
<p><a target="_blank" rel="noopener" href="https://www.quora.com/Why-is-measure-theory-so-important-in-probability-theory-and-is-this-also-the-case-for-applications">https://www.quora.com/Why-is-measure-theory-so-important-in-probability-theory-and-is-this-also-the-case-for-applications</a></p>
<p><a target="_blank" rel="noopener" href="https://www.quora.com/Why-do-we-need-measure-theory-for-Probability">https://www.quora.com/Why-do-we-need-measure-theory-for-Probability</a>)</p>
<details>
<summary>What's this?üòè</summary>
<summary>Woops!This is an Easter egg!üòù
</summary></details>



<h2 id="1-1-Sets"><a href="#1-1-Sets" class="headerlink" title="1.1 Sets"></a>1.1 Sets</h2><ul>
<li>[ ] ### basic concepts</li>
</ul>
<p>What composes a set or set definition.</p>
<p>How to represent a set and the caution point(uncountable set can‚Äôt be written in a list).</p>
<p>Relations between sets.</p>
<ul>
<li>[ ] ### Set Operations</li>
</ul>
<p>Complements, union, intersection, partition</p>
<p>Ordered pair representation</p>
<p>Sets and the associated operations are easy to visualize in terms of Venn diagrams.</p>
<ul>
<li>[ ] ### The Algebra of Sets</li>
</ul>
<p>Commutative law,  Associative law, Distribution law and so on‚Ä¶</p>
<p>Two particular useful properties are given by De Morgan‚Äôs laws. </p>
<h2 id="1-2-Probabilistic-Models"><a href="#1-2-Probabilistic-Models" class="headerlink" title="1.2 Probabilistic Models"></a>1.2 Probabilistic Models</h2><ul>
<li>[x] ### Definition of Probabilistic Model</li>
</ul>
<p>A probabilistic model is a mathematical description of an uncertain situation.</p>
<ul>
<li>[x] ### Elements of a Probabilistic Model </li>
</ul>
<p>Two ingredients: Sample space and Probability law.</p>
<p>remember the picture</p>
<p><img src="C:\Users\19772\AppData\Roaming\Typora\typora-user-images\image-20211008145510788.png" alt="image-20211008145510788" style="zoom:33%;"></p>
<ul>
<li>[ ] ### Sample Spaces and Events</li>
</ul>
<p>the definition of experiment, sample space, event and their properties.</p>
<ul>
<li>[ ] ### Choosing an Appropriate Sample Space</li>
</ul>
<p>The elements in a sample space should be distinct and mutually exclusive(Áã¨Á´ã‰∫íÊñ•), collectively exhaustive(ÂÆåÂÖ®Á©∑Â∞Ω)</p>
<p>In addition, a given situation may be modeled in several different ways, depending on the kind of questions that we are interested in. And also, the sample space should have enough detail to distinguish between all outcomes of interest to the modeler, while avoiding irrelevant details. </p>
<ul>
<li><p>[ ] ### Sequential Models  </p>
<p>Experiment with inherently sequential character, for it and its‚Äô sample space, we can use the tree-based sequential description.</p>
</li>
</ul>
<blockquote>
<p>In fact, the sample space of Monty Hall Problem is modeled with sequential stages, and the key is finding the right sample space.</p>
</blockquote>
<ul>
<li>[x] ### Probability Laws</li>
</ul>
<p>Intuitively, this specifies the ‚Äòlikelihood‚Äô of any outcome, or of any set of possible outcomes.</p>
<p>More precisely, the probability law assigns to every event $A$ a number $P(A)$ , called the probability of A , satisfying the following axioms.</p>
<ol>
<li>Nonnegativity</li>
<li>Additivity</li>
<li>Normalization</li>
</ol>
<ul>
<li>[x] ### Properties of Probability Laws</li>
</ul>
<p>There are many natural properties of a probability law which can be derived from the axioms.</p>
<p>We can use Venn diagrams for visualization and verification of various properties of probability laws.</p>
<p>And an intuitive reason of this is that Probability itself is a measure of set(sample space).<br>That means we can get disjoint sets and use the additivity and nonnegative property, this is consistent with the Venn diagrams, which can be viewed as a way to describe the element measure of sets.</p>
<ul>
<li>[ ] ### Discrete Models</li>
</ul>
<p>Sample space: a finite number of possible outcomes.</p>
<p>Discrete Probability Law: $P({ s_1,s_2,‚Ä¶,s_n}) =  P(s_1)+P(s_2)+‚Ä¶+P(s_n)$ </p>
<ul>
<li>[ ] ### Continuous Models</li>
</ul>
<p>Use the measure theory to build the model.</p>
<ul>
<li>[ ] ### Models and Reality</li>
</ul>
<p>Stages of Probability Theory development.</p>
<h2 id="1-3-Conditional-Probability"><a href="#1-3-Conditional-Probability" class="headerlink" title="1.3 Conditional Probability"></a>1.3 Conditional Probability</h2><ul>
<li>[ ] ### Introduction and Definition</li>
</ul>
<p>In many cases, we may have already known some information about the outcomes. So the original probability law can‚Äôt be correspond with the new situation, thus we want to find a new probability law to rebuild our model taking the known facts into account. </p>
<p>And that is so called conditional probability. Conditional probability provides us with a way to reason about the outcome of an experiment based on the partial information. </p>
<p>In our beliefs, or intuitively speaking, what does it mean if you tell me the partial information such that event $B$ has already happened?</p>
<blockquote>
<p>Caution! The information that event $B$ happened means that the experiment is finished, and we are analyzing the result , and we have the partial information that $B$ happened. It‚Äôs not the case that we are doing the experiment, and we know in advance that $B$ happens. In fact, the latter case‚Äôs probability law may be different from what we assume at first.</p>
</blockquote>
<p>It means that we now stands in the new universe B, and we need to reset the probabilities of each event.</p>
<p>How can we do that? ‚Äî By normalizing the original probability using $P(B)$. </p>
<p>Generalizing the argument , we get the definition:</p>
<script type="math/tex; mode=display">
P(A\ |\ B)={P(A \ \cap \ B) \over P(B)}</script><ul>
<li>[ ] ### Conditional Probabilities Specify a Probability Law</li>
</ul>
<p>To check the three axioms.</p>
<p>(Because the conditional probability is constructed by our intuition, so we need to use the axioms to check whether it is a probability law.)</p>
<p>Conditional probabilities constitute a legitimate probability law, all general properties of probability laws remain valid.</p>
<ul>
<li>[ ] ### Using Conditional Probability for Modeling</li>
</ul>
<p>When constructing probabilistic models for experiments that have a sequential character(physics process or logic sequence), it‚Äôs often natural and convenient to  fist specify conditional probabilities and then use them to determine unconditional probabilities.</p>
<p>A useful rule for calculating various probabilities in conjunction with a tree-based sequential description of an experiment‚Äî‚Äî‚Äî-Multiplication Rule.</p>
<p>Example 1.9 Radar Detection</p>
<p>Example 1.11 graduate and undergraduate partition(for all the cases, the same logic sequential analysis)</p>
<p>Example 1.12 The Monty Hall Problem(the key is to choose sample space appropriately)</p>
<p><a target="_blank" rel="noopener" href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-042j-mathematics-for-computer-science-fall-2005/readings/ln12.pdf">https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-042j-mathematics-for-computer-science-fall-2005/readings/ln12.pdf</a></p>
<h2 id="1-4-Total-Probability-Theorem-and-Bayes‚Äô-Rule"><a href="#1-4-Total-Probability-Theorem-and-Bayes‚Äô-Rule" class="headerlink" title="1.4 Total Probability Theorem and Bayes‚Äô Rule"></a>1.4 Total Probability Theorem and Bayes‚Äô Rule</h2><ul>
<li>[ ] ### Total Probability Theorem</li>
</ul>
<p>Use the ‚Äúdivide-and-conquer‚Äù approach with a partition of the sample space.</p>
<p>Example 1.15 Alice taking probability class: the recursion relationship of total probability theorem can reduce a lot calculation compared with just using multiplication rule along the branch.</p>
<ul>
<li>[ ] ### Inference and Bayes‚Äô Rule</li>
</ul>
<p>Bayes‚Äô rule is often used for inference. There are a number of ‚Äúcauses‚Äù that may result in a certain ‚Äúeffect‚Äù. We observe the effect, and we wish to infer the cause.</p>
<p>Example 1.16 Radar Detection 2.0</p>
<h2 id="1-5-Independence"><a href="#1-5-Independence" class="headerlink" title="1.5 Independence"></a>1.5 Independence</h2><ul>
<li>[ ] ### Introduction and Definition</li>
</ul>
<p>Conditional probability $P(A|B)$ is used to capture the partial information that event $B$ provides about event $A$. An interesting and important special case arises when the occurrence of B provides no such information and does not alter the probability that $A$ has occurred.</p>
<p>Independence is often easy to grasp intuitively(distinct, noninteracting physical process) ,however it is not easily visualized in terms of the sample space.</p>
<p>Example 1.19(b)</p>
<ul>
<li>[ ] ### Conditional Independence</li>
</ul>
<p>Since conditional probability is a legitimate probability law ,we can thus talk about independence of various events with respect to this conditional law.</p>
<p>Independence of two events $A$ and $B$ with respect to the unconditional probability law does not imply conditional independence and vice versa.</p>
<p>Example 1.21 Biased coin </p>
<ul>
<li>[ ] ### Independence of a Collection of Events</li>
</ul>
<p>Pairwise independence does not imply independence and the equality $P(A_1\cap A_2 \cap A_3)=P(A_1)P(A_2)P(A_3)$ is not enough for independence.</p>
<p>Example 1.22/1.23</p>
<ul>
<li>[ ] ### Reliability</li>
</ul>
<p>Divide the system into subsystems which consists of components that are connected either in series or in parallel.</p>
<ul>
<li>[ ] ### Independent Trials and the Binomial Probabilities</li>
</ul>
<p>If an experiment involves a sequence of independent but identical stages, we say that we have a sequence of independent trials. In the special case where there are only two possible results at each stage, we say that we have a sequence of independent Bernoulli trials. </p>
<h2 id="1-6-Counting"><a href="#1-6-Counting" class="headerlink" title="1.6 Counting"></a>1.6 Counting</h2><ul>
<li>[ ] ### The counting Principle</li>
</ul>
<p>Consider a process that consists of r stages. Suppose that:<br>(a) There are $m$ possible results at the first stage.<br>(b)For every possible result at the first stage,there are $n_2$ possible results at the second stage.<br>(c) More generally, for any sequence of possible results at the first $i-1$ stages, there are $n$ possible results at the $i$th stage. Then, the total number of possible results of the $r-$stage process is $n_1\ n_2¬∑¬∑¬∑n_r$</p>
<p>If the order of selection matters, the selection is called a permutation, and otherwise, it is called a combination. We will then discuss a more general type of counting, involving a partition of a collection of $n$ objects into multiple subsets. </p>
<ul>
<li>[ ] ### $k$-permutations</li>
</ul>
<p>Example 1.29 CD-arranging problem</p>
<ul>
<li>[ ] ### Combinations</li>
</ul>
<p>Counting arguments sometimes lead to formulas that are rather difficult to derive algebraically.<br>From the view of set and the view of combination formula to derive an equality involving $2^n \ and \ \tbinom{n}{r} $ </p>
<p>Remember the picture of the relationship between permutation and combination.</p>
<p>Example 1.31 Choose a group leader </p>
<ul>
<li>[ ] ### Partitions</li>
</ul>
<p>Combination can be viewed as a partition of the set in two, and now let‚Äôs consider partitions of the set into r disjoint subsets.</p>
<p>Using stage method, we can get the following formula:ÔºàAttention,$n_1,n_2,‚Ä¶,n_r$ are different, if $k$ of them are the same, we need to divide the formula by $k!$, this is in Problem 62Ôºâ</p>
<script type="math/tex; mode=display">
\left(\begin{array}{c}
n \\
n_{1}
\end{array}\right)\left(\begin{array}{c}
n-n_{1} \\
n_{2}
\end{array}\right)\left(\begin{array}{c}
n-n_{1}-n_{2} \\
n_{3}
\end{array}\right) \cdots\left(\begin{array}{c}
n-n_{1}-\cdots-n_{r-1} \\
n_{r}
\end{array}\right)</script><script type="math/tex; mode=display">
\frac{n !}{n_{1} !\left(n-n_{1}\right) !} \cdot \frac{\left(n-n_{1}\right) !}{n_{2} !\left(n-n_{1}-n_{2}\right) !} \cdots \frac{\left(n-n_{1}-\cdots-n_{r-1}\right) !}{\left(n-n_{1}-\cdots-n_{r-1}-n_{r}\right) ! n_{r} !}</script><p>After canceling we get:</p>
<script type="math/tex; mode=display">
\frac{n !}{n_{1} ! n_{2} ! \cdots n_{r} !}</script><p>This is called <strong>multinomial coefficient</strong> and is denoted by:</p>
<script type="math/tex; mode=display">
\left(\begin{array}{c}
n \\
n_{1}, n_{2}, \ldots, n_{r}
\end{array}\right)</script><p>Example 1.32 TATTO rearrange problem</p>
<p>Example 1.33 graduate and undergraduate partition</p>
<h1 id="2-Discrete-Random-Variables"><a href="#2-Discrete-Random-Variables" class="headerlink" title="2. Discrete Random Variables"></a>2. Discrete Random Variables</h1><h2 id="Overlook-the-Chapter-1"><a href="#Overlook-the-Chapter-1" class="headerlink" title="Overlook the Chapter"></a>Overlook the Chapter</h2><p>In this Chapter, we focus on discrete random variable. We first introduce some basic concepts. The concepts such as $PMF$, the mean, and the variance describe in various degrees of detail the probabilistic character of a random variable.  After that, we come to the $PMF$. It can be viewed as a measure on $(\mathbb R, B(\mathbb R) )$ since if the range of random variable chosen as a Borel set then the inverse image (correspond events) are also $\sigma-$algebra, it‚Äôs natural to assign probability to the value of random variable, which is the probability of the event ${X=x}$. Then we will learn some important random variables , also the functions of a random variable, whose $PMF$ calculation is almost the same as the $PMF$ of a single random variable.</p>
<p>For expectation, we will learn the intuitive diagram explaining expectation as the center, and the well-defined expectation, the expected value rule for functions of random variables, properties of mean(linear function). And also the variance.</p>
<p>For the experiment involving several random variables, we use the joint $PMF$ to describe the interdependence and the probability of any event that can be specified in terms of the random variable. And then we come to conditional and independence.</p>
<p>Condition on an event, condition on a random variable ,conditional expectation(total expectation theorem).</p>
<p>Independence of a random variable and an event, independence of random variables, and the property of expectation and variance under independence.</p>
<details>
<summary>See the note</summary>
<summary><img src="https://i.loli.net/2021/08/25/mL7PwTkuIzNDJA2.jpg" style="zoom: 25%;">
</summary></details>






<blockquote>
<p>For random variables, there is a great explanation.</p>
<p><a target="_blank" rel="noopener" href="http://www.ee.iitm.ac.in/~krishnaj/EE5110_files/notes/lecture11_rvs.pdf">http://www.ee.iitm.ac.in/~krishnaj/EE5110_files/notes/lecture11_rvs.pdf</a></p>
</blockquote>
<h2 id="2-1-Basic-Concepts"><a href="#2-1-Basic-Concepts" class="headerlink" title="2.1 Basic Concepts"></a>2.1 Basic Concepts</h2><ul>
<li><p>[ ] ### Main Concepts Related to Random Variables</p>
<p>Starting with a probabilistic model of an experiment:</p>
</li>
</ul>
<ol>
<li>Mathematically, a <strong>random variable</strong> is a real-valued function of the experimental outcome.</li>
<li>A <strong>function of a random variable</strong> defines another random variable. </li>
<li>We can associate with each random variable certain‚Äùaverages‚Äùof interest, such as the <strong>mean</strong> and the <strong>variance</strong>.</li>
<li>A random variable can be <strong>conditioned</strong> on an event or on another random variable.</li>
<li>There is a notion of <strong>independence</strong> of a random variable from an event or from another random variable.</li>
</ol>
<p>A random variable is called discrete if its range is either finite or countable infinite.</p>
<ul>
<li>[ ] ### Concepts Related to Discrete Random Variables </li>
</ul>
<p>Starting with a probabilistic model of an experiment:<br>‚óèA discrete random variable is a real-valued function of the outcome of the experiment that can take a finite or countably infinite number of values.<br>‚óè A discrete random variable has an associated probability mass function(PMF),which gives the probability of each numerical value that the random variable can take.<br>‚óèA function of a discrete random variable defines another discrete random variable, whose PMF can be obtained from the PMF of the original random variable.</p>
<h2 id="2-2-Probability-Mass-Functions"><a href="#2-2-Probability-Mass-Functions" class="headerlink" title="2.2 Probability Mass Functions"></a>2.2 Probability Mass Functions</h2><ul>
<li><p>[ ] ### Definition</p>
<p>In particular, if $x$ is any possible value of $X$, the probability mass of $x$ denoted $p_X(x)$, is the probability of event${ X=x}$ consisting of all outcomes that give rise to a value of $X$ equal to $x$:</p>
<script type="math/tex; mode=display">
p_X(x)=P(\{X=x\})</script><p>And as $x$ ranges over all possible values of $X$, the event${ X=x}$ are disjoint and form a partition of the sample space.</p>
</li>
</ul>
<ul>
<li>[ ] ### Calculation of the PMF of a Random Variable $X$‚Äã </li>
</ul>
<p>For each possible value $x$ of $X$: </p>
<ol>
<li><p>Collect all the possible outcomes that give rise to the event ${X = x}$. </p>
</li>
<li><p>Add their probabilities to obtain $p_X(x)$. </p>
</li>
</ol>
<h2 id="2-3-Functions-of-Random-Variables"><a href="#2-3-Functions-of-Random-Variables" class="headerlink" title="2.3 Functions of Random Variables"></a>2.3 Functions of Random Variables</h2><p>If $Y=g(X)$ is a function of a random variable $X$, then $Y$ is also a random variable, since it provides a numerical value for each possible outcome. This is because every outcome in the sample space defines a numerical value $x$ for $X$ and hence also the numerical value $y = g(x)$ for Y. If $X$ is discrete with $PMF$  $p_X$. then $Y$ is also discrete, and its $PMF$  $p_Y$ can be calculated using the $PMF$ of $X$ .In particular, to obtain $p_Y(y)$ for any $y$, we add the probabilities of all values of $x$ such that $g(x)= y$:</p>
<script type="math/tex; mode=display">
p_{Y}(y)=\sum_{\{x \mid g(x)=y\}} p_{X}(x)</script><p>Example 2.1 square function</p>
<h2 id="2-4-Expectation-Mean-and-Variance"><a href="#2-4-Expectation-Mean-and-Variance" class="headerlink" title="2.4 Expectation, Mean, and Variance"></a>2.4 Expectation, Mean, and Variance</h2><ul>
<li>[ ] ### Expectation</li>
</ul>
<p>The expectation of $X$ is a summary of the information provided by $PMF$ in a single representative number.</p>
<p>We define the expected value (also called the expectation or the mean) of a random variable $X$, with $PMF$ $p_X$, by</p>
<script type="math/tex; mode=display">
E[X]=\sum_{x} xp_{X}(x)</script><p>Expectation can be viewed as  the center of gravity of  the $PMF$, remember the picture on page 83.<br>And the diagram is intuitively correspond to ‚ÄòMass‚Äô in the word PMF, also the word ‚Äòmoment‚Äô.</p>
<p>$E[X^2]$ is called 2nd moment, because in physics, the form of $x^2f(x)$ is the same as Momentum of Inertia $r^2m$.</p>
<ul>
<li>[ ] ### Variance</li>
</ul>
<p>The most important quantity associated with a random variable $ X$, other than the mean, is its $variance$, which is denoted by $var(X)$ and is defined as the expected value of the random variable $var(X)=E[(X-E[X])^2]$.</p>
<p>The variance provides a measure of dispersion of $X$ around its mean. Another measure of dispersion is the $standard \ deviation$ of $X$ with the same units, which is defined as the square root of the variance and is denoted by $\sigma_X$:</p>
<script type="math/tex; mode=display">
\sigma_X=\sqrt {var(X)}</script><ul>
<li>[ ] ### Expectation Value Rule for Functions of Random Variable</li>
</ul>
<p>Let $X$ be a random variable with $PMF$ $p_X$, and let $g(X)$ be a function of $X$. Then, the expected value of the random variable $g( X) $is given by </p>
<script type="math/tex; mode=display">
E[g(X)] = \sum_x g(x)p_X(x)</script><p>Therefore, we just don‚Äôt need to find out the $PMF$ of $Y=g(X)$, the $PMF$ of $X$ is just enough.</p>
<ul>
<li>[ ] ### Properties of Mean and Variance</li>
</ul>
<p><strong>Mean and variance of a Linear Function of a Random Variable</strong></p>
<p>Let $X$ be a random variable and let</p>
<script type="math/tex; mode=display">
Y=aX+b</script><p>where $a$ and $b$ are given scalars. Then,</p>
<script type="math/tex; mode=display">
E[Y]=aE[X]+b, \ \ var(Y)=a^2var(X)</script><p>Unless $g(X)$ is a linear function, it is not generally true that $E[g(X)]$ is equal to $g(E[X])$.</p>
<p>Example 2.4 Average Speed Versus Average time</p>
<p><strong>Variance in Terms of Moments Expression</strong></p>
<script type="math/tex; mode=display">
var(X)=E[X^2]-(E[X])^2</script><ul>
<li>[ ] ### Mean and Variance of Some Common Random Variables</li>
</ul>
<p>See the notebook.</p>
<h2 id="2-5-Joint-PMFs-of-Multiple-Random-Variables"><a href="#2-5-Joint-PMFs-of-Multiple-Random-Variables" class="headerlink" title="2.5 Joint PMFs of Multiple Random Variables"></a>2.5 Joint PMFs of Multiple Random Variables</h2><ul>
<li>[ ] ### Definition</li>
</ul>
<p>Probability model often involve several random variables. All of these random variables are associated with the same experiment, sample space, and probability law, and their values may relate in interesting ways. This motivates us to consider probabilities of events involving simultaneously several random variables. </p>
<p>Consider two discrete random variables $X$ and $Y$ associated with the same experiment. The probabilities of the values that $X$ and $Y$ can take are captured by the $joint\ PMF$ of $X$ and $Y$, denoted $p_{X,Y}$. In particular. if $(x,y)$ is a pair of possible values of $X$ and $Y$, the probability mass of $(x,y)$is the probability of the event ${ X=x,Y=y}$:</p>
<script type="math/tex; mode=display">
p_{X,Y}=P(X=x,Y=y)\ \</script><p>The more precise notation is $P({ X=x} \cap { Y=y})$.</p>
<p>The joint $PMF$ determines the probability of any event that can be specified in terms of the random variables $X$ and $Y$.</p>
<script type="math/tex; mode=display">
P((X,Y) \in A)=\sum_{(x,y) \in A} p_{X,Y}(x,y)</script><p>And also formulas for the $marginal \ PMFs$, with the reason.</p>
<p>We can use $tabular \ method$ to derive marginal $PMF$ from joint $PMF$.</p>
<ul>
<li>[ ] ### Functions of Multiple Random Variables </li>
</ul>
<p>When there are multiple random variables, it‚Äôs natural to generate new random variables by considering functions involving several of these random  variables. In particular, a function $Z=g(X,Y)$ of the random variables $X$ and $Y$ defines another random variable. Its $PMF$ can be calculated from the joint $PMF$ $p_{X,Y}$ according to</p>
<script type="math/tex; mode=display">
p_{Z}(z)=\sum_{\{(x,y) \mid g(x,y)=z\}} p_{X,Y}(x,y)</script><p>Furthermore,  the expected value rule for functions naturally extends and take the form:</p>
<script type="math/tex; mode=display">
E[g(X,Y)]=\sum_x \sum_y g(x,y)p_{X,Y}(x,y)</script><p>In the special case where $g$ is a linear function, with scalars $a,b,c$ , we get</p>
<script type="math/tex; mode=display">
E[aX+bY+c]=aE[X]+bE[Y]+c</script><ul>
<li>[ ] ### More than Two Random Variables </li>
</ul>
<p>Just natural extensions.</p>
<p><img src="https://i.loli.net/2021/10/24/Zf6XpIc9VvteYns.png" alt="image-20211024233647699.png" style="zoom:80%;"></p>
<p><img src="https://i.loli.net/2021/10/24/NxpfBbluDqVeAFn.png" alt="image-20211024233710698.png" style="zoom:80%;"></p>
<h2 id="2-6-Conditioning"><a href="#2-6-Conditioning" class="headerlink" title="2.6 Conditioning"></a>2.6 Conditioning</h2><ul>
<li>[ ] ### Conditioning a Random Variable on an Event</li>
</ul>
<p><img src="https://i.loli.net/2021/10/25/vr1CWeN5HJoUcRh.png" alt="image-20211025000715806.png" style="zoom:80%;"></p>
<p>Example 2.13 pass the test with trying maximum n times</p>
<ul>
<li>[ ] ### Conditioning a Random Variable on Another</li>
</ul>
<p>Let $X$ and $Y$ be two random variables associated with the same experiment. If we know that the value of $Y$ is some particular $y$ [with $p<em>Y(y)&gt;0$], this provides partial knowledge about the value of $X$. This knowledge is captured by the $conditional\ PMF\ $ $p</em>{X|Y}$ of $X$ given $Y$, which is defined by specializing the definition of $p_{X|A}$ to events $A$ of the form ${Y=y}$.</p>
<script type="math/tex; mode=display">
p_{X|Y}={P(X=x,Y=y) \over P(Y=y)}={p_{X,Y}(x,y) \over p_Y(y)}</script><p>Let us fix some $y$ with $p<em>Y(y)&gt;0$ and consider $p</em>{X|Y}(x|y)$ as a function of $x$. This function is a valid $PMF$ for $X$: it assigns nonnegative values to each possible $x$ and these values add to 1. Furthermore this function of $x$ has the same shape as $p_{X|Y}(x|y)$ except that it is divided by $p_Y(y)$, which enforces the normalization property.</p>
<p>Example 2.15 the length of the message and the travel time of the message</p>
<ul>
<li><p>[ ] ### Conditional Expectation</p>
<p>Since the conditional $PMF$ is a legitimate $PMF$ just over a new universe, conditional expectation seems to be reasonable.</p>
</li>
</ul>
<p><img src="https://i.loli.net/2021/10/25/SWnyOIAjRH1CQeU.png" alt="image-20211025230709064.png" style="zoom:80%;"></p>
<p>Total expectation theorem: the unconditional average and be obtained by averaging the conditional averages. That is, using a divide-and-conquer approach to calculate the unconditional expectation form the conditional expectation. </p>
<script type="math/tex; mode=display">
E[X]=\sum_{i=1}^nP(A_i)E[X|A_i]</script><h2 id="2-7-Independence"><a href="#2-7-Independence" class="headerlink" title="2.7 Independence"></a>2.7 Independence</h2><ul>
<li>[ ] ### Independence of a Random Variable from an Event</li>
</ul>
<p>The idea is that knowing the occurrence of the conditioning event provides no new information on the value of  the random variable, which is requiring that the two events ${X=x}$ and $A$ be independent, for any choice $x$.</p>
<script type="math/tex; mode=display">
P(X=x\ and \ A)=p_{X|A}(x)P(A)</script><ul>
<li>[ ] ### Independence of Random Variables</li>
</ul>
<p>We say that two random variable $X$ and $Y$ are independent if:</p>
<script type="math/tex; mode=display">
p_{X,Y}=p_X(x)p_Y(y) \  \ \ \ \ \ for \ all \ x,y</script><p>This is the same requiring that the two events ${X=x}$ and ${Y=y}$ be independent for every $x$ and $y$.</p>
<p><img src="https://i.loli.net/2021/11/03/RxkY15GnavMUPtb.png" alt="image-20211025234110611.png" style="zoom:80%;"></p>
<p>If $X$ and $Y$ are independent, then</p>
<script type="math/tex; mode=display">
var(XY)=var(X)var(Y)+var(X)(E[Y])^2+var(Y)(E[X])^2</script><ul>
<li>[ ] ### Independence of Several Random Variables</li>
</ul>
<p>The preceding discussion extends naturally to the case of more than two random variables. For example. three random variables $X,Y$ and $Z$ are said to be independent if </p>
<script type="math/tex; mode=display">
p_{X,Y,Z}(x,y,z)=p_X(x)p_Y(y)p_Z(z)</script><p>ps: The independence of several events seems to require the pairwise independence, but here we didn‚Äôt state that. In fact, the property of pairwise independence can be derived from the formula above easily.</p>
<ul>
<li>[ ] ### Variance of the Sum of Independent Random Variables</li>
</ul>
<p>If $X_1,X_2,‚Ä¶,X_n$ are independent random variables, then:</p>
<script type="math/tex; mode=display">
var(X_1+X_2+ \cdot\cdot\cdot+X_n )=var(X_1)+var(X_2)+\cdot\cdot\cdot+var(X_n)</script><h1 id="3-General-Random-Variables"><a href="#3-General-Random-Variables" class="headerlink" title="3. General Random Variables"></a>3. General Random Variables</h1><h2 id="3-1-Continuous-Random-Variables-and-PDFs"><a href="#3-1-Continuous-Random-Variables-and-PDFs" class="headerlink" title="3.1 Continuous Random Variables and PDFs"></a>3.1 Continuous Random Variables and PDFs</h2><ul>
<li>[ ] ### Continuous random Variable</li>
</ul>
<p>A random variable $X$ is called continuous if there is a nonnegative function $f_X$ , called the probability density function of $X$, or $PDF$ for short, such that</p>
<script type="math/tex; mode=display">
P(X \in B)= \int_B f_X(x)dx</script><p>for any $B \in \mathcal B(\R)$.</p>
<p>To interpret the $PDF$, note that for an interval $[x,x+\delta]$ with very small length $\delta$, we have</p>
<script type="math/tex; mode=display">
P([x,x+\delta]= \int_x^{x+\delta}f_X(t)dt\approx f_X(x) \dotproduct \delta</script><p>so, we can view $f_X(x)$ as the ‚Äòprobability mass per unit length‚Äô near $x$.</p>
<ul>
<li>[ ] ### Expectation</li>
</ul>
<p>The expected value or expectation or mean of a continuous random variable $X$ is defined by </p>
<script type="math/tex; mode=display">
E[X]= \int_{-\infty}^{\infty} xf_X(x)dx</script><p>and can also be interpreted as the ‚Äòcenter of gravity‚Äô of the $PDF$.</p>
<p>If $X$ is a continuous random variable with given $PDF$, any real-valued function $Y=g(X)$ of $X$ is also a random variable(may be discrete or continuous). And the mean of $g(X)$ satisfies the expected value rule</p>
<script type="math/tex; mode=display">
E[g(X)]= \int_{-\infty}^{\infty}g(x)f_X(x)dx</script><h2 id="3-2-Cumulative-Distribution-Functions"><a href="#3-2-Cumulative-Distribution-Functions" class="headerlink" title="3.2 Cumulative Distribution Functions"></a>3.2 Cumulative Distribution Functions</h2><p>Loosely speaking, the $CDF\ F_X(x)$ ‚Äòaccumulates‚Äô probability ‚Äòup to‚Äô the value $x$.</p>
<p>Any random variable associated with a given probability model has a $CDF$, regardless of whether it is discrete or continuous. This is because ${X\leq x}$ is always an event and therefore has a well-defined probability.</p>
<p>In what follows, any unambiguous specification of the probability of all events of the form ${X\leq x}$, be it through a $PMF, PDF$ or $CDF$, will be referred to as the probability law of the random variable $X$. </p>
<p>If $X$ is discrete and takes integer values, the $PMF$ and the $CDF$ can be obtained from each other by summing or differencing.<br>If $X$ is continuous, the $PMF$ and the $CDF$ can be obtained from each other by integration or differentiation.</p>
<p>Example 3.6 The Maximum of Several Random Variables</p>
<h2 id="3-3-Normal-Random-Variables"><a href="#3-3-Normal-Random-Variables" class="headerlink" title="3.3 Normal Random Variables"></a>3.3 Normal Random Variables</h2><p>A continuous random variable $X$ is said to be normal or Gaussian if it has a $PDF$ of the form</p>
<script type="math/tex; mode=display">
f_X(x)={1\over \sqrt{2 \pi}\sigma}e^{-(x-\mu)^2\over2 \sigma^2}</script><p>The mean and the variance can be calculated to be </p>
<script type="math/tex; mode=display">
E[X]=\mu \  \  \ \ \ var(X)=\sigma^2</script><p>Normality is preserved by linear transformation.</p>
<ul>
<li>[ ] ### The Standard Normal Random Variable</li>
</ul>
<p>A normal random variable $Y$ with zero mean and unit variance is said to be standard normal. Its $CDF$ is denoted by $\Phi$:</p>
<script type="math/tex; mode=display">
\Phi(y)=P(Y\leq y)={1\over \sqrt{2 \pi}}\int_{-\infty}^y e^{-t^2\over2 }dt</script><p>More generally, we have</p>
<script type="math/tex; mode=display">
\Phi(-y)=1-\Phi(y)</script><ul>
<li>[ ] ### $CDF$ Calculation for a Normal Random Variable</li>
</ul>
<p>For a normal random variable $X$ with mean $Œº$ and variance $œÉ^2$Ôºå we use a two-step procedure.</p>
<ol>
<li>‚ÄúStandardize‚Äù $X$Ôºåi.e.Ôºåsubtract $Œº$ and divide by $\sigma$ to obtain a standard normal random variable $Y$.</li>
<li>Read the $CDF$ value from the standard normal table:</li>
</ol>
<script type="math/tex; mode=display">
P(X\leq x)=P({X-\mu \over \sigma}\leq{x-\mu \over \sigma})=P(Y \leq {x-\mu \over \sigma})=\Phi({x-\mu \over \sigma})</script><p>Example 3.8 Signal Detection (+1,-1,signal and normal noise)</p>
<h2 id="3-4-Joint-PDFs-of-Multiple-Random-Variables"><a href="#3-4-Joint-PDFs-of-Multiple-Random-Variables" class="headerlink" title="3.4 Joint PDFs of Multiple Random Variables"></a>3.4 Joint PDFs of Multiple Random Variables</h2><p>We say that two continuous random variables associated with the same experiment are jointly continuous and can be described in terms of  a joint $PDF$ $f<em>{X,Y}$ if $f</em>{X,Y}$ is a nonnegative function that satisfies</p>
<script type="math/tex; mode=display">
P((X,Y)\in B) = {\int\int}_{(x,y)\in B} f_{X,Y}dxdy</script><p>We can view $f_{X,Y}(a,c)$ as the ‚Äúprobability per unit area‚Äù in the vicinity of $(a,c)$.</p>
<p>The joint $PDF$ contains all relevant probabilistic information on the random variables $X,Y$ and their dependencies.</p>
<p>Example 3.11 Buffoon‚Äôs Needle</p>
<ul>
<li>[ ] ### Joint $CDF$ </li>
</ul>
<p>If $X$ and $Y$ are two random variables associated with the same experiment, we define their joint $CDF$ by</p>
<script type="math/tex; mode=display">
F_{X,Y}(x,y)=P(X\leq x,Y\leq y) = \int_{-\infty}^x\int_{-\infty}^yf_{X,Y}(s,t)dtds</script><p>Conversely, the $PDF$ can be recovered from the $CDF$ by differentiating:</p>
<script type="math/tex; mode=display">
f_{X,Y}(x,y) = \frac{\partial^2F_{X,Y}}{\partial x\partial y}(x,y)</script><p><img src="https://i.loli.net/2021/11/19/nGrgwfloAFe9tvE.png" style="zoom:80%;"></p>
<h2 id="3-5-Conditioning"><a href="#3-5-Conditioning" class="headerlink" title="3.5 Conditioning"></a>3.5 Conditioning</h2><p>The various definitions and formulas parallel the ones for the discrete case, and their interpretation is similar, except for some subtleties that arise when we condition on an event of ${Y=y}$, which has zero probability.</p>
<ul>
<li>[ ] ### Conditioning a Random Variable on an Event</li>
</ul>
<p>Since we have the original idea towards condition, we just need to write the $P(X\in B, X \in A)$ in terms of the continuous presentation.  </p>
<p><img src="https://i.loli.net/2021/11/19/knmYOHUM2apNGsJ.png" style="zoom:80%;"></p>
<p>Example 3.13 The Exponential Random Variable is Memoryless</p>
<ul>
<li>[ ] ### Conditioning one Random Variable on Another</li>
</ul>
<p>Let $X$ and $Y$ be continuous random variables with joint $PDF$ $f_{X,Y}$. For any $y$ with $f_Y(y) &gt; 0$ the conditional $PDF$ of $X$ given that $Y=y$, is defined by</p>
<script type="math/tex; mode=display">
f_{X|Y}(x|y)={f_{X,Y}(x,y) \over f_Y(y)}</script><p>It is best to view $y$ as a fixed number and consider $f<em>{X|Y}(x|y)$ as a function of the single variable $x$. Viewed as a function of $x$, $f</em>{X|Y}(x|y)$ has the same shape as the joint $PDF$ $f_{X,Y}(x,y)$, because the denominator $f_Y(y)$ does not depend on $x$.</p>
<h2 id="3-6-The-Continuous-Bayes‚Äô-Rule"><a href="#3-6-The-Continuous-Bayes‚Äô-Rule" class="headerlink" title="3.6 The Continuous Bayes‚Äô Rule"></a>3.6 The Continuous Bayes‚Äô Rule</h2><h1 id="4-Further-Topics-on-Random-Variables"><a href="#4-Further-Topics-on-Random-Variables" class="headerlink" title="4. Further Topics on Random Variables"></a>4. Further Topics on Random Variables</h1><h2 id="4-1-Derived-Distributions"><a href="#4-1-Derived-Distributions" class="headerlink" title="4.1 Derived Distributions"></a>4.1 Derived Distributions</h2><h2 id="4-2-Covariance-and-Correlation"><a href="#4-2-Covariance-and-Correlation" class="headerlink" title="4.2 Covariance and Correlation"></a>4.2 Covariance and Correlation</h2><p>In the previous chapters, we just talked about the properties of functions of random variables using their joint distribution. But how about the random variables themselves? In another word, what information can we get from the multiple random variable? So now we are focused on the relationship between the random variables.</p>
<p>When dealing with multiple random variables, it is sometimes useful to use vector and matrix notations. This makes the formulas more compact and lets us use facts from linear algebra. When we have $n$ random variables $X_1, X_2, ‚Ä¶, X_n$ we can put them in a (column) vector $X$:      </p>
<script type="math/tex; mode=display">
X = \begin{bmatrix} X_1\\ X_2\\  \vdots \\ X_n  \end{bmatrix}</script><p>We call $X$ a <strong>random vector</strong>. Here $X$ is an $n-$dimensional vector because it consists of $n$ random variables.  We usually use bold capital letters such as $X,Y$ and $Z$ to represent a random vector. To show a possible value of a random vector we usually use bold lowercase letters such as <strong>x</strong>, <strong>y</strong> and <strong>z</strong>. Thus, we can write the $CDF$ of the random vector $X$ as</p>
<script type="math/tex; mode=display">
\begin{aligned}
F_{\mathbf{X}}(\mathbf{x}) &=F_{X_{1}, X_{2}, \ldots, X_{n}}\left(x_{1}, x_{2}, \ldots, x_{n}\right) \\
&=P\left(X_{1} \leq x_{1}, X_{2} \leq x_{2}, \ldots, X_{n} \leq x_{n}\right)
\end{aligned}</script><p>If the $X_i$‚Äôs are jointly continuous, the $PDF$ of $X$ can be written as</p>
<script type="math/tex; mode=display">
f_{\mathbf{X}}(\mathbf{x}) =f_{X_{1}, X_{2}, \ldots, X_{n}}\left(x_{1}, x_{2}, \ldots, x_{n}\right)</script><p>To calculate the expectation, first let‚Äôs see this, we can transfer the intuition of expectation to the multiple random variable case, that is the interpret the expectation as the center of gravity.(Consider probability as frequency, just think of doing experiments as the process of getting the points, so actually you are spreading out and filling the plain with different mass or density on each point, and when you do the experiment , the expectation is the weighted average of the all points.)</p>
<p><img src="https://i.loli.net/2021/11/19/pYwoMviFZ4APqsX.png" style="zoom:33%;"></p>
<p>And using calculus, we can get the coordinate of center of gravity.</p>
<blockquote>
<p>See here how to calculate: <a target="_blank" rel="noopener" href="http://netedu.xauat.edu.cn/jpkc/netedu/jpkc/gdsx/homepage/5jxsd/52/092.htm">http://netedu.xauat.edu.cn/jpkc/netedu/jpkc/gdsx/homepage/5jxsd/52/092.htm</a></p>
</blockquote>
<p>Actually , the coordinate is $(E[X_1],E[X_2],..,E[X_n])$, a little amazing right?</p>
<p>The <strong>expected value vector</strong> or the <strong>mean vector</strong> of the random vector $X$ is defined as</p>
<script type="math/tex; mode=display">
E[X] = \begin{bmatrix} E[X_1]\\ E[X_2]\\  \vdots \\ E[X_n]  \end{bmatrix}</script><h2 id="4-3-Conditional-Expectation-and-Variance-Revisited"><a href="#4-3-Conditional-Expectation-and-Variance-Revisited" class="headerlink" title="4.3 Conditional Expectation and Variance Revisited"></a>4.3 Conditional Expectation and Variance Revisited</h2><h2 id="4-4-Transforms"><a href="#4-4-Transforms" class="headerlink" title="4.4 Transforms"></a>4.4 Transforms</h2><h2 id="4-5-Sum-of-a-Random-Number-of-Independent-Random-Variables"><a href="#4-5-Sum-of-a-Random-Number-of-Independent-Random-Variables" class="headerlink" title="4.5 Sum of a Random Number of Independent Random Variables"></a>4.5 Sum of a Random Number of Independent Random Variables</h2><h1 id="5-Limit-Theorems"><a href="#5-Limit-Theorems" class="headerlink" title="5. Limit Theorems"></a>5. Limit Theorems</h1><h2 id="Overlook-the-Chapter-2"><a href="#Overlook-the-Chapter-2" class="headerlink" title="Overlook the Chapter"></a>Overlook the Chapter</h2><h2 id="5-1-Markov-and-Chebyshev-Inequalities"><a href="#5-1-Markov-and-Chebyshev-Inequalities" class="headerlink" title="5.1 Markov and Chebyshev Inequalities"></a>5.1 Markov and Chebyshev Inequalities</h2><p>In this section, we derive some important inequalities. These inequalities use the mean and possibly the variance(Chebyshev) of a  random variable to draw conclusions on the probabilities of certain events. They are primarily useful in situations where exact values or bounds for the mean and variance of a random variable $X$ are easily computable, but the distribution of $X$ is either unavailable or hard to calculate.</p>
<ul>
<li>[ ] ### Markov Inequality</li>
</ul>
<p>Loosely speaking(Or Intuitively speaking), it asserts that if a nonnegative random variable has a small mean, then the probability that it takes a large value must also be small.</p>
<script type="math/tex; mode=display">
P(X \geq a) \leq {E[X] \over a},\ \ for\ all \ a >0</script><p><strong>Derivation</strong>(See the book)</p>
<p>But actually, the bounds provided by the Markov inequality can be quiet loose, so let‚Äôs come to a more powerful inequality ‚Äî‚Äî Chebyshev Inequality.</p>
<ul>
<li>[ ] ### Chebyshev Inequality</li>
</ul>
<p>Loosely speaking, it asserts that if a random variable has small variance, then the probability that it takes a value far from its mean is also small.</p>
<blockquote>
<p>ps: the random variable doesn‚Äôt need to be nonnegative.</p>
</blockquote>
<script type="math/tex; mode=display">
P(|X-\mu| \geq c) \leq {\sigma^2 \over c^2}</script><p><strong>Derivation</strong>(See the book)</p>
<p>The Chebyshev inequality tends to be more powerful than the Markov inequality(the bounds that it provides are more accurate), because it also uses information on the variance of $X$. </p>
<p>Still, the mean and the variance of a random variable are only a rough summary of its properties, and we cannot expect the bounds to be close approximations of the exact probabilities.</p>
<p>Example 5.3: Upper Bounds in the Chebyshev Inequality</p>
<h2 id="5-2-The-Weak-law-of-Large-Numbers"><a href="#5-2-The-Weak-law-of-Large-Numbers" class="headerlink" title="5.2 The Weak law of Large Numbers"></a>5.2 The Weak law of Large Numbers</h2><p>The weak law of large numbers asserts that the sample mean of a large number of independent identically distributed(<strong>IID</strong>) random variables is very close to the true mean, with high probability.</p>
<p>Sample mean:</p>
<script type="math/tex; mode=display">
M_n={X_1+...+X_n \over n}</script><p>And the only assumption needed is that $E[X_i]$ is well-defined.</p>
<p>Let $X_1,X_2,‚Ä¶$ be IID variables with mean $\mu$. For every $\epsilon&gt;0$, we have</p>
<script type="math/tex; mode=display">
P(|M_n-\mu| \geq \epsilon)=P(|{X_1+...+X_n \over n}-\mu| \geq \epsilon) \to 0, \ \ \ as\ n \to \infty</script><p>The weak law of large numbers states that for large $n$, the bulk of the distribution of $M_n$ is concentrated near $\mu$. In other words, the sample mean converges in probability to the true mean $\mu$.</p>
<p>Example 5.4 Probabilities and Frequencies</p>
<p>Example 5.5 Polling</p>
<h2 id="5-3-Convergence-in-Probability"><a href="#5-3-Convergence-in-Probability" class="headerlink" title="5.3 Convergence in Probability"></a>5.3 Convergence in Probability</h2><p><strong>Convergence of a Deterministic Sequence</strong></p>
<p><strong>Convergence in Probability</strong></p>
<blockquote>
<p>Just read the definition on the book.</p>
</blockquote>
<p>For convergence in probability, it‚Äôs also instructive to rephrase the above definition as follows: for every $\epsilon&gt;0$ and for every $\delta&gt;0$, there exists some $n_0$ such that</p>
<script type="math/tex; mode=display">
P(|Y_n-a| \geq \epsilon) \leq \delta  \ \ \ \ for\  all\ n \geq n_0</script><p>If we refer to $\epsilon$  as accuracy level, and $\delta$  as the confidence level, the definition takes the following intuitive form: for any given level of accuracy and confidence, $Y_n$ will be equal to $a$, within these levels of accuracy and confidence, provided that $n$ is large enough.</p>
<p>The convergence to a number $a$ of a sequence $Y_n$ does not imply the convergence of $E[Y_n]$ also to $a$. </p>
<p>Example 5.6 Min-sequence convergence</p>
<p>Example 5.7 Exponentially distributed over n sequence convergence</p>
<p>Example 5.8 The difference between convergence in probability and convergence in expectation</p>
<h2 id="5-4-The-Central-Limit-Theorem"><a href="#5-4-The-Central-Limit-Theorem" class="headerlink" title="5.4 The Central Limit Theorem"></a>5.4 The Central Limit Theorem</h2><p> <img src="https://i.loli.net/2021/11/03/XFpueUnV7SZmQDy.png" style="zoom: 50%;"></p>
<p>The distributions of $M_n$ and $S_n$ are kind of extreme, an intermediate view is obtained by considering the deviation $S_n-n\mu $ of $S_n$ from its mean $n\mu$ and scaling it by a factor proportional to $1/\sqrt n$, which keeps the variance at a constant level.</p>
<script type="math/tex; mode=display">
Z_n={S_n-n\mu \over \sigma \sqrt n}</script><p>The central limit theorem asserts that the distribution of this scaled random variable approaches a normal distribution.</p>
<p>Usefulness:</p>
<ol>
<li>Universal. Besides independence, and the implicit assumption that the mean and variance are finite, it places no other requirement on the distribution of $X_i$.</li>
<li>Conceptual side. It indicates that the sum of a large number of independent random variable is approximately normal.</li>
<li>Practical side. It provides accurate computational shortcut only requiring the knowledge of means and variances.</li>
</ol>
<p>And it says that the $CDF$ of $Z_n$ converges to standard normal $CDF$, just a statement of $CDF$, not $PDF$ or $PMF$. In fact, consider $Z_n$ is a discrete random variable, so mathematically speaking it has a $PMF$ not a $PDF$. And in the case where $n$ is not so large, the $PMF$ looks very loose, which can‚Äôt be viewed as a approximation of standard normal $PDF$.  That is why the $CLT$ states that the $CDF$ (not the $PDF$) of $Z_n$ converges to the standard normal $CDF$.  </p>
<p>The following picture can be viewed as a intuitive explanation, where $X_1$ and $X_2$ have been cooked up with the same mean and variance. </p>
<p><img src="https://i.loli.net/2021/11/03/UymrxjOVPS4nsMZ.png" style="zoom: 50%;"></p>
<p>But actually, the shape of $PMF$ or $PDF$ of $Z_n$ gets closer to the normal $PDF$ as $n$ increases. So, we can treat $Z_n$ as if normal. And also for $S_n$, which is just a linear transformation of $Z_n$.</p>
<ul>
<li>[ ] ### Approximations Based on the Central Limit Theorem</li>
</ul>
<p>The normal approximation is increasingly accurate as $n$ tends to infinity, but in practice we are generally faced with specific and finite values of $n$. And usually a small and appropriate number such as $15,20$ can work well. It would be useful to know how large $n$ should be before the approximation can be trusted, but there are no simple and general guidelines. Much depends on whether the distribution of the $X_i$ is close to normal and, in particular, whether it is symmetric. „ÄÅ</p>
<p><img src="https://i.loli.net/2021/11/03/koLqUs67zr5m2pW.png" style="zoom:50%;"></p>
<p><img src="https://i.loli.net/2021/11/03/ziUFj1vKkb7JCum.png" alt="image-20211103143446348.png" style="zoom:50%;"></p>
<p><strong>Calculation method</strong></p>
<p>Since the $CDF$ of $Z_n$ can be viewed as a approximation of standard normal variable $Z$,  it can be viewed as if normal. And $S_n$ and $M_n$ can also be viewed as if normal. So, it comes back to the case of calculating the probability of normal distributed events. Just do the linear transformations on $S_n$ and $M_n$ to get the form of $Z_n$, and use the approximation to transform the original problem to a standard normal distribution problem. The derivation (given $n$ and to find the probability) and the inverse problem (given the probability and to find the appropriate $n$) is just also the same as the standard normal case.</p>
<p>Example 5.10 Machine processes parts in a given time</p>
<p>Example 5.11 Polling</p>
<ul>
<li>[ ] ### De Moivre-Laplace Approximation to the Binomial</li>
</ul>
<p>A binomial random variable $S_n$ with parameter $n$ and $p$ can be viewed as the sum of $n$ independent Bernoulli random variable $X_1,X_2,‚Ä¶,X_n$, with common parameter $p$.</p>
<p>We can use the approximation suggested by the $CLT$ to provide an approximation for the probability of the events ${k \leq S_n\leq l}$, where $k$ and $l$ are given integers, </p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbf{P}\left(k \leq S_{n} \leq l\right) &=\mathbf{P}\left(\frac{k-n p}{\sqrt{n p(1-p)}} \leq \frac{S_{n}-n p}{\sqrt{n p(1-p)}} \leq \frac{l-n p}{\sqrt{n p(1-p)}}\right) \\
& \approx \Phi\left(\frac{l-n p}{\sqrt{n p(1-p)}}\right)-\Phi\left(\frac{k-n p}{\sqrt{n p(1-p)}}\right)
\end{aligned}</script><p>But since the event ${k \leq S_n\leq l}$ is the same as ${k-1 &lt; S_n&lt; l+1}$, it‚Äôs quiet reasonable to think of a nicer approximation. And it turns out that a more accurate approximation may be possible if we replace $k$ and $l$ by $k-{1 \over2}$ and $l-{1 \over2}$, respectively.</p>
<p>In fact, we can use this ${1\over2}$ idea to even calculate the individual probabilities. When $p$ is close to 1/2, in which case the $PMF$ of the $X_i$ is symmetric,the above formula yields a very good approximation for $n$ as low as 40 or 50. When $p$ is near 1 or near 0. the quality of the approximation drops. and a larger value of $n$ is needed to maintain the same accuracy.</p>
<p>Although, the $CLT$ is a statement of $CDF$, and it does not tell you what to do to approximate $PMF$ itself, but in the Binomial case $CLT$ can also give a good approximation on $PMF$.</p>
<ul>
<li>[ ] ### Paradox of CLT</li>
</ul>
<p>Consider a Poisson process that runs over a unit interval and where the arrival rate is equal to 1. And now, divide it into $n$ little pieces as the picture below:</p>
<p><img src="https://i.loli.net/2021/11/03/FefESTVNGZCA27H.png" style="zoom:50%;"></p>
<p>It seems that $X$ should follow a normal distribution, but $X$ just has the Poisson distribution. So what‚Äôs wrong?</p>
<p>In fact, the implicit requirement of $CLT$ is that $X_i$ should be fixed distributed. But $X_i$ in the above case does change when changing the size $n$.</p>
<ul>
<li>[ ] ### The difference between Estimate using Poisson and CLT</li>
</ul>
<h2 id="5-5-The-Strong-law-of-Large-Numbers"><a href="#5-5-The-Strong-law-of-Large-Numbers" class="headerlink" title="5.5 The Strong law of Large Numbers"></a>5.5 The Strong law of Large Numbers</h2><ul>
<li>[ ] ### a</li>
</ul>
<h1 id="6-The-Bernoulli-and-Poisson-Process"><a href="#6-The-Bernoulli-and-Poisson-Process" class="headerlink" title="6. The Bernoulli and Poisson Process"></a>6. The Bernoulli and Poisson Process</h1><h1 id="7-Markov-Chains"><a href="#7-Markov-Chains" class="headerlink" title="7. Markov Chains"></a>7. Markov Chains</h1><h1 id="8-Bayesian-Inference-and-the-Posterior-Distribution"><a href="#8-Bayesian-Inference-and-the-Posterior-Distribution" class="headerlink" title="8. Bayesian Inference and the Posterior Distribution"></a>8. Bayesian Inference and the Posterior Distribution</h1><h1 id="9-Classical-Statistical-Inference"><a href="#9-Classical-Statistical-Inference" class="headerlink" title="9. Classical Statistical Inference"></a>9. Classical Statistical Inference</h1></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">zxr</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://xurui314.github.io/2021/10/20/%E6%A6%82%E7%8E%87%E5%B0%8F%E8%AE%B0/">https://xurui314.github.io/2021/10/20/%E6%A6%82%E7%8E%87%E5%B0%8F%E8%AE%B0/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/">Ê¶ÇÁéáËÆ∫</a></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2021/10/19/hEVDO4xG7U38y6s.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer=""></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/11/15/%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/"><img class="prev-cover" src="https://i.loli.net/2021/10/25/B6bYLRmoNOgWsdZ.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">Êï∞ÁêÜÁªüËÆ°</div></div></a></div><div class="next-post pull-right"><a href="/2021/10/19/%E8%BF%91%E4%B8%96%E4%BB%A3%E6%95%B0/"><img class="next-cover" src="https://i.loli.net/2021/10/19/SatZJoUxDv24jCe.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Ëøë‰∏ñ‰ª£Êï∞Â∞èËÆ∞</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2021/11/15/Êï∞ÁêÜÁªüËÆ°/" title="Êï∞ÁêÜÁªüËÆ°"><img class="cover" src="https://i.loli.net/2021/10/25/B6bYLRmoNOgWsdZ.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-11-15</div><div class="title">Êï∞ÁêÜÁªüËÆ°</div></div></a></div><div><a href="/2021/09/17/ÊµãÂ∫¶Â≠¶‰π†ËµÑÊñô/" title="ÊµãÂ∫¶Â≠¶‰π†ËµÑÊñô"><img class="cover" src="https://i.loli.net/2021/08/24/JvTyhVwqtNWfzur.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-09-17</div><div class="title">ÊµãÂ∫¶Â≠¶‰π†ËµÑÊñô</div></div></a></div><div><a href="/2021/08/15/Êï∞Â≠¶È¢òÁõÆÊé¢Á©∂/" title="Ê¶ÇÁéáËÆ∫Êï∞Â≠¶È¢òÁõÆÊé¢Á©∂"><img class="cover" src="https://i.loli.net/2021/08/15/6CThXjkR4KBQoqe.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-08-15</div><div class="title">Ê¶ÇÁéáËÆ∫Êï∞Â≠¶È¢òÁõÆÊé¢Á©∂</div></div></a></div><div><a href="/2021/09/17/Ê¶ÇÁéáÂíåÊµãÂ∫¶/" title="Ê¶ÇÁéáÂíåÊµãÂ∫¶(ZJUÂ§ß‰Ω¨)"><img class="cover" src="https://i.loli.net/2021/09/17/9H5WSbTrVejOdkz.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-09-17</div><div class="title">Ê¶ÇÁéáÂíåÊµãÂ∫¶(ZJUÂ§ß‰Ω¨)</div></div></a></div><div><a href="/2021/08/09/ÁÇíÈ∏°Â•ΩÁêÜËß£ÁöÑÊµãÂ∫¶ËÆ∫/" title="ÁÇíÈ∏°Â•ΩÁêÜËß£ÁöÑÊµãÂ∫¶ËÆ∫"><img class="cover" src="https://i.loli.net/2021/08/09/zdt4YKoehQvR96S.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-08-09</div><div class="title">ÁÇíÈ∏°Â•ΩÁêÜËß£ÁöÑÊµãÂ∫¶ËÆ∫</div></div></a></div></div></div><hr><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div><div id="comment-switch"><span class="first-comment">Valine</span><span class="switch-btn"></span><span class="second-comment">Disqus</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div><div><div id="disqus_thread"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://s2.loli.net/2021/12/08/yTYthVwXD4IPbJ9.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"></div><div class="author-info__name">zxr</div><div class="author-info__description">Think and Do like an MIT student</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">39</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">20</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">10</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/XuRui314"><i class="fab fa-github"></i><span>This is zxr!üöÄ</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/XuRui314" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://mail.qq.com/" target="_blank" title="Email-1977289398@qq.com"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">zxrÁöÑÁîüÊ¥ªÔºåmathÔºåÁºñÁ®ãËÆ∞ÂΩï</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#General-ideas"><span class="toc-number">1.</span> <span class="toc-text">General ideas</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Probability-and-Measure-theory"><span class="toc-number">1.1.</span> <span class="toc-text">Probability and Measure theory</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Probability-Space"><span class="toc-number">1.1.1.</span> <span class="toc-text">Probability Space</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Discrete-probability-space"><span class="toc-number">1.1.2.</span> <span class="toc-text">Discrete probability space</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Continuous-probability-space"><span class="toc-number">1.1.3.</span> <span class="toc-text">Continuous probability space</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Random-variable"><span class="toc-number">1.1.4.</span> <span class="toc-text">Random variable</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#General"><span class="toc-number">1.1.4.1.</span> <span class="toc-text">General</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Discrete"><span class="toc-number">1.1.4.2.</span> <span class="toc-text">Discrete</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Continuous"><span class="toc-number">1.1.4.3.</span> <span class="toc-text">Continuous</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Study-model"><span class="toc-number">1.2.</span> <span class="toc-text">Study model</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Thinkings-about-Probability-and-The-History-of-Probability"><span class="toc-number">1.3.</span> <span class="toc-text">Thinkings about Probability and The History of Probability</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1-Sample-Space-and-Probability"><span class="toc-number">2.</span> <span class="toc-text">1. Sample Space and Probability</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Overlook-the-Chapter"><span class="toc-number">2.1.</span> <span class="toc-text">Overlook the Chapter</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-Sets"><span class="toc-number">2.2.</span> <span class="toc-text">1.1 Sets</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-Probabilistic-Models"><span class="toc-number">2.3.</span> <span class="toc-text">1.2 Probabilistic Models</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-3-Conditional-Probability"><span class="toc-number">2.4.</span> <span class="toc-text">1.3 Conditional Probability</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-4-Total-Probability-Theorem-and-Bayes%E2%80%99-Rule"><span class="toc-number">2.5.</span> <span class="toc-text">1.4 Total Probability Theorem and Bayes‚Äô Rule</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-5-Independence"><span class="toc-number">2.6.</span> <span class="toc-text">1.5 Independence</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-6-Counting"><span class="toc-number">2.7.</span> <span class="toc-text">1.6 Counting</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-Discrete-Random-Variables"><span class="toc-number">3.</span> <span class="toc-text">2. Discrete Random Variables</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Overlook-the-Chapter-1"><span class="toc-number">3.1.</span> <span class="toc-text">Overlook the Chapter</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-Basic-Concepts"><span class="toc-number">3.2.</span> <span class="toc-text">2.1 Basic Concepts</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-Probability-Mass-Functions"><span class="toc-number">3.3.</span> <span class="toc-text">2.2 Probability Mass Functions</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-3-Functions-of-Random-Variables"><span class="toc-number">3.4.</span> <span class="toc-text">2.3 Functions of Random Variables</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-4-Expectation-Mean-and-Variance"><span class="toc-number">3.5.</span> <span class="toc-text">2.4 Expectation, Mean, and Variance</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-5-Joint-PMFs-of-Multiple-Random-Variables"><span class="toc-number">3.6.</span> <span class="toc-text">2.5 Joint PMFs of Multiple Random Variables</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-6-Conditioning"><span class="toc-number">3.7.</span> <span class="toc-text">2.6 Conditioning</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-7-Independence"><span class="toc-number">3.8.</span> <span class="toc-text">2.7 Independence</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-General-Random-Variables"><span class="toc-number">4.</span> <span class="toc-text">3. General Random Variables</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-Continuous-Random-Variables-and-PDFs"><span class="toc-number">4.1.</span> <span class="toc-text">3.1 Continuous Random Variables and PDFs</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2-Cumulative-Distribution-Functions"><span class="toc-number">4.2.</span> <span class="toc-text">3.2 Cumulative Distribution Functions</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-3-Normal-Random-Variables"><span class="toc-number">4.3.</span> <span class="toc-text">3.3 Normal Random Variables</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-4-Joint-PDFs-of-Multiple-Random-Variables"><span class="toc-number">4.4.</span> <span class="toc-text">3.4 Joint PDFs of Multiple Random Variables</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-5-Conditioning"><span class="toc-number">4.5.</span> <span class="toc-text">3.5 Conditioning</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-6-The-Continuous-Bayes%E2%80%99-Rule"><span class="toc-number">4.6.</span> <span class="toc-text">3.6 The Continuous Bayes‚Äô Rule</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-Further-Topics-on-Random-Variables"><span class="toc-number">5.</span> <span class="toc-text">4. Further Topics on Random Variables</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#4-1-Derived-Distributions"><span class="toc-number">5.1.</span> <span class="toc-text">4.1 Derived Distributions</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-2-Covariance-and-Correlation"><span class="toc-number">5.2.</span> <span class="toc-text">4.2 Covariance and Correlation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-3-Conditional-Expectation-and-Variance-Revisited"><span class="toc-number">5.3.</span> <span class="toc-text">4.3 Conditional Expectation and Variance Revisited</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-4-Transforms"><span class="toc-number">5.4.</span> <span class="toc-text">4.4 Transforms</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-5-Sum-of-a-Random-Number-of-Independent-Random-Variables"><span class="toc-number">5.5.</span> <span class="toc-text">4.5 Sum of a Random Number of Independent Random Variables</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#5-Limit-Theorems"><span class="toc-number">6.</span> <span class="toc-text">5. Limit Theorems</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Overlook-the-Chapter-2"><span class="toc-number">6.1.</span> <span class="toc-text">Overlook the Chapter</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-1-Markov-and-Chebyshev-Inequalities"><span class="toc-number">6.2.</span> <span class="toc-text">5.1 Markov and Chebyshev Inequalities</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-2-The-Weak-law-of-Large-Numbers"><span class="toc-number">6.3.</span> <span class="toc-text">5.2 The Weak law of Large Numbers</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-3-Convergence-in-Probability"><span class="toc-number">6.4.</span> <span class="toc-text">5.3 Convergence in Probability</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-4-The-Central-Limit-Theorem"><span class="toc-number">6.5.</span> <span class="toc-text">5.4 The Central Limit Theorem</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-5-The-Strong-law-of-Large-Numbers"><span class="toc-number">6.6.</span> <span class="toc-text">5.5 The Strong law of Large Numbers</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#6-The-Bernoulli-and-Poisson-Process"><span class="toc-number">7.</span> <span class="toc-text">6. The Bernoulli and Poisson Process</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#7-Markov-Chains"><span class="toc-number">8.</span> <span class="toc-text">7. Markov Chains</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#8-Bayesian-Inference-and-the-Posterior-Distribution"><span class="toc-number">9.</span> <span class="toc-text">8. Bayesian Inference and the Posterior Distribution</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#9-Classical-Statistical-Inference"><span class="toc-number">10.</span> <span class="toc-text">9. Classical Statistical Inference</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/01/10/Asuka/" title="Asuka"><img src="https://s2.loli.net/2022/01/10/naGjKA2SuoWtZkc.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Asuka"></a><div class="content"><a class="title" href="/2022/01/10/Asuka/" title="Asuka">Asuka</a><time datetime="2022-01-10T11:42:45.000Z" title="Created 2022-01-10 19:42:45">2022-01-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/01/09/%E8%87%AA%E6%88%91%E5%8F%8D%E7%9C%81/" title="Self-criticism"><img src="https://s2.loli.net/2022/01/09/7uczh3dySMCm1Y5.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Self-criticism"></a><div class="content"><a class="title" href="/2022/01/09/%E8%87%AA%E6%88%91%E5%8F%8D%E7%9C%81/" title="Self-criticism">Self-criticism</a><time datetime="2022-01-09T15:41:25.000Z" title="Created 2022-01-09 23:41:25">2022-01-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/01/06/java-learning/" title="java learning"><img src="https://s2.loli.net/2022/01/06/xacLs9uH5RWeUME.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="java learning"></a><div class="content"><a class="title" href="/2022/01/06/java-learning/" title="java learning">java learning</a><time datetime="2022-01-06T11:16:33.000Z" title="Created 2022-01-06 19:16:33">2022-01-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/01/02/English-learning/" title="English learning"><img src="https://s2.loli.net/2022/01/02/xDYFpqLMn82OE9G.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="English learning"></a><div class="content"><a class="title" href="/2022/01/02/English-learning/" title="English learning">English learning</a><time datetime="2022-01-01T16:07:18.000Z" title="Created 2022-01-02 00:07:18">2022-01-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/01/01/Artificial-intelligence/" title="Artificial intelligence"><img src="https://s2.loli.net/2022/01/02/TuMvU6KqNaLOfwF.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Artificial intelligence"></a><div class="content"><a class="title" href="/2022/01/01/Artificial-intelligence/" title="Artificial intelligence">Artificial intelligence</a><time datetime="2022-01-01T15:36:15.000Z" title="Created 2022-01-01 23:36:15">2022-01-01</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">¬©2020 - 2022 By zxr</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="github-badge"><a style="color: #fff" rel="license" href="https://hexo.io/" target="_blank" title="Áî± Hexo Âº∫ÂäõÈ©±Âä®"><span class="badge-subject">Powered</span><span class="badge-value bg-blue">Hexo</span></a><a style="color: #fff" rel="license" href="https://gitee.com/" target="_blank" title="ÈùôÊÄÅÁΩëÈ°µÊâòÁÆ°‰∫é GitHub Pages Âíå Coding Pages Âíå Gitee Pages"><span class="badge-subject">Hosted</span><span class="badge-value bg-brightgreen">GitHub &amp; Coding &amp; Gitee</span></a><a style="color: #fff" rel="license" href="https://www.jsdelivr.com/" target="_blank" title="jsDelivr Êèê‰æõ CDN Âä†ÈÄüÊúçÂä°"><span class="badge-subject">CDN</span><span class="badge-value bg-orange">jsDelivr</span></a><a style="color: #fff" rel="license" href="https://jerryc.me" target="_blank" title="Á´ôÁÇπ‰ΩøÁî® Butterfly‰∏ªÈ¢ò"><span class="badge-subject">Theme</span><span class="badge-value bg-blue">Butterfly</span></a><a style="color: #fff" rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" title="Êú¨Á´ôÁÇπÈááÁî®Áü•ËØÜÂÖ±‰∫´ÁΩ≤Âêç-ÈùûÂïÜ‰∏öÊÄß‰ΩøÁî®-Áõ∏ÂêåÊñπÂºèÂÖ±‰∫´ 4.0 ÂõΩÈôÖËÆ∏ÂèØÂçèËÆÆËøõË°åËÆ∏ÂèØ"><span class="badge-subject"><i class="fa fa-copyright"></i></span><span class="badge-value bg-lightgrey">BY-NC-SA 4.0  </span></a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="Increase font size"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="Decrease font size"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = '[object Object]'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: '',
      appKey: '',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script>function loadDisqus () {
  var disqus_config = function () {
    this.page.url = 'https://xurui314.github.io/2021/10/20/%E6%A6%82%E7%8E%87%E5%B0%8F%E8%AE%B0/'
    this.page.identifier = '2021/10/20/Ê¶ÇÁéáÂ∞èËÆ∞/'
    this.page.title = 'Ê¶ÇÁéáÂ∞èËÆ∞'
  };

  window.disqusReset = () => {
    DISQUS.reset({
      reload: true,
      config: disqus_config
    })
  }

  if (window.DISQUS) disqusReset()
  else {
    (function() { 
      var d = document, s = d.createElement('script');
      s.src = 'https://.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  }
}

if ('Valine' === 'Disqus' || !false) {
  if (false) btf.loadComment(document.getElementById('disqus_thread'), loadDisqus)
  else loadDisqus()
} else {
  function loadOtherComment () {
    loadDisqus()
  }
}
</script></div><script src="https://cdn.jsdelivr.net/gh/XuRui314/live2d-widget@1.0.1/autoload.js"></script><script src="/js/title.js"></script><script src="/dist/nochocolate.js"></script><div id="aplayer"></div><script type="text/javascript" src="/dist/APlayer.min.js"></script><script type="text/javascript" src="/dist/music.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/gh/metowolf/MetingJS@1.2/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = [
  'title',
  '#config-diff',
  '#body-wrap',
  '#rightside-config-hide',
  '#rightside-config-show',
  '.js-pjax'
]

if (false) {
  pjaxSelectors.unshift('meta[property="og:image"]', 'meta[property="og:title"]', 'meta[property="og:url"]')
}

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.removeEventListener('scroll', window.tocScrollFn)
  window.removeEventListener('scroll', scrollCollect)

  typeof preloader === 'object' && preloader.initLoading()
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // Analytics
  if (false) {
    MtaH5.pgv()
  }

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async="" data-pjax="" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax="">if(document.getElementById('recent-posts') && (location.pathname ==='all'|| 'all' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/Math/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">üìö zxr„ÅÆÊï∞Â≠¶‰∏ñÁïå (10)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/ÁÆóÊ≥ïÂ≠¶‰π†/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">üéÆ zxr„ÅÆÁÆóÊ≥ïÂ≠¶‰π† (5)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/ÁîüÊ¥ªË∂£Èóª/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">üê±‚Äçüëì zxr„ÅÆÁîüÊ¥ªË∂£Èóª (4)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/ÁºñÁ®ãÂÆû‰æã/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">üë©‚Äçüíª zxr„ÅÆÁºñÁ®ãÂ≠¶‰π† (4)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/ÁîüÊ¥ªÊÑüÊÇü/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">üö¥‚Äç‚ôÇ zxr„ÅÆÁîüÊ¥ªÊÑüÊÇü (9)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/Hexo/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">üíå zxr„ÅÆBlogËÆ∞ÂΩï (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="https://XuRui314.github.io/categories" style="flex:1;text-align: center;margin-bottom: 10px;">Êü•ÁúãÊõ¥Â§ö...</a></div></div>';
    console.log('Â∑≤ÊåÇËΩΩmagnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style> <script data-pjax="">if(document.getElementById('recent-posts') && location.pathname =='/'){
    
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/09/17/9H5WSbTrVejOdkz.jpg" alt="https://i.loli.net/2021/09/17/9H5WSbTrVejOdkz.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-09-17</span><a class="blog-slider__title" href="2021/09/17/Ê¶ÇÁéáÂíåÊµãÂ∫¶/">Ê¶ÇÁéáÂíåÊµãÂ∫¶(ZJUÂ§ß‰Ω¨)</a><div class="blog-slider__text">Êù•ÁúãÁúãZJUËÆ°ÁßëÂ§ß‰Ω¨Ëß£ÈáäÊ¶ÇÁéáÂíåÊµãÂ∫¶ü•ô</div><a class="blog-slider__button" href="2021/09/17/Ê¶ÇÁéáÂíåÊµãÂ∫¶/">ËØ¶ÊÉÖ</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/25/bPy5m3j9QAilwr2.jpg" alt="https://i.loli.net/2021/08/25/bPy5m3j9QAilwr2.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-08-26</span><a class="blog-slider__title" href="2021/08/26/ÁÆóÊ≥ïÈ¢òÁõÆÁªÉ‰π†/">AcWing-Oj-Âà∑È¢òÂ≠¶‰π†ËÆ∞ÂΩï(Âü∫Á°ÄÁÆóÊ≥ï)</a><div class="blog-slider__text">Êù•ÁúãÁÆóÊ≥ïËíüËíªÁöÑ‰∏¢‰∫∫Êó•Â∏∏Âïäüë©‚Äçü¶Ω</div><a class="blog-slider__button" href="2021/08/26/ÁÆóÊ≥ïÈ¢òÁõÆÁªÉ‰π†/">ËØ¶ÊÉÖ</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/15/NYcSXrECnvzOiLP.jpg" alt="https://i.loli.net/2021/08/15/NYcSXrECnvzOiLP.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-08-15</span><a class="blog-slider__title" href="2021/08/15/‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúËØÜÂà´ÊâãÂÜôÊï∞Â≠ó/">‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúËØÜÂà´ÊâãÂÜôÊï∞Â≠ó</a><div class="blog-slider__text">ËØÜÂà´ÊâãÂÜôÊï∞Â≠óÊúÄÁÆÄÂçïÁöÑÂÆûÁé∞üß¶</div><a class="blog-slider__button" href="2021/08/15/‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúËØÜÂà´ÊâãÂÜôÊï∞Â≠ó/">ËØ¶ÊÉÖ</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/15/F8aP7R36IidpCt5.jpg" alt="https://i.loli.net/2021/08/15/F8aP7R36IidpCt5.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-08-14</span><a class="blog-slider__title" href="2021/08/14/Á•ûÁªèÁΩëÁªúÊê≠Âª∫ÂáÜÂ§áÂÜÖÂÆπ/">Á•ûÁªèÁΩëÁªúÊê≠Âª∫ÂáÜÂ§áÂÜÖÂÆπ</a><div class="blog-slider__text">Â¶Ç‰ΩïËØÜÂà´ÊâãÂÜôüî¢ÔºåzxrÂ∏¶‰Ω†‰∏ÄÊ≠•‰∏ÄÊ≠•ÂÆûÁé∞üéº</div><a class="blog-slider__button" href="2021/08/14/Á•ûÁªèÁΩëÁªúÊê≠Âª∫ÂáÜÂ§áÂÜÖÂÆπ/">ËØ¶ÊÉÖ</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/12/SJs3MgYC7x8IU26.jpg" alt="https://i.loli.net/2021/08/12/SJs3MgYC7x8IU26.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-08-12</span><a class="blog-slider__title" href="2021/08/12/xuperchain-solidity/">xuperchain&solidity</a><div class="blog-slider__text">Âå∫ÂùóÈìæ‰∏çÊ≠¢ÊòØÊåñÂ∏ÅÔºåËøòÊúâvÁ•ûÂíåsolidityüéà</div><a class="blog-slider__button" href="2021/08/12/xuperchain-solidity/">ËØ¶ÊÉÖ</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/07/27/6fy8mTCbAOWPkrq.png" alt="https://i.loli.net/2021/07/27/6fy8mTCbAOWPkrq.png"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-07-26</span><a class="blog-slider__title" href="2021/07/26/FFT/">FFTÁöÑËØ¶Ëß£</a><div class="blog-slider__text">Ëøô‰πàÂ•ΩÁúãÁöÑFFTÔºå‰ø°Âè∑ÁãóÈÉΩÈ¶ãÂì≠‰∫Üüí¶</div><a class="blog-slider__button" href="2021/07/26/FFT/">ËØ¶ÊÉÖ</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/09/zdt4YKoehQvR96S.jpg" alt="https://i.loli.net/2021/08/09/zdt4YKoehQvR96S.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-08-09</span><a class="blog-slider__title" href="2021/08/09/ÁÇíÈ∏°Â•ΩÁêÜËß£ÁöÑÊµãÂ∫¶ËÆ∫/">ÁÇíÈ∏°Â•ΩÁêÜËß£ÁöÑÊµãÂ∫¶ËÆ∫</a><div class="blog-slider__text">‰∏âÊÆµÂ≠óÔºåËÆ©‰Ω†ËØªÊáÇÊµãÂ∫¶ËÆ∫</div><a class="blog-slider__button" href="2021/08/09/ÁÇíÈ∏°Â•ΩÁêÜËß£ÁöÑÊµãÂ∫¶ËÆ∫/">ËØ¶ÊÉÖ</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/12/wF7TJlqxOLEWGQk.png" alt="https://i.loli.net/2021/08/12/wF7TJlqxOLEWGQk.png"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-07-27</span><a class="blog-slider__title" href="2021/07/27/FT/">ÂÇÖÈáåÂè∂Â≠¶‰π†ËµÑÊñô</a><div class="blog-slider__text">ÁÆÄÂçïÂ•ΩÂ≠¶ÁöÑÂÇÖÈáåÂè∂Â≠¶‰π†ËµÑÊñô</div><a class="blog-slider__button" href="2021/07/27/FT/">ËØ¶ÊÉÖ</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/07/27/f7jO8hlNpzWVXSP.jpg" alt="https://i.loli.net/2021/07/27/f7jO8hlNpzWVXSP.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-07-26</span><a class="blog-slider__title" href="2021/07/26/hello-world/">Â§ßÈ∏üËΩ¨ËΩ¨ËΩ¨ÈÖíÂêßÂÜÖÈÉ®ÁªùÂØÜÊ°£Ê°à</a><div class="blog-slider__text">‰∏çË¶ÅÁÇπËøõÊù•QAQÔºÅ</div><a class="blog-slider__button" href="2021/07/26/hello-world/">ËØ¶ÊÉÖ</a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('Â∑≤ÊåÇËΩΩswiper')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script>
<script data-pjax="" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper/swiper/swiper.min.js"></script>
<script data-pjax="" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper@0.18/swiper/swiperindex.js"></script>
<style></style><script data-pjax="">function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('Â∑≤ÊåÇËΩΩelectric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // Êó†Êä•ÈîôÔºå‰ΩÜ‰∏çÂΩ±Âìç‰ΩøÁî®(ÊîØÊåÅpjaxË∑≥ËΩ¨)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // ÊúâÊä•ÈîôÔºå‰ΩÜ‰∏çÂΩ±Âìç‰ΩøÁî®(ÊîØÊåÅpjaxË∑≥ËΩ¨)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax="" src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script>
  <script data-pjax="" src="https://cdn.jsdelivr.net/gh/Zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script>
  <script data-pjax="">
        function GithubCalendarConfig(){
            var git_githubapiurl ="https://python-github-calendar-api.vercel.app/api?XuRui314";
            var git_color =['#ebedf0', '#fdcdec', '#fc9bd9', '#fa6ac5', '#f838b2', '#f5089f', '#c4067e', '#92055e', '#540336', '#48022f', '#30021f'];
            var git_user ="XuRui314";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="height:100%;display: flex;align-items: center;justify-content: center;"><svg style="height:50px" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>';
            if(parent_div_git && location.pathname =='/'){
                console.log('Â∑≤ÊåÇËΩΩgithub calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // Êó†Êä•ÈîôÔºå‰ΩÜ‰∏çÂΩ±Âìç‰ΩøÁî®(ÊîØÊåÅpjaxË∑≥ËΩ¨)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // ÊúâÊä•ÈîôÔºå‰ΩÜ‰∏çÂΩ±Âìç‰ΩøÁî®(ÊîØÊåÅpjaxË∑≥ËΩ¨)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:248px}@media screen and (max-width:650px) {#github_container{background-image:;min-height:0px}}</style>
    <style></style><script async="" src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"live2d-widget-model-wanko"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.7},"log":false});</script></body></html>