<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Machine Learning Code | XuRui-Blog</title><meta name="keywords" content="Python,Machine Learning"><meta name="author" content="zxr"><meta name="copyright" content="zxr"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Just record the codes implement without using the library functions. One algorithm One day.   Courses: MIT_6.036 Python Stanford_cs231n  ËøôÈÉ®ÂàÜÂÆûÂú®ÊòØÂ§™Â§ö‰∫ÜÔºåÂêéÊù•Áõ¥Êé•Â∞±Êê¨Âà∞github‰∏ä‰∫ÜÔºåÊÉ≥ÁúãÂÆåÊï¥ÁâàÔºåÂèØ‰ª•Âéª‰∏ãÈù¢ÁöÑlinkÔºö https://github.com">
<meta property="og:type" content="article">
<meta property="og:title" content="Machine Learning Code">
<meta property="og:url" content="https://xurui314.github.io/2022/01/14/Machine-Learning-Coding/index.html">
<meta property="og:site_name" content="XuRui-Blog">
<meta property="og:description" content="Just record the codes implement without using the library functions. One algorithm One day.   Courses: MIT_6.036 Python Stanford_cs231n  ËøôÈÉ®ÂàÜÂÆûÂú®ÊòØÂ§™Â§ö‰∫ÜÔºåÂêéÊù•Áõ¥Êé•Â∞±Êê¨Âà∞github‰∏ä‰∫ÜÔºåÊÉ≥ÁúãÂÆåÊï¥ÁâàÔºåÂèØ‰ª•Âéª‰∏ãÈù¢ÁöÑlinkÔºö https://github.com">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://s2.loli.net/2022/01/14/LaGcAPJX9QpgTBH.jpg">
<meta property="article:published_time" content="2022-01-14T12:42:54.000Z">
<meta property="article:modified_time" content="2022-02-18T04:13:41.452Z">
<meta property="article:author" content="zxr">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="Machine Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2022/01/14/LaGcAPJX9QpgTBH.jpg"><link rel="shortcut icon" href="https://i.loli.net/2021/07/27/lSHRJbx7dYwTk8f.jpg"><link rel="canonical" href="https://xurui314.github.io/2022/01/14/Machine-Learning-Coding/"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Machine Learning Code',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-02-18 12:13:41'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    document.addEventListener('pjax:complete', detectApple)})(window)</script><link rel="stylesheet" href="/css/badge.css"><link rel="stylesheet" href="/css/modify.css"><link rel="stylesheet" href="/css/mouse.css"><link rel="stylesheet" href="/dist/APlayer.min.css"><link rel="stylesheet" href="/css/custom.css"><link rel="stylesheet" href="/css/bilibiliBanner.css" media="defer" onload="this.media='screen'"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper/swiper/swiper.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper/swiper/swiperstyle.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css">
<style>#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags:before {content:"\A";
  white-space: pre;}#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags > .article-meta__separator{display:none}</style>
<link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script async="" src="https://unpkg.zhimg.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://s2.loli.net/2021/12/08/yTYthVwXD4IPbJ9.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">76</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">35</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">16</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> ‰∏ªÈ°µüç≠</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Ê°£Ê°àüåä</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Ê†áÁ≠æüìë</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> ÂàÜÁ±ªüåà</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> Â•ΩÂ∫∑ÁöÑ‚ú®</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener" href="https://ocw.mit.edu/"><i class="fa-fw fas fa-link"></i><span> Êù•Â≠¶È∫ªÂ≠¶</span></a></li><li><a class="site-page child" href="/bangumis/"><i class="fa-fw fas fa-video"></i><span> zxr„ÅÆËøΩÁï™ËÆ°Âàí</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=RyOyXsKuUgI"><i class="fa-fw fas fa-heart"></i><span> zxrÊúÄÁà±Êª¥upÂòâÂÄ©</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://oskarstalberg.com/game/planet/planet.html"><span> Planet</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> ÂèãÈìæüíï</span></a></div><div class="menus_item"><a class="site-page" href="https://xurui314.github.io/aboutme/"><span> AboutMeüèÇ</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.foreverblog.cn/go.html"><span> Ëô´Ê¥û</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://s2.loli.net/2022/01/14/LaGcAPJX9QpgTBH.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">XuRui-Blog</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> ‰∏ªÈ°µüç≠</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Ê°£Ê°àüåä</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Ê†áÁ≠æüìë</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> ÂàÜÁ±ªüåà</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> Â•ΩÂ∫∑ÁöÑ‚ú®</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener" href="https://ocw.mit.edu/"><i class="fa-fw fas fa-link"></i><span> Êù•Â≠¶È∫ªÂ≠¶</span></a></li><li><a class="site-page child" href="/bangumis/"><i class="fa-fw fas fa-video"></i><span> zxr„ÅÆËøΩÁï™ËÆ°Âàí</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=RyOyXsKuUgI"><i class="fa-fw fas fa-heart"></i><span> zxrÊúÄÁà±Êª¥upÂòâÂÄ©</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://oskarstalberg.com/game/planet/planet.html"><span> Planet</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> ÂèãÈìæüíï</span></a></div><div class="menus_item"><a class="site-page" href="https://xurui314.github.io/aboutme/"><span> AboutMeüèÇ</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.foreverblog.cn/go.html"><span> Ëô´Ê¥û</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Machine Learning Code</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2022-01-14T12:42:54.000Z" title="Created 2022-01-14 20:42:54">2022-01-14</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2022-02-18T04:13:41.452Z" title="Updated 2022-02-18 12:13:41">2022-02-18</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Machine-Learning/">Machine Learning</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">5.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>32min</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Machine Learning Code"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><div class="top-img" style="background-image: url('https://s2.loli.net/2022/01/14/LaGcAPJX9QpgTBH.jpg');"></div><article class="post-content" id="article-container"><blockquote>
<p>Just record the codes implement without using the library functions.</p>
<p>One algorithm One day.</p>
</blockquote>
<blockquote>
<p>Courses:</p>
<p><a target="_blank" rel="noopener" href="https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/course/">MIT_6.036</a></p>
<p><a target="_blank" rel="noopener" href="https://pythonprogramming.net/machine-learning-tutorials/">Python</a></p>
<p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=d14TUNcbn1k&amp;list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk&amp;index=4">Stanford_cs231n</a></p>
</blockquote>
<p>ËøôÈÉ®ÂàÜÂÆûÂú®ÊòØÂ§™Â§ö‰∫ÜÔºåÂêéÊù•Áõ¥Êé•Â∞±Êê¨Âà∞github‰∏ä‰∫ÜÔºåÊÉ≥ÁúãÂÆåÊï¥ÁâàÔºåÂèØ‰ª•Âéª‰∏ãÈù¢ÁöÑ<strong>link</strong>Ôºö</p>
<p><a target="_blank" rel="noopener" href="https://github.com/XuRui314/MIT_6.036_homework_zxr">https://github.com/XuRui314/MIT_6.036_homework_zxr</a></p>
<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">MIT's CAT~</span><br><span class="line"></span><br><span class="line">ML                                                                          </span><br><span class="line">/    /\__/\     mio~                                                            </span><br><span class="line">\__=(  o_O )=                                                                       </span><br><span class="line">(__________)                                                    </span><br><span class="line"> |_ |_ |_ |_                                                            </span><br></pre></td></tr></tbody></table></figure>
<h1>Preparation Knowledge</h1>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://github.com/XuRui314/MIT_6.036_homework_zxr/blob/main/MIT_6_036_HW01_Linear_Classfier.ipynb">Click here!</a></p>
</blockquote>
<h1>Supervised Learning</h1>
<h2 id="No-Model">No Model</h2>
<h3 id="KNN">KNN</h3>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> style</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> sqrt</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line">style.use(<span class="string">'fivethirtyeight'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">k_nearest</span>(<span class="params">dataset, test_point, k = <span class="number">3</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(dataset) &gt;= k:</span><br><span class="line">        warnings.warn(<span class="string">'K is set to a value less than total voting groups!'</span>)</span><br><span class="line">    distances = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> group <span class="keyword">in</span> dataset:</span><br><span class="line">        <span class="keyword">for</span> feature_point <span class="keyword">in</span> dataset[group]:</span><br><span class="line">            euclidean_distance = sqrt((test_point[<span class="number">0</span>] - feature_point[<span class="number">0</span>] )**<span class="number">2</span> + (test_point[<span class="number">1</span>] - feature_point[<span class="number">1</span>] )**<span class="number">2</span>)</span><br><span class="line">            distances.append([euclidean_distance,group])</span><br><span class="line"></span><br><span class="line">    votes = [i[<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">sorted</span>(distances)[:k]]</span><br><span class="line">    vote_result = Counter(votes).most_common(<span class="number">1</span>)[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># votes contain the group character ['k', 'k', 'r']</span></span><br><span class="line">    <span class="comment"># print(Counter(votes).most_common(1))</span></span><br><span class="line">    <span class="comment"># You can see the Counter method also contains the #votes, so we use[0] to get['k', 2]</span></span><br><span class="line">    <span class="comment"># and [0][0] to get 'k'</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> vote_result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dataset = {<span class="string">'k'</span>: [[<span class="number">10</span>, <span class="number">20</span>], [<span class="number">20</span>, <span class="number">30</span>], [<span class="number">30</span>, <span class="number">10</span>]], <span class="string">'r'</span>: [[<span class="number">60</span>, <span class="number">50</span>], [<span class="number">70</span>, <span class="number">45</span>], [<span class="number">80</span>, <span class="number">90</span>]]}</span><br><span class="line"></span><br><span class="line">test_point = [<span class="number">20</span>, <span class="number">70</span>]</span><br><span class="line"></span><br><span class="line">[[plt.scatter(ii[<span class="number">0</span>],ii[<span class="number">1</span>],s=<span class="number">100</span>,color= i) <span class="keyword">for</span> ii <span class="keyword">in</span> dataset[i]] <span class="keyword">for</span> i <span class="keyword">in</span> dataset]</span><br><span class="line"></span><br><span class="line"><span class="comment"># the same as:</span></span><br><span class="line"><span class="comment"># for i in dataset:</span></span><br><span class="line"><span class="comment">#     for j in dataset[i]:</span></span><br><span class="line"><span class="comment">#         plt.scatter(j[0],j[1],s=100,color= i)</span></span><br><span class="line"><span class="comment"># i represents the 'k' and 'r'</span></span><br><span class="line"></span><br><span class="line">prediction = k_nearest(dataset, test_point, k = <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"prediction is"</span>, prediction)</span><br><span class="line"></span><br><span class="line">plt.scatter(test_point[<span class="number">0</span>], test_point[<span class="number">1</span>], s = <span class="number">100</span>, marker = <span class="string">'+'</span>, color = prediction)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<img src="https://s2.loli.net/2022/01/19/xK7rW6mZHIaPRkY.png" style="zoom: 80%;">
<h2 id="Linear-classification">Linear classification</h2>
<blockquote>
<p>The same model, with the same prediction rule: <img src="https://math.now.sh?inline=sign%28%20%5Ctheta%5E%7B%5Cmathsf%20T%7D%5Cmathsf%20x%20%2B%20%5Ctheta_0%20%29" style="display:inline-block;margin: 0;"></p>
<p>And i will introduce some learning algorithm below:</p>
</blockquote>
<h3 id="Perceptron">Perceptron</h3>
<p><a target="_blank" rel="noopener" href="https://introml_oll.odl.mit.edu/cat-soop/_static/6.036/homework/hw02/code_for_hw02_downloadable.zip">download lab</a></p>
<p><strong>python</strong></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. transpose is not equal to reshape(col, row)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. understand broadcast</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. split &amp; concatenate</span></span><br><span class="line">ji = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>]])</span><br><span class="line">ji = np.array_split(ji, <span class="number">2</span>,, axis = <span class="number">0</span>) <span class="comment"># axis = 0 means each row</span></span><br><span class="line">output: a <span class="built_in">list</span></span><br><span class="line">[array([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">6</span>]]), </span><br><span class="line"> array([[ <span class="number">7</span>,  <span class="number">8</span>],</span><br><span class="line">       [ <span class="number">9</span>, <span class="number">10</span>]])]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">j2 = np.concatenate(j, axis = <span class="number">0</span>) <span class="comment"># ÂèÇÊï∞‰∏ç‰∏ÄÂÆöÊòØ()tupleÔºåÂåÖ‰Ωèsequence of arrayÂç≥ÂèØ</span></span><br><span class="line">output: a matrix(ndarray) </span><br><span class="line">j2 <span class="keyword">is</span> the same <span class="keyword">as</span> ji</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. list &amp; matrix addation</span></span><br><span class="line"><span class="built_in">list</span> addition:</span><br><span class="line">    j = ji[<span class="number">0</span>:<span class="number">1</span>] + ji[<span class="number">1</span>:<span class="number">2</span>]</span><br><span class="line">output: the same <span class="keyword">as</span> ji</span><br><span class="line">[array([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">6</span>]]), </span><br><span class="line"> array([[ <span class="number">7</span>,  <span class="number">8</span>],</span><br><span class="line">       [ <span class="number">9</span>, <span class="number">10</span>]])]</span><br><span class="line"></span><br><span class="line">matrix addition:  </span><br><span class="line">    j2 = ji[<span class="number">0</span>:<span class="number">1</span>, :] + ji[<span class="number">2</span>:<span class="number">4</span>, :]</span><br><span class="line">output: broadcast</span><br><span class="line">    [[ <span class="number">6</span>  <span class="number">8</span>]</span><br><span class="line">    [ <span class="number">8</span> <span class="number">10</span>]]</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"><span class="comment"># 4. mulitplication</span></span><br><span class="line">C = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line">C*C</span><br><span class="line">output: array([[ <span class="number">1</span>,  <span class="number">4</span>,  <span class="number">9</span>, <span class="number">16</span>]])</span><br><span class="line">    mulitplied entry by entry</span><br></pre></td></tr></tbody></table></figure>
<p><code>1.</code> <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/72128096">ÁúüÊ≠£ÁêÜËß£ transpose Âíå reshape - Áü•‰πé (zhihu.com)</a></p>
<p><code>2.</code> <a target="_blank" rel="noopener" href="https://numpy.org/doc/stable/user/basics.broadcasting.html">numpy broadcast</a></p>
<blockquote>
<p>Notation convention: mit lab uses col vector, and the matrix is represented as <img src="https://math.now.sh?inline=d" style="display:inline-block;margin: 0;"> x <img src="https://math.now.sh?inline=n" style="display:inline-block;margin: 0;">Ôºå<img src="https://math.now.sh?inline=d" style="display:inline-block;margin: 0;"> is the dimension of data vectors and <img src="https://math.now.sh?inline=n" style="display:inline-block;margin: 0;"> is the number of vectors</p>
</blockquote>
<p><strong>Implement perceptron</strong></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># x is dimension d by 1</span></span><br><span class="line"><span class="comment"># th is dimension d by 1</span></span><br><span class="line"><span class="comment"># th0 is dimension 1 by 1</span></span><br><span class="line"><span class="comment"># return 1 by 1 matrix of +1, 0, -1</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">positive</span>(<span class="params">x, th, th0</span>):</span></span><br><span class="line">   <span class="keyword">return</span> np.sign(th.T@x + th0)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Perceptron algorithm with offset.</span></span><br><span class="line"><span class="comment"># data is dimension d by n</span></span><br><span class="line"><span class="comment"># labels is dimension 1 by n</span></span><br><span class="line"><span class="comment"># T is a positive integer number of steps to run</span></span><br><span class="line"><span class="comment"># Perceptron algorithm with offset.</span></span><br><span class="line"><span class="comment"># data is dimension d by n</span></span><br><span class="line"><span class="comment"># labels is dimension 1 by n</span></span><br><span class="line"><span class="comment"># T is a positive integer number of steps to run</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">perceptron</span>(<span class="params">data, labels, params = {}, hook = <span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="comment"># if T not in params, default to 100</span></span><br><span class="line">    T = params.get(<span class="string">'T'</span>, <span class="number">100</span>)</span><br><span class="line">    (d, n) = data.shape</span><br><span class="line"></span><br><span class="line">    theta = np.zeros((d, <span class="number">1</span>)); theta_0 = np.zeros((<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(T):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            x = data[:,i:i+<span class="number">1</span>]</span><br><span class="line">            y = labels[:,i:i+<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">if</span> y * positive(x, theta, theta_0) &lt;= <span class="number">0.0</span>:</span><br><span class="line">                theta = theta + y * x</span><br><span class="line">                theta_0 = theta_0 + y</span><br><span class="line">                <span class="keyword">if</span> hook: hook((theta, theta_0))</span><br><span class="line">    <span class="keyword">return</span> theta, theta_0</span><br></pre></td></tr></tbody></table></figure>
<p><strong>Implement averaged perceptron</strong></p>
<p>Regular perceptron can be somewhat sensitive to the most recent examples that it sees. Instead, averaged perceptron produces a more stable output by outputting the average value of <code>th</code> and <code>th0</code> across all iterations.</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># row representation</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">averaged_perceptron</span>(<span class="params">data, labels, params = {}, hook = <span class="literal">None</span></span>):</span></span><br><span class="line">       <span class="comment"># if T not in params, default to 100</span></span><br><span class="line">    T = params.get(<span class="string">'T'</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Your implementation here</span></span><br><span class="line">    (d, n) = data.shape</span><br><span class="line">    th = np.zeros((<span class="number">1</span>, d)); ths = np.zeros((<span class="number">1</span>, d)) <span class="comment"># 2-dim</span></span><br><span class="line">    th0 = np.zeros((<span class="number">1</span>, <span class="number">1</span>)); th0s = np.zeros((<span class="number">1</span>, <span class="number">1</span>)) <span class="comment"># 2-dim</span></span><br><span class="line">    data = data.T <span class="comment"># row representation</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(T):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            yi = labels[:, i : i + <span class="number">1</span>] <span class="comment"># 2-dim</span></span><br><span class="line">            xi = data[i:i+<span class="number">1</span>, :] <span class="comment"># 2-dim</span></span><br><span class="line">            <span class="string">'''</span></span><br><span class="line"><span class="string">            also can be written as</span></span><br><span class="line"><span class="string">            yi = labels[0, i] # 1-dim</span></span><br><span class="line"><span class="string">            xi = data[i] # 1-dim</span></span><br><span class="line"><span class="string">            '''</span></span><br><span class="line">            <span class="keyword">if</span> yi * (xi@th.T + th0) &lt;= <span class="number">0.0</span>:</span><br><span class="line">                th += yi * xi</span><br><span class="line">                th0 += yi</span><br><span class="line">                <span class="keyword">if</span> hook: hook((th, th0))</span><br><span class="line">            ths += th</span><br><span class="line">            th0s += th0</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (ths / (n * T)).T, th0s / (n * T)</span><br></pre></td></tr></tbody></table></figure>
<p><strong>Evaluating a classifier</strong></p>
<ul>
<li><code>data</code>: a d by n array of floats (representing n data points in d dimensions)</li>
<li><code>labels</code>: a 1 by n array of elements in (+1, -1), representing target labels</li>
<li><code>th</code>: a d by 1 array of floats that together with</li>
<li><code>th0</code>: a single scalar or 1 by 1 array, represents a hyperplane</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">eval_classifier</span>(<span class="params">learner, data_train, labels_train, data_test, labels_test</span>):</span></span><br><span class="line">    (d, t) = data_test.shape</span><br><span class="line">    th = np.zeros((d, <span class="number">1</span>)); th0 = np.zeros((<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    th, th0 = learner(data_train, labels_train)</span><br><span class="line">    ans = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(t):</span><br><span class="line">        x = data_test[:,i:i+<span class="number">1</span>]</span><br><span class="line">        y = labels_test[:,i:i+<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span>(np.sign(th.T@x + th0) == y):</span><br><span class="line">            ans = ans + <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">float</span>(ans) / k</span><br></pre></td></tr></tbody></table></figure>
<p>**Evaluating a learning algorithm using a data source **</p>
<p>Returns a scalar number of data points that the separator correctly classified.</p>
<p>The eval_classifier function should accept the following parameters:</p>
<ul>
<li><code>learner</code> - a function, such as perceptron or averaged_perceptron</li>
<li><code>data_train</code> - training data</li>
<li><code>labels_train</code> - training labels</li>
<li><code>data_test</code> - test data</li>
<li><code>labels_test</code> - test labels</li>
</ul>
<p>and returns the percentage correct on a new testing set as a float between 0. and 1.</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">eval_learning_alg</span>(<span class="params">learner, data_gen, n_train, n_test, it</span>):</span></span><br><span class="line">    ans = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(it):</span><br><span class="line">        (data_train, labels_train) = data_gen(n_train)</span><br><span class="line">        (data_test, labels_test) = data_gen(n_test)</span><br><span class="line">        an = eval_classifier(learner, data_train, labels_train, data_test, labels_test)</span><br><span class="line">        ans += an</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> ans / it</span><br></pre></td></tr></tbody></table></figure>
<p><strong>The difference between evaluating the classifier and the learning algorithm</strong></p>
<p>One classifier is just one specific result from the learning algorithm. To evaluate the learning algorithm, we can choose to average over a set of test data.</p>
<p><strong>Evaluating a learning algorithm using a data source</strong></p>
<ul>
<li><code>data_gen</code> - a data generator, call it with a desired data set size; returns a tuple (data, labels)</li>
<li><code>it</code> - the number of iterations to average over</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">eval_learning_alg</span>(<span class="params">learner, data_gen, n_train, n_test, it</span>):</span></span><br><span class="line">    ans = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(it):</span><br><span class="line">        (data_train, labels_train) = data_gen(n_train)</span><br><span class="line">        (data_test, labels_test) = data_gen(n_test)</span><br><span class="line">        an = eval_classifier(learner, data_train, labels_train, data_test, labels_test)</span><br><span class="line">        ans += an</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> ans / it</span><br></pre></td></tr></tbody></table></figure>
<p><strong>Evaluating a learning algorithm with a fixed dataset</strong></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">xval_learning_alg</span>(<span class="params">learner, data, labels, k</span>):</span></span><br><span class="line">    s_data = np.array_split(data, k, axis=<span class="number">1</span>)</span><br><span class="line">    s_labels = np.array_split(labels, k, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    score_sum = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">        data_train = np.concatenate(s_data[:i] + s_data[i+<span class="number">1</span>:], axis=<span class="number">1</span>)</span><br><span class="line">        labels_train = np.concatenate(s_labels[:i] + s_labels[i+<span class="number">1</span>:], axis=<span class="number">1</span>)</span><br><span class="line">        data_test = np.array(s_data[i])</span><br><span class="line">        labels_test = np.array(s_labels[i])</span><br><span class="line">        score_sum += eval_classifier(learner, data_train, labels_train,</span><br><span class="line">                                              data_test, labels_test)</span><br><span class="line">    <span class="keyword">return</span> score_sum/k</span><br></pre></td></tr></tbody></table></figure>
<p><a target="_blank" rel="noopener" href="https://github.com/XuRui314/MIT_6.036_homework_zxr/blob/main/MIT_6_036_HW03_Feature_Representation.ipynb">Lab</a></p>
<h3 id="SVM">SVM</h3>
<h4 id="brute-force">brute force</h4>
<p><a target="_blank" rel="noopener" href="https://pythonprogramming.net/predictions-svm-machine-learning-tutorial/?completed=/svm-optimization-python-2-machine-learning-tutorial/">svm_basic</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV19E411c7B5?from=search&amp;seid=16239299400440471946&amp;spm_id_from=333.337.0.0">‰∏ÄËµ∑Â≠¶ML‰πãÊîØÊåÅÂêëÈáèÊú∫Ôºå‰∏Ä‰∏™SVMÁÆóÊ≥ïÁöÑPythonÂÆûÁé∞Ôºà2Ôºâ_ÂìîÂì©ÂìîÂì©_bilibili</a></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> style</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">style.use(<span class="string">'ggplot'</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Support_Vector_Machine</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, visualization = <span class="literal">True</span></span>):</span></span><br><span class="line">        self.visualization = visualization</span><br><span class="line">        self.colors = {<span class="number">1</span>: <span class="string">'r'</span>, -<span class="number">1</span>: <span class="string">'b'</span>}</span><br><span class="line">        <span class="keyword">if</span> self.visualization:</span><br><span class="line">            self.fig = plt.figure()</span><br><span class="line">            self.ax = self.fig.add_subplot(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># train</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, data</span>):</span></span><br><span class="line">        self.data = data</span><br><span class="line"></span><br><span class="line">        <span class="comment"># {||w||: [w, b]}</span></span><br><span class="line">        opt_dict = {}</span><br><span class="line"></span><br><span class="line">        <span class="comment"># w is first set with angle 45 degree</span></span><br><span class="line">        rotMatrix = <span class="keyword">lambda</span> theta: np.array([np.sin(theta), np.cos(theta)])</span><br><span class="line"></span><br><span class="line">        theta_step = np.pi / <span class="number">10</span></span><br><span class="line">        transforms = [np.array(rotMatrix(theta))</span><br><span class="line">                        <span class="keyword">for</span> theta <span class="keyword">in</span> np.arange(<span class="number">0</span>, np.pi, theta_step)]</span><br><span class="line"></span><br><span class="line">        all_data = []</span><br><span class="line">        <span class="keyword">for</span> yi <span class="keyword">in</span> self.data:</span><br><span class="line">            <span class="keyword">for</span> featureset <span class="keyword">in</span> self.data[yi]:</span><br><span class="line">                <span class="keyword">for</span> feature <span class="keyword">in</span> featureset:</span><br><span class="line">                    all_data.append(feature)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        self.max_feature_value = <span class="built_in">max</span>(all_data)</span><br><span class="line">        self.min_feature_value = <span class="built_in">min</span>(all_data)</span><br><span class="line">        all_data = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        step_sizes = [self.max_feature_value * <span class="number">0.1</span>,</span><br><span class="line">                      self.max_feature_value * <span class="number">0.01</span>,</span><br><span class="line">                      <span class="comment"># starts getting very high cost after this</span></span><br><span class="line">                      self.max_feature_value * <span class="number">0.001</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># extremely expensive</span></span><br><span class="line">        b_range_multiple = <span class="number">5</span></span><br><span class="line">        b_multiple = <span class="number">5</span></span><br><span class="line">        latest_optimum = self.max_feature_value * <span class="number">10</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> step <span class="keyword">in</span> step_sizes:</span><br><span class="line">            w = np.array([latest_optimum, latest_optimum])</span><br><span class="line"></span><br><span class="line">            <span class="comment"># we can do this because convex</span></span><br><span class="line">            optimized = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">while</span> <span class="keyword">not</span> optimized:</span><br><span class="line">                <span class="keyword">for</span> b <span class="keyword">in</span> np.arange(-<span class="number">1</span> * (self.max_feature_value * b_range_multiple),</span><br><span class="line">                                    <span class="number">1</span> * (self.max_feature_value * b_range_multiple),</span><br><span class="line">                                    step * b_multiple):</span><br><span class="line">                    <span class="keyword">for</span> transform <span class="keyword">in</span> transforms:</span><br><span class="line">                        w_t = w * transform</span><br><span class="line">                        found_option = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">                        <span class="keyword">for</span> i <span class="keyword">in</span> self.data:</span><br><span class="line">                            <span class="keyword">for</span> xi <span class="keyword">in</span> self.data[i]:</span><br><span class="line">                                yi = i</span><br><span class="line">                                <span class="keyword">if</span> <span class="keyword">not</span> yi * (np.dot(w_t, xi) + b) &gt;= <span class="number">1</span>:</span><br><span class="line">                                    found_option = <span class="literal">False</span></span><br><span class="line">                                    <span class="keyword">break</span></span><br><span class="line">                            <span class="keyword">if</span> <span class="keyword">not</span> found_option:</span><br><span class="line">                                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">                        <span class="keyword">if</span> found_option:</span><br><span class="line">                            opt_dict[np.linalg.norm(w_t)] = [w_t, b]</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> w[<span class="number">0</span>] &lt; <span class="number">0</span>:</span><br><span class="line">                    optimized = <span class="literal">True</span></span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">"+1 optimized\n"</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    w = w - step</span><br><span class="line"></span><br><span class="line">            norms = <span class="built_in">sorted</span>([n <span class="keyword">for</span> n <span class="keyword">in</span> opt_dict])</span><br><span class="line">            opt_choice = opt_dict[norms[<span class="number">0</span>]]</span><br><span class="line">            self.w = opt_choice[<span class="number">0</span>]</span><br><span class="line">            self.b = opt_choice[<span class="number">1</span>]</span><br><span class="line">            latest_optimum = opt_choice[<span class="number">0</span>][<span class="number">0</span>] * step * <span class="number">2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, features</span>):</span></span><br><span class="line">        classification = np.sign(np.dot(self.w, np.array(features)) + self.b)</span><br><span class="line">        <span class="keyword">if</span> classification != <span class="number">0</span> <span class="keyword">and</span> self.visualization:</span><br><span class="line">            self.ax.scatter(features[<span class="number">0</span>], features[<span class="number">1</span>], s = <span class="number">200</span>, marker = <span class="string">'*'</span>, c = self.colors[classification])</span><br><span class="line">        <span class="keyword">return</span> classification</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">visualize</span>(<span class="params">self</span>):</span></span><br><span class="line">        [[self.ax.scatter(x[<span class="number">0</span>], x[<span class="number">1</span>], s=<span class="number">100</span>, color=self.colors[i]) <span class="keyword">for</span> x <span class="keyword">in</span> data_dict[i]] <span class="keyword">for</span> i <span class="keyword">in</span> data_dict]</span><br><span class="line">        <span class="comment"># hyperplane = x.w+b</span></span><br><span class="line">        <span class="comment"># v = x.w+b</span></span><br><span class="line">        <span class="comment"># psv = 1</span></span><br><span class="line">        <span class="comment"># nsv = -1</span></span><br><span class="line">        <span class="comment"># dec = 0</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">hyperplane</span>(<span class="params">x,w,b,v</span>):</span></span><br><span class="line">            <span class="keyword">return</span> (-w[<span class="number">0</span>]*x-b+v) / w[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        datarange = (self.min_feature_value*<span class="number">0.9</span>,self.max_feature_value*<span class="number">1.1</span>)</span><br><span class="line">        hyp_x_min = datarange[<span class="number">0</span>]</span><br><span class="line">        hyp_x_max = datarange[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># (w.x+b) = 1</span></span><br><span class="line">        <span class="comment"># positive support vector hyperplane</span></span><br><span class="line">        psv1 = hyperplane(hyp_x_min, self.w, self.b, <span class="number">1</span>)</span><br><span class="line">        psv2 = hyperplane(hyp_x_max, self.w, self.b, <span class="number">1</span>)</span><br><span class="line">        self.ax.plot([hyp_x_min,hyp_x_max],[psv1,psv2], <span class="string">'k'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># (w.x+b) = -1</span></span><br><span class="line">        <span class="comment"># negative support vector hyperplane</span></span><br><span class="line">        nsv1 = hyperplane(hyp_x_min, self.w, self.b, -<span class="number">1</span>)</span><br><span class="line">        nsv2 = hyperplane(hyp_x_max, self.w, self.b, -<span class="number">1</span>)</span><br><span class="line">        self.ax.plot([hyp_x_min,hyp_x_max],[nsv1,nsv2], <span class="string">'k'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># (w.x+b) = 0</span></span><br><span class="line">        <span class="comment"># positive support vector hyperplane</span></span><br><span class="line">        db1 = hyperplane(hyp_x_min, self.w, self.b, <span class="number">0</span>)</span><br><span class="line">        db2 = hyperplane(hyp_x_max, self.w, self.b, <span class="number">0</span>)</span><br><span class="line">        self.ax.plot([hyp_x_min,hyp_x_max],[db1,db2], <span class="string">'y--'</span>)</span><br><span class="line"></span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data_dict = {-<span class="number">1</span>: np.array([[<span class="number">1</span>, <span class="number">8</span>],[<span class="number">2</span>, <span class="number">3</span>],[<span class="number">3</span>, <span class="number">6</span>]]),</span><br><span class="line">             <span class="number">1</span>: np.array([[<span class="number">1</span>, -<span class="number">2</span>],[<span class="number">3</span>, -<span class="number">4</span>],[<span class="number">3</span>, <span class="number">0</span>]])}</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">svm =Support_Vector_Machine()</span><br><span class="line">svm.fit(data = data_dict)</span><br><span class="line"></span><br><span class="line">predict_us = [[<span class="number">0</span>,<span class="number">10</span>],</span><br><span class="line">              [<span class="number">1</span>,<span class="number">3</span>],</span><br><span class="line">              [<span class="number">3</span>,<span class="number">4</span>],</span><br><span class="line">              [<span class="number">5</span>,<span class="number">8</span>]]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> predict_us:</span><br><span class="line">    svm.predict(p)</span><br><span class="line"></span><br><span class="line">svm.visualize()</span><br></pre></td></tr></tbody></table></figure>
<img src="https://s2.loli.net/2022/01/23/IjNAGhmgzQJo3F9.png" style="zoom:80%;">
<h4 id="Kernel-method">Kernel method</h4>
<p># loading‚Ä¶</p>
<h2 id="Network-classification">Network classification</h2>
<h3 id="NN-neural-network">NN(neural network)</h3>
<blockquote>
<p>This part may be a little abundant, but each part will be introduced really in detail.</p>
</blockquote>
<p>For simplicity but enough to cover the basic ideas of NN, i will just choose the Two Layer NN for the code example.</p>
<p>So, before diving into the neural net construction, let‚Äôs first set down the main parts and each part‚Äô targets.</p>
<ol>
<li>
<p>The understanding <strong>fundamentals of neural net</strong>.<br>
Including the functions(based on mini-batch) that are used through the building process.</p>
</li>
<li>
<p>The <strong>preparation of data set</strong>, that is the MINIST data set.</p>
<p>Including the operations of loading the data set, using the data.</p>
</li>
<li>
<p>The <strong>implement of structure of NN</strong>, just the structure.</p>
<p>Including the weight„ÄÅbias matrix.</p>
</li>
<li>
<p>The <strong>mini-batch method and its implement</strong>.</p>
<p>Including the design of functions and design of echo.</p>
</li>
</ol>
<p>I‚Äôll use python to realize the whole procedure.</p>
<p>As a result of using mini-batch, there may be some methods will be used later that you are not so familiar with.</p>
<p>So now, I‚Äôm gonna to introduce them:</p>
<h4 id="Methods">Methods</h4>
<p><strong>python basic</strong></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#in python, you should know that</span></span><br><span class="line">Invariant <span class="built_in">type</span>: integer, <span class="built_in">float</span>, long, <span class="built_in">complex</span>, string, <span class="built_in">tuple</span>, <span class="built_in">frozenset</span></span><br><span class="line">Variant <span class="built_in">type</span>: <span class="built_in">list</span>, dictionary, <span class="built_in">set</span>, numpy array, user defined objects</span><br><span class="line"><span class="string">""""</span></span><br><span class="line"><span class="string">When we pass a paramter to a function, if a the variable type is variant, the inner change in the function will also cause the outter value change.</span></span><br><span class="line"><span class="string">"""</span> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## lambda</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span>(<span class="params">m, n</span>):</span></span><br><span class="line">    <span class="keyword">return</span> m - n</span><br><span class="line">x = <span class="number">3</span></span><br><span class="line">t = <span class="number">2</span></span><br><span class="line">f = <span class="keyword">lambda</span> w: loss(x, t)</span><br><span class="line"><span class="comment"># the same as</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span>(<span class="params">w</span>):</span></span><br><span class="line">    <span class="keyword">return</span> loss(x, t) <span class="comment"># This is calling another function, and x, t are arguments not parameters</span></span><br><span class="line">ans = f(x) <span class="comment"># ans = 1</span></span><br><span class="line"><span class="string">""" w is only a pseudo paramter, the reason of using lambda is to simplify coding."""</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## enumerate()</span></span><br><span class="line"><span class="comment"># iterate through an array</span></span><br><span class="line">bar = np.array([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>, <span class="number">5</span>],[<span class="number">8</span>,<span class="number">9</span>]])</span><br><span class="line"><span class="built_in">list</span>(<span class="built_in">enumerate</span>(bar))</span><br><span class="line"><span class="comment"># output: [(0, array([1, 2])), (1, array([3, 5])), (2, array([8, 9]))]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> idx,x <span class="keyword">in</span> <span class="built_in">enumerate</span>(bar):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f"idx is <span class="subst">{idx}</span>, x is"</span>,x)</span><br><span class="line">    </span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">output: idx is 0, x is [1 2]</span></span><br><span class="line"><span class="string">idx is 1, x is [3 5]</span></span><br><span class="line"><span class="string">idx is 2, x is [8 9]</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></tbody></table></figure>
<p><strong>numpy basic: shape</strong></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## numpy basic</span></span><br><span class="line">x = np.array([[<span class="number">0.1</span>, <span class="number">0.8</span>, <span class="number">0.1</span>], [<span class="number">0.3</span>, <span class="number">0.1</span>, <span class="number">0.6</span>], [<span class="number">0.2</span>, <span class="number">0.5</span>, <span class="number">0.3</span>], [<span class="number">0.8</span>, <span class="number">0.1</span>, <span class="number">0.6</span>]])</span><br><span class="line"></span><br><span class="line">x.ndim <span class="comment"># output: 2</span></span><br><span class="line">x.shape <span class="comment"># output: (4, 3)</span></span><br><span class="line">x.size <span class="comment"># output: 12 numbers of elements</span></span><br><span class="line">x.argmax(axis = <span class="number">1</span>) <span class="comment"># output: array([1, 2, 1, 0])</span></span><br><span class="line"><span class="string">""" axis = 1 means in each row, find the max number's index """</span></span><br><span class="line"></span><br><span class="line">x.reshape(<span class="number">1</span>, x.size)</span><br><span class="line"><span class="comment"># change x to 2d-vector form, not 1d-vector</span></span><br><span class="line"><span class="comment"># output:</span></span><br><span class="line">array([[<span class="number">0.1</span>, <span class="number">0.8</span>, <span class="number">0.1</span>, <span class="number">0.3</span>, <span class="number">0.1</span>, <span class="number">0.6</span>, <span class="number">0.2</span>, <span class="number">0.5</span>, <span class="number">0.3</span>, <span class="number">0.8</span>, <span class="number">0.1</span>, <span class="number">0.6</span>]])</span><br><span class="line"></span><br><span class="line">x.reshape(<span class="number">2</span>, <span class="number">6</span>)</span><br><span class="line"><span class="comment"># output: </span></span><br><span class="line">array([[<span class="number">0.1</span>, <span class="number">0.8</span>, <span class="number">0.1</span>, <span class="number">0.3</span>, <span class="number">0.1</span>, <span class="number">0.6</span>],</span><br><span class="line">       [<span class="number">0.2</span>, <span class="number">0.5</span>, <span class="number">0.3</span>, <span class="number">0.8</span>, <span class="number">0.1</span>, <span class="number">0.6</span>]])</span><br><span class="line"><span class="comment"># change x to 2 rows, 6 colunms array, in the order of row index</span></span><br></pre></td></tr></tbody></table></figure>
<p><strong>numpy basic: operation</strong></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([[<span class="number">0.1</span>, <span class="number">0.8</span>, <span class="number">0.1</span>], [<span class="number">0.3</span>, <span class="number">0.1</span>, <span class="number">0.6</span>], [<span class="number">0.2</span>, <span class="number">0.5</span>, <span class="number">0.3</span>], [<span class="number">0.8</span>, <span class="number">0.1</span>, <span class="number">0.6</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># get one single element</span></span><br><span class="line">x[<span class="number">0</span>, <span class="number">1</span>] <span class="keyword">or</span> x[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line"><span class="comment"># output: 0.8</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># get row vecotors</span></span><br><span class="line">x[[<span class="number">0</span>, <span class="number">2</span>]]</span><br><span class="line"><span class="comment"># output:</span></span><br><span class="line">array([[<span class="number">0.1</span>, <span class="number">0.8</span>, <span class="number">0.1</span>], [<span class="number">0.2</span>, <span class="number">0.5</span>, <span class="number">0.3</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># matrix - 1d vector</span></span><br><span class="line"><span class="comment"># every row minus the vector</span></span><br><span class="line">x - [<span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.1</span>]</span><br><span class="line"><span class="comment"># output:</span></span><br><span class="line">array([[<span class="number">0.</span> , <span class="number">0.7</span>, <span class="number">0.</span> ],</span><br><span class="line">       [<span class="number">0.2</span>, <span class="number">0.</span> , <span class="number">0.5</span>],</span><br><span class="line">       [<span class="number">0.1</span>, <span class="number">0.4</span>, <span class="number">0.2</span>],</span><br><span class="line">       [<span class="number">0.7</span>, <span class="number">0.</span> , <span class="number">0.5</span>]])</span><br><span class="line"><span class="string">""" </span></span><br><span class="line"><span class="string">The vector must have the same size as the row vector.</span></span><br><span class="line"><span class="string">In the softmax function, we use the traverse method to avoid the mistake.</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Traverse method</span></span><br><span class="line">x.T</span><br><span class="line"><span class="comment"># output: </span></span><br><span class="line">array([[<span class="number">0.1</span>, <span class="number">0.3</span>, <span class="number">0.2</span>, <span class="number">0.8</span>],</span><br><span class="line">       [<span class="number">0.8</span>, <span class="number">0.1</span>, <span class="number">0.5</span>, <span class="number">0.1</span>],</span><br><span class="line">       [<span class="number">0.1</span>, <span class="number">0.6</span>, <span class="number">0.3</span>, <span class="number">0.6</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># get specific elements </span></span><br><span class="line">x &lt;= <span class="number">0.5</span></span><br><span class="line"><span class="comment"># output:</span></span><br><span class="line">array([[ <span class="literal">True</span>, <span class="literal">False</span>,  <span class="literal">True</span>],</span><br><span class="line">       [ <span class="literal">True</span>,  <span class="literal">True</span>, <span class="literal">False</span>],</span><br><span class="line">       [ <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>],</span><br><span class="line">       [<span class="literal">False</span>,  <span class="literal">True</span>, <span class="literal">False</span>]])</span><br><span class="line"></span><br><span class="line">x[(x &lt;= <span class="number">0.5</span>)]</span><br><span class="line"><span class="comment"># output:</span></span><br><span class="line">array([<span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.3</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.5</span>, <span class="number">0.3</span>, <span class="number">0.1</span>])</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<p><strong>numpy random</strong></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## numpy random</span></span><br><span class="line"><span class="comment"># np.random.randn: array ramdom generation</span></span><br><span class="line">x = np.random.randn(<span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line"><span class="comment"># get a 2 row, 4 column array, whose elements are correspond to normal distribution. </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># np.random.choice: randomly pick numbers</span></span><br><span class="line">train_size = x_train.shape[<span class="number">0</span>]</span><br><span class="line">batch_size = <span class="number">10</span></span><br><span class="line">batch_mask = np.random.choice(train_size, batch_size)</span><br><span class="line"><span class="comment"># the same as np.random.choice(60000, 10), pick 10 numbers randomly from 0-59999, and generate an index array.</span></span><br><span class="line"></span><br><span class="line">x_batch = x_train[batch_mask]</span><br><span class="line">t_batch = t_train[batch_mask]</span><br></pre></td></tr></tbody></table></figure>
<p><strong>numpy.nditer</strong></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## numpy.nditer</span></span><br><span class="line">it = np.nditer(x, flags=[<span class="string">'multi_index'</span>], op_flags=[<span class="string">'readwrite'</span>]) <span class="comment"># type: numpy.nditer</span></span><br><span class="line"></span><br><span class="line"><span class="string">""""</span></span><br><span class="line"><span class="string">np.nditer is used to iterare through an array, the parameter flags = ['multi_index'] means you can just use it.multi_index to get the index of it[0](current element) in the original array.</span></span><br><span class="line"><span class="string">"""</span><span class="string">"</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># example</span></span><br><span class="line"><span class="string">x = np.arange(6).reshape(2,3)</span></span><br><span class="line"><span class="string">it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])</span></span><br><span class="line"><span class="string">while not it.finished:</span></span><br><span class="line"><span class="string">    print("</span>%d &lt;%s&gt;<span class="string">" % (it[0], it.multi_index))</span></span><br><span class="line"><span class="string">    it.iternext()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 0 &lt;(0, 0)&gt;</span></span><br><span class="line"><span class="string"># 1 &lt;(0, 1)&gt;</span></span><br><span class="line"><span class="string"># 2 &lt;(0, 2)&gt;</span></span><br><span class="line"><span class="string"># 3 &lt;(1, 0)&gt;</span></span><br><span class="line"><span class="string"># 4 &lt;(1, 1)&gt;</span></span><br><span class="line"><span class="string"># 5 &lt;(1, 2)&gt;</span></span><br></pre></td></tr></tbody></table></figure>
<h4 id="Data-processing">Data processing</h4>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> dataset.mnist <span class="keyword">import</span> load_mnist</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">    load MNIST dataset</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    normalize : Â∞ÜÂõæÂÉèÁöÑÂÉèÁ¥†ÂÄºÊ≠£ËßÑÂåñ‰∏∫0.0~1.0</span></span><br><span class="line"><span class="string">    one_hot_label : </span></span><br><span class="line"><span class="string">        one_hot_label‰∏∫TrueÁöÑÊÉÖÂÜµ‰∏ãÔºåÊ†áÁ≠æ‰Ωú‰∏∫one-hotÊï∞ÁªÑËøîÂõû</span></span><br><span class="line"><span class="string">        one-hotÊï∞ÁªÑÊòØÊåá[0,0,1,0,0,0,0,0,0,0]ËøôÊ†∑ÁöÑÊï∞ÁªÑ</span></span><br><span class="line"><span class="string">    flatten : ÊòØÂê¶Â∞ÜÂõæÂÉèÂ±ïÂºÄ‰∏∫‰∏ÄÁª¥Êï∞ÁªÑ</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">    (ËÆ≠ÁªÉÂõæÂÉè, ËÆ≠ÁªÉÊ†áÁ≠æ), (ÊµãËØïÂõæÂÉè, ÊµãËØïÊ†áÁ≠æ)</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">(x_train, t_train), (x_test, t_test) = load_mnist(normalize = <span class="literal">True</span>, one_hot_label = <span class="literal">True</span>)</span><br><span class="line"><span class="string">""""</span></span><br><span class="line"><span class="string"> x_train and t_train are array type</span></span><br><span class="line"><span class="string"> x_train.shape: (60000, 784)</span></span><br><span class="line"><span class="string"> t_train.shape: (60000, ) just the 1d-vector</span></span><br><span class="line"><span class="string">"""</span><span class="string">"</span></span><br><span class="line"><span class="string"></span></span><br></pre></td></tr></tbody></table></figure>
<h4 id="Functions">Functions</h4>
<p>Neural network can be used in classification and regression problems, but the output needs to be changed according to the specific situation.</p>
<p>When it comes to the choice of output layer activation function, generally speaking, in the regression problem, we usually use the identity function and in the classification problem  we usually use the softmax function.</p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/295247085/answer/1778398778">‰∫åÂàÜÁ±ªÈóÆÈ¢òÔºåÂ∫îËØ•ÈÄâÊã©sigmoidËøòÊòØsoftmax?</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/105722023">sigmoid and softmax</a></p>
<p><strong>softmax</strong></p>
<p style=""><img src="https://math.now.sh?from=y_k%3D%20%7Bexp%28a_k%29%20%5Cover%20%5Csum_%7Bi%3D1%7D%5En%20exp(a_i)%7D%3D%20%7Bexp(a_k%20%2B%20C)%20%5Cover%20%5Csum_%7Bi%3D1%7D%5En%20exp(a_i%20%2B%20C)%7D%0A"></p><p>Because of  the property of <img src="https://math.now.sh?inline=y_k%20%5Cin%20%5B0%2C1%5D" style="display:inline-block;margin: 0;"> and <img src="https://math.now.sh?inline=%5Csum_ky_k%20%3D%201" style="display:inline-block;margin: 0;">, we can interpret <img src="https://math.now.sh?inline=y_k" style="display:inline-block;margin: 0;"> as probability. And in practice, we usually use <img src="https://math.now.sh?inline=C" style="display:inline-block;margin: 0;"> (often chosen with the maximum number in <img src="https://math.now.sh?inline=y_k" style="display:inline-block;margin: 0;">) to avoid overflow.</p>
<img src="https://s2.loli.net/2022/01/16/NUKG2JmAEserZPb.png" style="zoom:50%;">
<blockquote>
<p>The picture above use the sigmoid function as the activation function,  whereas the below one uses softmax.</p>
</blockquote>
<img src="https://s2.loli.net/2022/01/16/baoAPnTRO4qj3dS.png" style="zoom: 50%;">
<p><strong>loss function</strong></p>
<p>mean squared error</p>
<p style=""><img src="https://math.now.sh?from=E%20%3D%20%7B1%5Cover2%7D%20%5Csum_k%28y_k-t_k%29%5E2%0A"></p><p>cross entropy error</p>
<p style=""><img src="https://math.now.sh?from=E%20%3D%20-%5Csum_kt_kln%5E%7By_k%7D%0A"></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># sigmoid</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</span><br><span class="line"></span><br><span class="line"><span class="comment"># derivative of sigmoid</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid_grad</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> (<span class="number">1.0</span> - sigmoid(x)) * sigmoid(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># softmax</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">if</span> x.ndim == <span class="number">2</span>:</span><br><span class="line">        x = x.T</span><br><span class="line">        x = x - np.<span class="built_in">max</span>(x, axis = <span class="number">0</span>)</span><br><span class="line">        y = np.exp(x) / np.<span class="built_in">sum</span>(np.exp(x), axis = <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> y.T</span><br><span class="line">    x = x - np.<span class="built_in">max</span>(x) <span class="comment"># 1-dim case</span></span><br><span class="line">    <span class="keyword">return</span> np.exp(x) / np.<span class="built_in">sum</span>(np.exp(x))</span><br><span class="line"></span><br><span class="line"><span class="comment"># mean_squared_error</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mean_squared_error</span>(<span class="params">y, t</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0.5</span> * np.<span class="built_in">sum</span>((y-t)**<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># cross_entropy_error</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cross_entropy_error</span>(<span class="params">y, t</span>):</span></span><br><span class="line">    <span class="keyword">if</span> y.ndim == <span class="number">1</span>:</span><br><span class="line">        t = t.reshape(<span class="number">1</span>, t.size)</span><br><span class="line">        y = y.reshape(<span class="number">1</span>, y.size)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># one-hot-label case</span></span><br><span class="line">    <span class="keyword">if</span> t.size == y.size:</span><br><span class="line">        t = t.argmax(axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    batch_size = y.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> -np.<span class="built_in">sum</span>(np.log(y[np.arange(batch_size), t] + <span class="number">1e-7</span>)) / batch_size</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h4 id="TwoLayerNet">TwoLayerNet</h4>
<blockquote>
<p>The Notation Convention: row represents the input, column represents the output.</p>
</blockquote>
<img src="https://s2.loli.net/2022/01/16/VJad6KqtX7wxsu8.png" style="zoom:67%;">
<img src="https://s2.loli.net/2022/01/16/EPDxcaywLG2gRrB.png" style="zoom:80%;">
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> functions <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> gradient <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TwoLayerNet</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, input_size, hidden_size, output_size, weight_init_std = <span class="number">0.01</span></span>):</span></span><br><span class="line">        self.params = {}</span><br><span class="line">        <span class="comment"># initialize</span></span><br><span class="line">        self.params[<span class="string">'w1'</span>] = np.random.randn(input_size, hidden_size) * weight_init_std</span><br><span class="line">        self.params[<span class="string">'b1'</span>] = np.zeros(hidden_size)</span><br><span class="line">        self.params[<span class="string">'w2'</span>] = np.random.randn(hidden_size, output_size) * weight_init_std</span><br><span class="line">        self.params[<span class="string">'b2'</span>] = np.zeros(output_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        w1, w2 = self.params[<span class="string">'w1'</span>], self.params[<span class="string">'w2'</span>]</span><br><span class="line">        b1, b2 = self.params[<span class="string">'b1'</span>], self.params[<span class="string">'b2'</span>]</span><br><span class="line"></span><br><span class="line">        y1 = np.dot(x, w1) + b1</span><br><span class="line">        z1 = sigmoid(y1)</span><br><span class="line">        y2 = np.dot(z1, w2) + b2</span><br><span class="line">        z2 = softmax(y2)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> z2</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">loss</span>(<span class="params">self, x, t</span>):</span></span><br><span class="line">        z = self.predict(x)</span><br><span class="line">        <span class="keyword">return</span> cross_entropy_error(z, t)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gradient_without_back_propagation</span>(<span class="params">self, x, t</span>):</span></span><br><span class="line">        loss_W = <span class="keyword">lambda</span> W: self.loss(x, t)</span><br><span class="line"></span><br><span class="line">        grads = {}</span><br><span class="line">        grads[<span class="string">'w1'</span>] = numerical_gradient(loss_W, self.params[<span class="string">'w1'</span>])</span><br><span class="line">        grads[<span class="string">'b1'</span>] = numerical_gradient(loss_W, self.params[<span class="string">'b1'</span>])</span><br><span class="line">        grads[<span class="string">'w2'</span>] = numerical_gradient(loss_W, self.params[<span class="string">'w2'</span>])</span><br><span class="line">        grads[<span class="string">'b2'</span>] = numerical_gradient(loss_W, self.params[<span class="string">'b2'</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> grads</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># pseudo back propagation</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gradient</span>(<span class="params">self, x, t</span>):</span></span><br><span class="line">        <span class="comment"># forward</span></span><br><span class="line">        w1, w2 = self.params[<span class="string">'w1'</span>], self.params[<span class="string">'w2'</span>]</span><br><span class="line">        b1, b2 = self.params[<span class="string">'b1'</span>], self.params[<span class="string">'b2'</span>]</span><br><span class="line">        grads = {}</span><br><span class="line"></span><br><span class="line">        batch_num = x.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># forward</span></span><br><span class="line"></span><br><span class="line">        y1 = np.dot(x, w1) + b1</span><br><span class="line">        z1 = sigmoid(y1)</span><br><span class="line">        y2 = np.dot(z1, w2) + b2</span><br><span class="line">        z2 = softmax(y2)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># backward</span></span><br><span class="line">        dz = (z2 - t) / batch_num <span class="comment"># derivative of the mean squired loss function</span></span><br><span class="line">        grads[<span class="string">'b2'</span>] = np.<span class="built_in">sum</span>(dz, axis = <span class="number">0</span>)</span><br><span class="line">        grads[<span class="string">'w2'</span>] = np.dot(z1.T, dz)</span><br><span class="line"></span><br><span class="line">        dy1 = np.dot(dz, w2.T)</span><br><span class="line">        dz1 = sigmoid_grad(y1) * dy1</span><br><span class="line">        grads[<span class="string">'w1'</span>] = np.dot(x.T, dz1)</span><br><span class="line">        grads[<span class="string">'b1'</span>] = np.<span class="built_in">sum</span>(dz1, axis = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> grads</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">accuracy</span>(<span class="params">self, x, t</span>):</span></span><br><span class="line">        y = self.predict(x)</span><br><span class="line">        y = np.argmax(y, axis = <span class="number">1</span>)</span><br><span class="line">        t = np.argmax(t, axis = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        accuracy = np.<span class="built_in">sum</span>(y==t) / <span class="built_in">float</span>(y.shape[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> accuracy</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h4 id="Mini-batch-training-without-backward-propagation">Mini-batch training without backward propagation</h4>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> dataset.mnist <span class="keyword">import</span> load_mnist</span><br><span class="line"><span class="keyword">from</span> TwoLayerNet <span class="keyword">import</span> TwoLayerNet</span><br><span class="line"><span class="keyword">from</span> functions <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">(x_train, t_train), (x_test, t_test) = load_mnist(normalize=<span class="literal">True</span>, one_hot_label = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># parameters</span></span><br><span class="line">iters_num = <span class="number">10000</span></span><br><span class="line">train_size = x_train.shape[<span class="number">0</span>]</span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">learning_rate = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># recode the train loss</span></span><br><span class="line">train_loss_list = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># record the accuracy</span></span><br><span class="line">train_acc_list = []</span><br><span class="line">test_acc_list = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># the average iters per epoch</span></span><br><span class="line">iter_per_epoch = <span class="built_in">max</span>(train_size / batch_size, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># training</span></span><br><span class="line">network = TwoLayerNet(input_size = <span class="number">784</span>, hidden_size = <span class="number">50</span>, output_size = <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iters_num):</span><br><span class="line">    <span class="comment"># get mini-batch</span></span><br><span class="line">    batch_mask = np.random.choice(train_size, batch_size)</span><br><span class="line">    x_batch = x_train[batch_mask]</span><br><span class="line">    t_batch = t_train[batch_mask]</span><br><span class="line"></span><br><span class="line">    grad = network.gradient(x_batch, t_batch)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># update the parameters</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> (<span class="string">'w1'</span>, <span class="string">'b1'</span>, <span class="string">'w2'</span>,<span class="string">'b2'</span>):</span><br><span class="line">        network.params[key] -= learning_rate * grad[key]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># record the loss and training process</span></span><br><span class="line">    loss = network.loss(x_batch, t_batch)</span><br><span class="line">    train_loss_list.append(loss)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># echo design</span></span><br><span class="line">    <span class="keyword">if</span> i % iter_per_epoch == <span class="number">0</span>:</span><br><span class="line">        train_acc = network.accuracy(x_train, t_train)</span><br><span class="line">        test_acc = network.accuracy(x_test, t_test)</span><br><span class="line">        train_acc_list.append(train_acc)</span><br><span class="line">        test_acc_list.append(test_acc)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"train_acc, test_acc |"</span> + <span class="built_in">str</span>(train_acc) + <span class="string">', '</span> + <span class="built_in">str</span>(test_acc))</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h3 id="Back-Propagation">Back Propagation</h3>
<h4 id="Math">Math</h4>
<p style=""><img src="https://math.now.sh?from=z%20%3D%20f%20%28Y%29%2C%20%5C%20Y%20%3D%20XW%20%2B%20B%20%5Cto%20%7B%5Cpartial%20z%20%5Cover%20%5Cpartial%20W%7D%20%3D%20X%5ET%7B%5Cpartial%20z%20%5Cover%20%5Cpartial%20Y%7D%20%5C%5C%0Az%20%3D%20f%20(Y)%2C%20%5C%20Y%20%3D%20XW%20%2B%20B%20%5Cto%20%7B%5Cpartial%20z%20%5Cover%20%5Cpartial%20X%7D%20%3D%20%7B%5Cpartial%20z%20%5Cover%20%5Cpartial%20Y%7D%20W%5ET%0A"></p><p>For the proof of this formula, you can just take 1-dimension case for example,  and increase the dimension, then smoothly generalizing to the matrix form.</p>
<p>That is, to get an intuition understanding, look the following, and draw the neural connection picture to gain a feeling over the formula.</p>
<p style=""><img src="https://math.now.sh?from=X%20%3D%20%5Bx_1%2C%20x_2%2C%20x_3%5D%2C%20%5C%20%20%5C%20W%3D%0A%5Cbegin%7Bbmatrix%7D%0Aw_%7B1%7D%20%5C%5C%0Aw_%7B2%7D%5C%5C%0Aw_%7B3%7D%0A%5Cend%7Bbmatrix%7D%0A%2C%20%5C%20%5C%20%20Y%3Dy%0A"></p><p>And now, just add one more dimension to see the process again:</p>
<p style=""><img src="https://math.now.sh?from=X%20%3D%20%5Bx_1%2C%20x_2%2C%20x_3%5D%2C%20%5C%20%20%5C%20W%3D%0A%5Cbegin%7Bbmatrix%7D%0Aw_%7B11%7D%26%20w_%7B12%7D%20%5C%5C%0Aw_%7B21%7D%26%20w_%7B22%7D%5C%5C%0Aw_%7B31%7D%26%20w_%7B32%7D%20%0A%5Cend%7Bbmatrix%7D%0A%2C%20%5C%20%5C%20%20Y%3D%5By_1%2C%20y_2%5D%0A"></p><h4 id="The-representation-of-layers-in-the-back-propagation-algorithm">The representation of layers in the back propagation algorithm</h4>
<p><img src="https://math.now.sh?inline=x" style="display:inline-block;margin: 0;">, <img src="https://math.now.sh?inline=a" style="display:inline-block;margin: 0;"> are the nodes in the previous representation, but now we are gonna to talk about the forward propagation and back propagation, so we need to express the transformations in each layers explicitly.</p>
<img src="https://s2.loli.net/2022/01/18/P7McH53ZVQK9iyd.png" style="zoom:80%;">
<h4 id="BP-design">BP design</h4>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> functions <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Relu</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.mask = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        self.mask = (x &lt;= <span class="number">0</span>)</span><br><span class="line">        out = x.copy</span><br><span class="line">        out[self.mask] = <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">self, dout</span>):</span></span><br><span class="line">        dout[self.mask] = <span class="number">0</span></span><br><span class="line">        dx = dout</span><br><span class="line">        <span class="keyword">return</span> dx</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Sigmoid</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.out =  <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        out = sigmoid(x)</span><br><span class="line">        self.out = out</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">self, dout</span>):</span></span><br><span class="line">        dx = sigmoid_grad(self.out) * dout</span><br><span class="line">        <span class="keyword">return</span> dx</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Affine</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, w, b</span>):</span></span><br><span class="line">        self.w = w</span><br><span class="line">        self.b = b</span><br><span class="line">        self.x = <span class="literal">None</span></span><br><span class="line">        self.dw = <span class="literal">None</span></span><br><span class="line">        self.db = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        self.x = x</span><br><span class="line">        out = np.dot(x, self.w) + self.b</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">self, dout</span>):</span></span><br><span class="line">        dx = np.dot(dout, self.w.T)</span><br><span class="line">        self.dw = np.dot(self.x.T, dout)</span><br><span class="line">        self.db = np.<span class="built_in">sum</span>(dout, axis = <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> dx</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SoftmaxWithLoss</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.loss = <span class="literal">None</span></span><br><span class="line">        self.y = <span class="literal">None</span></span><br><span class="line">        self.t = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, t</span>):</span></span><br><span class="line">        self.t = t</span><br><span class="line">        self.y = softmax(x)</span><br><span class="line">        self.loss = cross_entropy_error(self.y, t)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">self, dout = <span class="number">1</span></span>):</span></span><br><span class="line">        batch_size = self.t.shape[<span class="number">0</span>]</span><br><span class="line">        dx = (self.y - self.t) / batch_size</span><br><span class="line">        <span class="keyword">return</span> dx</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h4 id="Mini-batch-training-with-backward-propagation">Mini-batch training with backward propagation</h4>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># the training part are the same</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> functions <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> gradient <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> BP_design <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TwoLayerNet</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, input_size, hidden_size, output_size, weight_init_std = <span class="number">0.01</span></span>):</span></span><br><span class="line">        self.params = {}</span><br><span class="line">        <span class="comment"># initialize</span></span><br><span class="line">        <span class="comment"># weight_init_std is the initial standard variance of weight</span></span><br><span class="line">        self.params[<span class="string">'w1'</span>] = np.random.randn(input_size, hidden_size) * weight_init_std</span><br><span class="line">        self.params[<span class="string">'b1'</span>] = np.zeros(hidden_size)</span><br><span class="line">        self.params[<span class="string">'w2'</span>] = np.random.randn(hidden_size, output_size) * weight_init_std</span><br><span class="line">        self.params[<span class="string">'b2'</span>] = np.zeros(output_size)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ordered dictionary</span></span><br><span class="line">        self.layers = OrderedDict()</span><br><span class="line">        self.layers[<span class="string">'Affine1'</span>] = Affine(self.params[<span class="string">'w1'</span>], self.params[<span class="string">'b1'</span>])</span><br><span class="line">        self.layers[<span class="string">'Relu'</span>] = Relu()</span><br><span class="line">        self.layers[<span class="string">'Affine2'</span>] = Affine(self.params[<span class="string">'w2'</span>], self.params[<span class="string">'b2'</span>])</span><br><span class="line"></span><br><span class="line">        self.lastLayer = SoftmaxWithLoss()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers.values():</span><br><span class="line">            x = layer.forward(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">loss</span>(<span class="params">self, x, t</span>):</span></span><br><span class="line">        z = self.predict(x)</span><br><span class="line">        <span class="keyword">return</span> self.lastLayer.forward(z, t)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gradient</span>(<span class="params">self, x, t</span>):</span></span><br><span class="line">        <span class="comment"># forward</span></span><br><span class="line">        self.loss(x, t) <span class="comment"># loss function will call the predict function</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># backward</span></span><br><span class="line">        dout = <span class="number">1</span></span><br><span class="line">        dout = self.lastLayer.backward(dout)</span><br><span class="line"></span><br><span class="line">        layers = <span class="built_in">list</span>(self.layers.values())</span><br><span class="line">        layers.reverse()</span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> layers:</span><br><span class="line">            dout = layer.backward(dout)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        grads = {}</span><br><span class="line">        grads[<span class="string">'w1'</span>] = self.layers[<span class="string">'Affine1'</span>].dw</span><br><span class="line">        grads[<span class="string">'b1'</span>] = self.layers[<span class="string">'Affine1'</span>].db</span><br><span class="line">        grads[<span class="string">'w2'</span>] = self.layers[<span class="string">'Affine2'</span>].dw</span><br><span class="line">        grads[<span class="string">'b2'</span>] = self.layers[<span class="string">'Affine2'</span>].db</span><br><span class="line">        <span class="keyword">return</span> grads</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">accuracy</span>(<span class="params">self, x, t</span>):</span></span><br><span class="line">        y = self.predict(x)</span><br><span class="line">        y = np.argmax(y, axis = <span class="number">1</span>)</span><br><span class="line">        t = np.argmax(t, axis = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        accuracy = np.<span class="built_in">sum</span>(y==t) / <span class="built_in">float</span>(y.shape[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> accuracy</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h3 id="CNN">CNN</h3>
<h4 id="Introduction">Introduction</h4>
<p>Why CNN?</p>
<p>In the previous neural network, we just use the fully connected layer. However, many important spatial information are lost in the fully connected layer,  such as one pixel is closer to its neighboring pixel. And also, the fully connected layer just has too many parameters, so complex.</p>
<p><a target="_blank" rel="noopener" href="https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215">https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215</a></p>
<h4 id="Convolution">Convolution</h4>
<p>ÂØπÂç∑ÁßØÁöÑ‰∏Ä‰∫õÁúãÊ≥ïÔºå</p>
<p>Âú®Ê∑±Â∫¶Â≠¶‰π†‰∏≠ÔºåÂç∑ÁßØ‰∏≠ÁöÑËøáÊª§Âô®‰∏çÁªèËøáÂèçËΩ¨„ÄÇ‰∏•Ê†ºÊù•ËØ¥ÔºåËøôÊòØ‰∫íÁõ∏ÂÖ≥„ÄÇÊàë‰ª¨Êú¨Ë¥®‰∏äÊòØÊâßË°åÈÄêÂÖÉÁ¥†‰πòÊ≥ïÂíåÂä†Ê≥ï„ÄÇ‰ΩÜÂú®Ê∑±Â∫¶Â≠¶‰π†‰∏≠ÔºåÁõ¥Êé•Â∞ÜÂÖ∂Áß∞‰πã‰∏∫Âç∑ÁßØÊõ¥Âä†Êñπ‰æø„ÄÇËøôÊ≤°‰ªÄ‰πàÈóÆÈ¢òÔºåÂõ†‰∏∫ËøáÊª§Âô®ÁöÑÊùÉÈáçÊòØÂú®ËÆ≠ÁªÉÈò∂ÊÆµÂ≠¶‰π†Âà∞ÁöÑ„ÄÇÂ¶ÇÊûú‰∏äÈù¢‰æãÂ≠ê‰∏≠ÁöÑÂèçËΩ¨ÂáΩÊï∞ g ÊòØÊ≠£Á°ÆÁöÑÂáΩÊï∞ÔºåÈÇ£‰πàÁªèËøáËÆ≠ÁªÉÂêéÔºåÂ≠¶‰π†ÂæóÂà∞ÁöÑËøáÊª§Âô®ÁúãËµ∑Êù•Â∞±‰ºöÂÉèÊòØÂèçËΩ¨ÂêéÁöÑÂáΩÊï∞ g„ÄÇÂõ†Ê≠§ÔºåÂú®ËÆ≠ÁªÉ‰πãÂâçÔºåÊ≤°ÂøÖË¶ÅÂÉèÂú®ÁúüÊ≠£ÁöÑÂç∑ÁßØ‰∏≠ÈÇ£Ê†∑È¶ñÂÖàÂèçËΩ¨ËøáÊª§Âô®„ÄÇ</p>
<p>Âç∑ÁßØÂÖ∂ÂÆûË¶ÅÊääÊ†∏ÁøªËΩ¨‰∏Ä‰∏ãÁöÑÔºå‰ΩÜÂú®ÂõæÂÉè‰∏≠Â§ßÈÉ®ÂàÜÊ†∏ÈÉΩÊòØÂØπÁß∞ÁöÑÔºåÊâÄ‰ª•‰∏§ËÄÖÂ∞±‰∏ÄÊ†∑‰∫Ü„ÄÇ</p>
<img src="https://s2.loli.net/2022/01/21/GHfwx1Z4vznmO2j.jpg" style="zoom:80%;">
<p>ÂØπ‰∫éÂõæÂÉèËÄåË®ÄÔºåÁ¶ªÊï£Âç∑ÁßØÁöÑËÆ°ÁÆóËøáÁ®ãÊòØÊ®°ÊùøÁøªËΩ¨ÔºåÁÑ∂ÂêéÂú®ÂéüÂõæÂÉè‰∏äÊªëÂä®Ê®°ÊùøÔºåÊääÂØπÂ∫î‰ΩçÁΩÆ‰∏äÁöÑÂÖÉÁ¥†Áõ∏‰πòÂêéÂä†Ëµ∑Êù•ÔºåÂæóÂà∞ÊúÄÁªàÁöÑÁªìÊûú„ÄÇÂ¶ÇÊûú‰∏çËÄÉËôëÁøªËΩ¨ÔºåËøô‰∏™ÊªëÂä®-Áõ∏‰πò-Âè†Âä†ÁöÑËøáÁ®ãÂ∞±ÊòØÁõ∏ÂÖ≥Êìç‰Ωú„ÄÇ‰∫ãÂÆû‰∏äÊàë‰πü‰∏ÄÁõ¥Áî®Áõ∏ÂÖ≥Êù•ÁêÜËß£Âç∑ÁßØ„ÄÇÂú®Êó∂ÂüüÂÜÖÂèØ‰ª•‰ªé‰∏§‰∏™ËßíÂ∫¶Êù•ÁêÜËß£ËøôÊ†∑ÂÅöÁöÑÂê´‰πâ„ÄÇ</p>
<p>‰∏ÄÁßçÊòØÊª§Ê≥¢ÔºåÊØîÂ¶ÇÊúÄÁÆÄÂçïÁöÑÈ´òÊñØÊ®°ÊùøÔºåÂ∞±ÊòØÊääÊ®°ÊùøÂÜÖÂÉèÁ¥†‰πò‰ª•‰∏çÂêåÁöÑÊùÉÂÄºÁÑ∂ÂêéÂä†Ëµ∑Êù•‰Ωú‰∏∫Ê®°ÊùøÁöÑ‰∏≠ÂøÉÂÉèÁ¥†ÂÄºÔºåÂ¶ÇÊûúÊ®°ÊùøÂèñÂÄºÂÖ®‰∏∫1ÔºåÂ∞±ÊòØÊªëÂä®Âπ≥ÂùáÔºõÂ¶ÇÊûúÊ®°ÊùøÂèñÂÄº‰∏∫È´òÊñØÔºåÂ∞±ÊòØÂä†ÊùÉÊªëÂä®Âπ≥ÂùáÔºåÊùÉÈáçÊòØ‰∏≠Èó¥È´òÔºåÂõõÂë®‰ΩéÔºåÂú®È¢ëÁéá‰∏äÁêÜËß£Â∞±ÊòØ‰ΩéÈÄöÊª§Ê≥¢Âô®ÔºõÂ¶ÇÊûúÊ®°ÊùøÂèñÂÄº‰∏∫‰∏Ä‰∫õËæπÁºòÊ£ÄÊµãÁöÑÊ®°ÊùøÔºåÁªìÊûúÂ∞±ÊòØÊ®°ÊùøÂ∑¶ËæπÁöÑÂÉèÁ¥†ÂáèÂè≥ËæπÁöÑÂÉèÁ¥†ÔºåÊàñËÄÖÂè≥ËæπÁöÑÂáèÂ∑¶ËæπÁöÑÔºåÂæóÂà∞ÁöÑÂ∞±ÊòØÂõæÂÉèÊ¢ØÂ∫¶ÔºåÊñπÂêë‰∏çÂêå‰ª£Ë°®‰∏çÂêåÊñπÂêëÁöÑËæπÁºòÔºõ</p>
<p>Âè¶‰∏ÄÁßçÁêÜËß£ÊòØÊäïÂΩ±ÔºåÂõ†‰∏∫ÂΩìÂâçÊ®°ÊùøÂÜÖÈÉ®ÂõæÂÉèÂíåÊ®°ÊùøÁöÑÁõ∏‰πòÁ¥ØÂä†Êìç‰ΩúÂ∞±ÊòØÂõæÂÉèÂ±ÄÈÉ®patchÂíåÊ®°ÊùøÁöÑÂÜÖÁßØÊìç‰ΩúÔºåÂ¶ÇÊûúÊääpatchÂíåÊ®°ÊùøÊãâÁõ¥ÔºåÊãâÁõ¥ÁöÑÂêëÈáèÁúãÊàêÊòØÂêëÈáèÁ©∫Èó¥‰∏≠ÁöÑÂêëÈáèÔºåÈÇ£‰πàËøô‰∏™ËøáÁ®ãÂ∞±ÊòØpatchÂêëÊ®°ÊùøÊñπÂêë‰∏äÁöÑÊäïÂΩ±Ôºå‰∏ÄÂπÖÂõæÂÉèÂíå‰∏Ä‰∏™Ê®°ÊùøÂç∑ÁßØÔºåÂæóÂà∞ÁöÑÁªìÊûúÂ∞±ÊòØÂõæÂÉèÂêÑ‰∏™patchÂú®Ëøô‰∏™ÊñπÂêë‰∏äÁöÑresponse mapÊàñËÄÖfeature mapÔºõÂ¶ÇÊûúËøôÊ†∑ÁöÑÊ®°ÊùøÊúâ‰∏ÄÁªÑÔºåÊàë‰ª¨ÂèØ‰ª•ÊääËøô‰∏ÄÁªÑÁúãÊàê‰∏ÄÁªÑÂü∫ÔºåÂæóÂà∞ÁöÑ‰∏ÄÁªÑfeature mapÂ∞±ÊòØÂéüÂõæÂÉèÂú®ËøôÁªÑÂü∫‰∏äÁöÑÊäïÂΩ±„ÄÇÂ∏∏ËßÅÁöÑÂ¶ÇÁî®‰∏ÄÁªÑGarborÊª§Ê≥¢Âô®ÊèêÂèñÂõæÂÉèÁöÑÁâπÂæÅÔºå‰ª•ÂèäÂç∑ÁßØÁ•ûÁªèÁΩëÁªú‰∏≠ÁöÑÁ¨¨‰∏ÄÂ±ÇÔºåÂõæÂÉèÂú®ÂêÑ‰∏™Âç∑ÁßØÊ†∏‰∏äÁöÑÊäïÂΩ±„ÄÇ</p>
<p><strong>Original idea in probability and signal processing</strong></p>
<p>‰∏çÁ®≥ÂÆöËæìÂÖ•„ÄÅÁ®≥ÂÆöËæìÂá∫ÔºåÊ±ÇÁ≥ªÁªüÂ≠òÈáè„ÄÇ</p>
<p><strong>Convolution in CNN</strong></p>
<blockquote>
<p>Why filter is called filter?</p>
</blockquote>
<p>From the respect of Fourier Transform:</p>
<p><a target="_blank" rel="noopener" href="https://www.robots.ox.ac.uk/~az/lectures/ia/lect2.pdf">https://www.robots.ox.ac.uk/~az/lectures/ia/lect2.pdf</a></p>
<h4 id="The-whole-procedure">The whole procedure</h4>
<p><img src="https://s2.loli.net/2022/01/19/4iDgATEk71j3dLa.png" alt=""></p>
<p><img src="https://s2.loli.net/2022/01/19/UsAnwuXZqc34EQf.png" alt=""></p>
<blockquote>
<p>pseudo code</p>
</blockquote>
<p><img src="https://s2.loli.net/2022/01/19/tNvT9HEpzkBmefM.png" alt=""></p>
<h4 id=""></h4>
<h4 id="Data-representation"><strong>Data representation</strong></h4>
<p style=""><img src="https://math.now.sh?from=4%20Dimensions%20%5C%20%5C%20%5C%20%5C%20%5C%20%5C%20%28batch%5C_num%2Cchannel%2Cheight%2C%20width%29%0A"></p><p><strong>Channel</strong></p>
<img src="https://s2.loli.net/2022/01/20/fhebwyr7POj8Jpm.png" style="zoom:80%;">
<img src="https://s2.loli.net/2022/01/20/uIl1OxnXhyCPNQM.png" style="zoom:80%;">
<img src="https://s2.loli.net/2022/01/20/as9dL7CNURZA24w.png" style="zoom:80%;">
<img src="https://s2.loli.net/2022/01/20/vNPUkcdfjzWZhSg.png" style="zoom:80%;">
<p><strong>Batch_num</strong></p>
<img src="https://s2.loli.net/2022/01/20/bTLWOHYa6JKh9xm.png" style="zoom:80%;">
<h4 id="Convolution-layer">Convolution layer</h4>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/40951745">ÂèçÂêë‰º†Êí≠‰πãÂÖ≠ÔºöCNN Âç∑ÁßØÂ±ÇÂèçÂêë‰º†Êí≠ - Áü•‰πé (zhihu.com)</a></p>
<p><strong>im2col</strong></p>
<p>The normal convolution operation use many for loops, which behave really slowly with numpy. So, actually, we choose <strong>im2col</strong>, basically saying, it‚Äôs just reshape convolution into matrix multiplication.</p>
<p>In more detail,  the number of cols after the im2col transform is the <strong>number of kernel traverses</strong>, the rows are the filter‚Äôs size times #channel.</p>
<img src="https://s2.loli.net/2022/01/20/XZdEPa7IQOHclCG.png" style="zoom:80%;">
<img src="C:\Users\19772\Pictures\blogËß£ÈáäÂõæÁâá\20171105162824191" alt="img" style="zoom:80%;">
<img src="https://s2.loli.net/2022/01/20/UhOfc53aIetqjdR.jpg" style="zoom: 50%;">
<img src="https://s2.loli.net/2022/01/20/G1yqHIgJaYKxBpF.png" style="zoom:80%;">
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> common.util <span class="keyword">import</span> im2col</span><br><span class="line"><span class="keyword">from</span> common.util <span class="keyword">import</span> col2im</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Covolution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, w, b, stride = <span class="number">1</span>, pad = <span class="number">0</span> </span>):</span></span><br><span class="line">        self.w = w</span><br><span class="line">        self.b = b</span><br><span class="line">        self.stride = stride</span><br><span class="line">        self.pad = pad</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ‰∏≠Èó¥Êï∞ÊçÆÔºàbackwardÊó∂‰ΩøÁî®Ôºâ</span></span><br><span class="line">        self.x = <span class="literal">None</span></span><br><span class="line">        self.col = <span class="literal">None</span></span><br><span class="line">        self.col_W = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># ÊùÉÈáçÂíåÂÅèÁΩÆÂèÇÊï∞ÁöÑÊ¢ØÂ∫¶</span></span><br><span class="line">        self.dw = <span class="literal">None</span></span><br><span class="line">        self.db = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment"># w means filter</span></span><br><span class="line">        <span class="comment"># get the shape</span></span><br><span class="line">        FN, C, FH, FW = self.w.shape</span><br><span class="line">        N, C, H, W = x.shape</span><br><span class="line">        <span class="comment"># output height and width size</span></span><br><span class="line">        out_h = <span class="built_in">int</span>(<span class="number">1</span> + (H + <span class="number">2</span> * self.pad - FH) / self.stride)</span><br><span class="line">        out_w = <span class="built_in">int</span>(<span class="number">1</span> + (W + <span class="number">2</span> * self.pad - FW) / self.stride)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># transformation and convolution</span></span><br><span class="line">        col = im2col(x, FH, FW, self.stride, self.pad)</span><br><span class="line">        col_w = self.w.reshape(FN, -<span class="number">1</span>).T <span class="comment"># traverse for dot product</span></span><br><span class="line">        out = np.dot(col, col_w) + self.b</span><br><span class="line"></span><br><span class="line">        out = out.reshape(N, out_h, out_w, -<span class="number">1</span>).transpose(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">self, dout</span>):</span></span><br><span class="line">        FN, C, FH, FW = self.w.shape</span><br><span class="line">        dout = dout.transpose(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>).reshape(-<span class="number">1</span>, FN)</span><br><span class="line"></span><br><span class="line">        self.db = np.<span class="built_in">sum</span>(dout, axis=<span class="number">0</span>)</span><br><span class="line">        self.dW = np.dot(self.col.T, dout)</span><br><span class="line">        self.dW = self.dw.transpose(<span class="number">1</span>, <span class="number">0</span>).reshape(FN, C, FH, FW)</span><br><span class="line"></span><br><span class="line">        dcol = np.dot(dout, self.col_W.T)</span><br><span class="line">        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> dx</span><br></pre></td></tr></tbody></table></figure>
<p><strong>Difference between transpose and reshape</strong></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/72128096">ÁúüÊ≠£ÁêÜËß£ transpose Âíå reshape - Áü•‰πé (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_42820722/article/details/120483962">(42Êù°Ê∂àÊÅØ) Ê∑±Â∫¶Â≠¶‰π†ÂÖ•Èó®-Êüê‰∫õÁªÜËäÇÁöÑÁêÜËß£2Ôºàim2colÔºåtranspose‰∫§Êç¢Áª¥Â∫¶Ôºâ_Ë∂ÖÁ∫ßËèú-CSDNÂçöÂÆ¢</a></p>
<h4 id="Pooling-layer">Pooling layer</h4>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Pooling</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, pool_h, pool_w, stride = <span class="number">1</span>, pad = <span class="number">0</span></span>):</span></span><br><span class="line">        self.pool_h = pool_h</span><br><span class="line">        self.pool_w = pool_w</span><br><span class="line">        self.stride = stride</span><br><span class="line">        self.pad = pad</span><br><span class="line"></span><br><span class="line">        self.x = <span class="literal">None</span></span><br><span class="line">        self.arg_max = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        N, C, H, W = x.shape</span><br><span class="line">        out_h = <span class="built_in">int</span>(<span class="number">1</span> + (H - self.pool_h) / self.stride)</span><br><span class="line">        out_w = <span class="built_in">int</span>(<span class="number">1</span> + (W - self.pool_w) / self.stride)</span><br><span class="line"></span><br><span class="line">        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)</span><br><span class="line">        col = col.reshape(-<span class="number">1</span>, self.pool_h * self.pool_w)</span><br><span class="line">        <span class="comment"># reshape can be visualized as first make the matrix 1-d with order rows to rows</span></span><br><span class="line">        <span class="comment"># and then, reshape it from the order of width, height...</span></span><br><span class="line"></span><br><span class="line">        out = np.<span class="built_in">max</span>(col, axis = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        out = out.reshape(N, out_h, out_w, C).transpose(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">self, dout</span>):</span></span><br><span class="line">        dout = dout.transpose(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">        pool_size = self.pool_h * self.pool_w</span><br><span class="line">        dmax = np.zeros((dout.size, pool_size))</span><br><span class="line">        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()</span><br><span class="line">        dmax = dmax.reshape(dout.shape + (pool_size,))</span><br><span class="line">        dcol = dmax.reshape(dmax.shape[<span class="number">0</span>] * dmax.shape[<span class="number">1</span>] * dmax.shape[<span class="number">2</span>], -<span class="number">1</span>)</span><br><span class="line">        dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)</span><br><span class="line">        <span class="keyword">return</span> dx</span><br></pre></td></tr></tbody></table></figure>
<h4 id="Fully-connection-layer">Fully connection layer</h4>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">zxr</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://xurui314.github.io/2022/01/14/Machine-Learning-Coding/">https://xurui314.github.io/2022/01/14/Machine-Learning-Coding/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Python/">Python</a><a class="post-meta__tags" href="/tags/Machine-Learning/">Machine Learning</a></div><div class="post_share"><div class="social-share" data-image="https://s2.loli.net/2022/01/14/LaGcAPJX9QpgTBH.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer=""></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/02/09/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B/"><img class="prev-cover" src="https://s2.loli.net/2022/02/09/ithGk3OMsN8E1rT.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">Some talk about stochastic process</div></div></a></div><div class="next-post pull-right"><a href="/2022/01/12/Attack-on-Titan/"><img class="next-cover" src="https://s2.loli.net/2022/01/12/qWYLfoIhz4vakJU.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">zxrÈùíÊò•ÁöÑË°•ÂÆå---Attack on Titan</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2022/02/10/MIT-ML/" title="MIT ML"><img class="cover" src="https://s2.loli.net/2022/01/14/ftJD3kOcUnPHpzN.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-02-10</div><div class="title">MIT ML</div></div></a></div><div><a href="/2022/10/13/Tree-based-AI/" title="Tree based AI"><img class="cover" src="https://s2.loli.net/2022/10/13/Z8Llvman5s1iGXz.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-10-13</div><div class="title">Tree based AI</div></div></a></div><div><a href="/2022/06/16/nlp-learning-recording/" title="nlp learning recording"><img class="cover" src="https://images.unsplash.com/photo-1501555088652-021faa106b9b?ixlib=rb-1.2.1&amp;ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&amp;auto=format&amp;fit=crop&amp;w=873&amp;q=80" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-06-16</div><div class="title">nlp learning recording</div></div></a></div><div><a href="/2021/08/15/‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúËØÜÂà´ÊâãÂÜôÊï∞Â≠ó/" title="‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúËØÜÂà´ÊâãÂÜôÊï∞Â≠ó"><img class="cover" src="https://i.loli.net/2021/08/15/NYcSXrECnvzOiLP.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-08-15</div><div class="title">‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúËØÜÂà´ÊâãÂÜôÊï∞Â≠ó</div></div></a></div><div><a href="/2021/08/14/Á•ûÁªèÁΩëÁªúÊê≠Âª∫ÂáÜÂ§áÂÜÖÂÆπ/" title="Á•ûÁªèÁΩëÁªúÊê≠Âª∫ÂáÜÂ§áÂÜÖÂÆπ"><img class="cover" src="https://i.loli.net/2021/08/15/F8aP7R36IidpCt5.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-08-14</div><div class="title">Á•ûÁªèÁΩëÁªúÊê≠Âª∫ÂáÜÂ§áÂÜÖÂÆπ</div></div></a></div><div><a href="/2022/06/01/Multimodal-NER/" title="Multimodal NER"><img class="cover" src="https://s2.loli.net/2022/06/01/NGZoMHJQIyVS5Ab.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-06-01</div><div class="title">Multimodal NER</div></div></a></div></div></div><hr><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div><div id="comment-switch"><span class="first-comment">Valine</span><span class="switch-btn"></span><span class="second-comment">Disqus</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div><div><div id="disqus_thread"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://s2.loli.net/2021/12/08/yTYthVwXD4IPbJ9.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"></div><div class="author-info__name">zxr</div><div class="author-info__description">Think and Do like an MIT student</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">76</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">35</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">16</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/XuRui314"><i class="fab fa-github"></i><span>This is zxr!üöÄ</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/XuRui314" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://mail.qq.com/" target="_blank" title="Email-1977289398@qq.com"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">zxrÁöÑÁîüÊ¥ªÔºåmathÔºåÁºñÁ®ãËÆ∞ÂΩï,<div class="twopeople"><div class="container" style="height:200px;"><canvas class="illo" width="800" height="800" style="max-width: 200px; max-height: 200px; touch-action: none; width: 640px; height: 640px;"></canvas></div><script src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/js/twopeople1.js"></script><script src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/js/zdog.dist.js"></script><script id="rendered-js" src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/js/twopeople.js"></script><style>.twopeople{margin: 0;align-items: center;justify-content: center;text-align: center;}canvas{display: block;margin: 0 auto;cursor: move;}</style></div><div class="twopeople"></div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">Preparation Knowledge</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">Supervised Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#No-Model"><span class="toc-number">2.1.</span> <span class="toc-text">No Model</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#KNN"><span class="toc-number">2.1.1.</span> <span class="toc-text">KNN</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Linear-classification"><span class="toc-number">2.2.</span> <span class="toc-text">Linear classification</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Perceptron"><span class="toc-number">2.2.1.</span> <span class="toc-text">Perceptron</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SVM"><span class="toc-number">2.2.2.</span> <span class="toc-text">SVM</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#brute-force"><span class="toc-number">2.2.2.1.</span> <span class="toc-text">brute force</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Kernel-method"><span class="toc-number">2.2.2.2.</span> <span class="toc-text">Kernel method</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Network-classification"><span class="toc-number">2.3.</span> <span class="toc-text">Network classification</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#NN-neural-network"><span class="toc-number">2.3.1.</span> <span class="toc-text">NN(neural network)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Methods"><span class="toc-number">2.3.1.1.</span> <span class="toc-text">Methods</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Data-processing"><span class="toc-number">2.3.1.2.</span> <span class="toc-text">Data processing</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Functions"><span class="toc-number">2.3.1.3.</span> <span class="toc-text">Functions</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#TwoLayerNet"><span class="toc-number">2.3.1.4.</span> <span class="toc-text">TwoLayerNet</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Mini-batch-training-without-backward-propagation"><span class="toc-number">2.3.1.5.</span> <span class="toc-text">Mini-batch training without backward propagation</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Back-Propagation"><span class="toc-number">2.3.2.</span> <span class="toc-text">Back Propagation</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Math"><span class="toc-number">2.3.2.1.</span> <span class="toc-text">Math</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#The-representation-of-layers-in-the-back-propagation-algorithm"><span class="toc-number">2.3.2.2.</span> <span class="toc-text">The representation of layers in the back propagation algorithm</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#BP-design"><span class="toc-number">2.3.2.3.</span> <span class="toc-text">BP design</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Mini-batch-training-with-backward-propagation"><span class="toc-number">2.3.2.4.</span> <span class="toc-text">Mini-batch training with backward propagation</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CNN"><span class="toc-number">2.3.3.</span> <span class="toc-text">CNN</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Introduction"><span class="toc-number">2.3.3.1.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Convolution"><span class="toc-number">2.3.3.2.</span> <span class="toc-text">Convolution</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#The-whole-procedure"><span class="toc-number">2.3.3.3.</span> <span class="toc-text">The whole procedure</span></a></li><li class="toc-item toc-level-4"><a class="toc-link"><span class="toc-number">2.3.3.4.</span> <span class="toc-text"></span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Data-representation"><span class="toc-number">2.3.3.5.</span> <span class="toc-text">Data representation</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Convolution-layer"><span class="toc-number">2.3.3.6.</span> <span class="toc-text">Convolution layer</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Pooling-layer"><span class="toc-number">2.3.3.7.</span> <span class="toc-text">Pooling layer</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Fully-connection-layer"><span class="toc-number">2.3.3.8.</span> <span class="toc-text">Fully connection layer</span></a></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/05/13/Multimodel-Pretrained-Model/" title="Multimodel Pretrained Model"><img src="https://cdn.jsdelivr.net/gh/wdm1732418365/CDN/New%20folder/daydream%20(1).png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Multimodel Pretrained Model"></a><div class="content"><a class="title" href="/2023/05/13/Multimodel-Pretrained-Model/" title="Multimodel Pretrained Model">Multimodel Pretrained Model</a><time datetime="2023-05-13T14:39:00.000Z" title="Created 2023-05-13 22:39:00">2023-05-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/13/Contrastive-Learning-in-Multimodal/" title="Contrastive Learning in Multimodal"><img src="https://cdn.jsdelivr.net/gh/wdm1732418365/CDN/New%20folder/daydream%20(11).png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Contrastive Learning in Multimodal"></a><div class="content"><a class="title" href="/2023/05/13/Contrastive-Learning-in-Multimodal/" title="Contrastive Learning in Multimodal">Contrastive Learning in Multimodal</a><time datetime="2023-05-13T14:38:33.000Z" title="Created 2023-05-13 22:38:33">2023-05-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/04/21/11-777-Multimodal-Machine-Learning/" title="11-777 Multimodal Machine Learning"><img src="https://remakelearning.org/wp-content/uploads/2020/03/3X2-RML-Edits-2-1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="11-777 Multimodal Machine Learning"></a><div class="content"><a class="title" href="/2023/04/21/11-777-Multimodal-Machine-Learning/" title="11-777 Multimodal Machine Learning">11-777 Multimodal Machine Learning</a><time datetime="2023-04-21T14:28:23.000Z" title="Created 2023-04-21 22:28:23">2023-04-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/04/13/HW4P1/" title="HW4P1"><img src="https://pbs.twimg.com/media/FHtPhbzXMAcEyGE.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="HW4P1"></a><div class="content"><a class="title" href="/2023/04/13/HW4P1/" title="HW4P1">HW4P1</a><time datetime="2023-04-13T15:02:59.000Z" title="Created 2023-04-13 23:02:59">2023-04-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/17/%E9%A3%9E%E6%A1%A8%E5%AD%A6%E4%B9%A0%E8%B5%9B%EF%BC%9A%E4%BA%A7%E5%93%81%E8%AF%84%E8%AE%BA%E8%A7%82%E7%82%B9%E6%8F%90%E5%8F%96/" title="È£ûÊ°®Â≠¶‰π†ËµõÔºö‰∫ßÂìÅËØÑËÆ∫ËßÇÁÇπÊèêÂèñ"><img src="https://pic1.zhimg.com/v2-1583bb0421d71bf07ed0897f4186da82_xl.jpg?source=32738c0c" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="È£ûÊ°®Â≠¶‰π†ËµõÔºö‰∫ßÂìÅËØÑËÆ∫ËßÇÁÇπÊèêÂèñ"></a><div class="content"><a class="title" href="/2023/03/17/%E9%A3%9E%E6%A1%A8%E5%AD%A6%E4%B9%A0%E8%B5%9B%EF%BC%9A%E4%BA%A7%E5%93%81%E8%AF%84%E8%AE%BA%E8%A7%82%E7%82%B9%E6%8F%90%E5%8F%96/" title="È£ûÊ°®Â≠¶‰π†ËµõÔºö‰∫ßÂìÅËØÑËÆ∫ËßÇÁÇπÊèêÂèñ">È£ûÊ°®Â≠¶‰π†ËµõÔºö‰∫ßÂìÅËØÑËÆ∫ËßÇÁÇπÊèêÂèñ</a><time datetime="2023-03-17T14:48:51.000Z" title="Created 2023-03-17 22:48:51">2023-03-17</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">¬©2020 - 2023 By zxr</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="github-badge"><a style="color: #fff" rel="license" href="https://hexo.io/" target="_blank" title="Áî± Hexo Âº∫ÂäõÈ©±Âä®"><span class="badge-subject">Powered</span><span class="badge-value bg-blue">Hexo</span></a><a style="color: #fff" rel="license" href="https://gitee.com/" target="_blank" title="ÈùôÊÄÅÁΩëÈ°µÊâòÁÆ°‰∫é GitHub Pages Âíå Coding Pages Âíå Gitee Pages"><span class="badge-subject">Hosted</span><span class="badge-value bg-brightgreen">GitHub &amp; Coding &amp; Gitee</span></a><a style="color: #fff" rel="license" href="https://www.jsdelivr.com/" target="_blank" title="jsDelivr Êèê‰æõ CDN Âä†ÈÄüÊúçÂä°"><span class="badge-subject">CDN</span><span class="badge-value bg-orange">jsDelivr</span></a><a style="color: #fff" rel="license" href="https://jerryc.me" target="_blank" title="Á´ôÁÇπ‰ΩøÁî® Butterfly‰∏ªÈ¢ò"><span class="badge-subject">Theme</span><span class="badge-value bg-blue">Butterfly</span></a><a style="color: #fff" rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" title="Êú¨Á´ôÁÇπÈááÁî®Áü•ËØÜÂÖ±‰∫´ÁΩ≤Âêç-ÈùûÂïÜ‰∏öÊÄß‰ΩøÁî®-Áõ∏ÂêåÊñπÂºèÂÖ±‰∫´ 4.0 ÂõΩÈôÖËÆ∏ÂèØÂçèËÆÆËøõË°åËÆ∏ÂèØ"><span class="badge-subject"><i class="fa fa-copyright"></i></span><span class="badge-value bg-lightgrey">BY-NC-SA 4.0  </span></a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="Increase font size"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="Decrease font size"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = '[object Object]'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: '',
      appKey: '',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script>function loadDisqus () {
  var disqus_config = function () {
    this.page.url = 'https://xurui314.github.io/2022/01/14/Machine-Learning-Coding/'
    this.page.identifier = '2022/01/14/Machine-Learning-Coding/'
    this.page.title = 'Machine Learning Code'
  };

  window.disqusReset = () => {
    DISQUS.reset({
      reload: true,
      config: disqus_config
    })
  }

  if (window.DISQUS) disqusReset()
  else {
    (function() { 
      var d = document, s = d.createElement('script');
      s.src = 'https://.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  }
}

if ('Valine' === 'Disqus' || !false) {
  if (false) btf.loadComment(document.getElementById('disqus_thread'), loadDisqus)
  else loadDisqus()
} else {
  function loadOtherComment () {
    loadDisqus()
  }
}
</script></div><script src="https://cdn.jsdelivr.net/gh/XuRui314/live2d-widget@1.0.1/autoload.js"></script><script src="/js/title.js"></script><script src="/dist/nochocolate.js"></script><div id="aplayer"></div><script type="text/javascript" src="/dist/APlayer.min.js"></script><script type="text/javascript" src="/dist/music.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/gh/metowolf/MetingJS@1.2/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = [
  'title',
  '#config-diff',
  '#body-wrap',
  '#rightside-config-hide',
  '#rightside-config-show',
  '.js-pjax'
]

if (false) {
  pjaxSelectors.unshift('meta[property="og:image"]', 'meta[property="og:title"]', 'meta[property="og:url"]')
}

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.removeEventListener('scroll', window.tocScrollFn)
  window.removeEventListener('scroll', scrollCollect)

  typeof preloader === 'object' && preloader.initLoading()
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // Analytics
  if (false) {
    MtaH5.pgv()
  }

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async="" data-pjax="" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax="">if(document.getElementById('recent-posts') && (location.pathname ==='all'|| 'all' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/Math/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">üìö zxr„ÅÆÊï∞Â≠¶‰∏ñÁïå (12)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/ÁÆóÊ≥ïÂ≠¶‰π†/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">üéÆ zxr„ÅÆÁÆóÊ≥ïÂ≠¶‰π† (6)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/ÁîüÊ¥ªË∂£Èóª/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">üê±‚Äçüëì zxr„ÅÆÁîüÊ¥ªË∂£Èóª (4)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/ÁºñÁ®ãÂÆû‰æã/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">üë©‚Äçüíª zxr„ÅÆÁºñÁ®ãÂ≠¶‰π† (4)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/ÁîüÊ¥ªÊÑüÊÇü/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">üö¥‚Äç‚ôÇ zxr„ÅÆÁîüÊ¥ªÊÑüÊÇü (11)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/Hexo/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">üíå zxr„ÅÆBlogËÆ∞ÂΩï (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="https://XuRui314.github.io/categories" style="flex:1;text-align: center;margin-bottom: 10px;">Êü•ÁúãÊõ¥Â§ö...</a></div></div>';
    console.log('Â∑≤ÊåÇËΩΩmagnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style> <script data-pjax="">if(document.getElementById('recent-posts') && location.pathname =='/'){
    
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/09/17/9H5WSbTrVejOdkz.jpg" alt="https://i.loli.net/2021/09/17/9H5WSbTrVejOdkz.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-09-17</span><a class="blog-slider__title" href="2021/09/17/Ê¶ÇÁéáÂíåÊµãÂ∫¶/">Ê¶ÇÁéáÂíåÊµãÂ∫¶(ZJUÂ§ß‰Ω¨)</a><div class="blog-slider__text">Êù•ÁúãÁúãZJUËÆ°ÁßëÂ§ß‰Ω¨Ëß£ÈáäÊ¶ÇÁéáÂíåÊµãÂ∫¶ü•ô</div><a class="blog-slider__button" href="2021/09/17/Ê¶ÇÁéáÂíåÊµãÂ∫¶/">ËØ¶ÊÉÖ</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/25/bPy5m3j9QAilwr2.jpg" alt="https://i.loli.net/2021/08/25/bPy5m3j9QAilwr2.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-08-26</span><a class="blog-slider__title" href="2021/08/26/ÁÆóÊ≥ïÈ¢òÁõÆÁªÉ‰π†/">AcWing-Oj-Âà∑È¢òÂ≠¶‰π†ËÆ∞ÂΩï(Âü∫Á°ÄÁÆóÊ≥ï)</a><div class="blog-slider__text">Êù•ÁúãÁÆóÊ≥ïËíüËíªÁöÑ‰∏¢‰∫∫Êó•Â∏∏Âïäüë©‚Äçü¶Ω</div><a class="blog-slider__button" href="2021/08/26/ÁÆóÊ≥ïÈ¢òÁõÆÁªÉ‰π†/">ËØ¶ÊÉÖ</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/15/NYcSXrECnvzOiLP.jpg" alt="https://i.loli.net/2021/08/15/NYcSXrECnvzOiLP.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-08-15</span><a class="blog-slider__title" href="2021/08/15/‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúËØÜÂà´ÊâãÂÜôÊï∞Â≠ó/">‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúËØÜÂà´ÊâãÂÜôÊï∞Â≠ó</a><div class="blog-slider__text">ËØÜÂà´ÊâãÂÜôÊï∞Â≠óÊúÄÁÆÄÂçïÁöÑÂÆûÁé∞üß¶</div><a class="blog-slider__button" href="2021/08/15/‰∏§Â±ÇÁ•ûÁªèÁΩëÁªúËØÜÂà´ÊâãÂÜôÊï∞Â≠ó/">ËØ¶ÊÉÖ</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/15/F8aP7R36IidpCt5.jpg" alt="https://i.loli.net/2021/08/15/F8aP7R36IidpCt5.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-08-14</span><a class="blog-slider__title" href="2021/08/14/Á•ûÁªèÁΩëÁªúÊê≠Âª∫ÂáÜÂ§áÂÜÖÂÆπ/">Á•ûÁªèÁΩëÁªúÊê≠Âª∫ÂáÜÂ§áÂÜÖÂÆπ</a><div class="blog-slider__text">Â¶Ç‰ΩïËØÜÂà´ÊâãÂÜôüî¢ÔºåzxrÂ∏¶‰Ω†‰∏ÄÊ≠•‰∏ÄÊ≠•ÂÆûÁé∞üéº</div><a class="blog-slider__button" href="2021/08/14/Á•ûÁªèÁΩëÁªúÊê≠Âª∫ÂáÜÂ§áÂÜÖÂÆπ/">ËØ¶ÊÉÖ</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/12/SJs3MgYC7x8IU26.jpg" alt="https://i.loli.net/2021/08/12/SJs3MgYC7x8IU26.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-08-12</span><a class="blog-slider__title" href="2021/08/12/xuperchain-solidity/">xuperchain&solidity</a><div class="blog-slider__text">Âå∫ÂùóÈìæ‰∏çÊ≠¢ÊòØÊåñÂ∏ÅÔºåËøòÊúâvÁ•ûÂíåsolidityüéà</div><a class="blog-slider__button" href="2021/08/12/xuperchain-solidity/">ËØ¶ÊÉÖ</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/07/27/6fy8mTCbAOWPkrq.png" alt="https://i.loli.net/2021/07/27/6fy8mTCbAOWPkrq.png"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-07-26</span><a class="blog-slider__title" href="2021/07/26/FFT/">FFTÁöÑËØ¶Ëß£</a><div class="blog-slider__text">Ëøô‰πàÂ•ΩÁúãÁöÑFFTÔºå‰ø°Âè∑ÁãóÈÉΩÈ¶ãÂì≠‰∫Üüí¶</div><a class="blog-slider__button" href="2021/07/26/FFT/">ËØ¶ÊÉÖ</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/09/zdt4YKoehQvR96S.jpg" alt="https://i.loli.net/2021/08/09/zdt4YKoehQvR96S.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-08-09</span><a class="blog-slider__title" href="2021/08/09/ÁÇíÈ∏°Â•ΩÁêÜËß£ÁöÑÊµãÂ∫¶ËÆ∫/">ÁÇíÈ∏°Â•ΩÁêÜËß£ÁöÑÊµãÂ∫¶ËÆ∫</a><div class="blog-slider__text">‰∏âÊÆµÂ≠óÔºåËÆ©‰Ω†ËØªÊáÇÊµãÂ∫¶ËÆ∫</div><a class="blog-slider__button" href="2021/08/09/ÁÇíÈ∏°Â•ΩÁêÜËß£ÁöÑÊµãÂ∫¶ËÆ∫/">ËØ¶ÊÉÖ</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/12/wF7TJlqxOLEWGQk.png" alt="https://i.loli.net/2021/08/12/wF7TJlqxOLEWGQk.png"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-07-27</span><a class="blog-slider__title" href="2021/07/27/FT/">ÂÇÖÈáåÂè∂Â≠¶‰π†ËµÑÊñô</a><div class="blog-slider__text">ÁÆÄÂçïÂ•ΩÂ≠¶ÁöÑÂÇÖÈáåÂè∂Â≠¶‰π†ËµÑÊñô</div><a class="blog-slider__button" href="2021/07/27/FT/">ËØ¶ÊÉÖ</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/07/27/f7jO8hlNpzWVXSP.jpg" alt="https://i.loli.net/2021/07/27/f7jO8hlNpzWVXSP.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-07-26</span><a class="blog-slider__title" href="2021/07/26/hello-world/">Â§ßÈ∏üËΩ¨ËΩ¨ËΩ¨ÈÖíÂêßÂÜÖÈÉ®ÁªùÂØÜÊ°£Ê°à</a><div class="blog-slider__text">‰∏çË¶ÅÁÇπËøõÊù•QAQÔºÅ</div><a class="blog-slider__button" href="2021/07/26/hello-world/">ËØ¶ÊÉÖ</a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('Â∑≤ÊåÇËΩΩswiper')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script>
<script data-pjax="" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper/swiper/swiper.min.js"></script>
<script data-pjax="" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper@0.18/swiper/swiperindex.js"></script>
<style></style><script data-pjax="">function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('Â∑≤ÊåÇËΩΩelectric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // Êó†Êä•ÈîôÔºå‰ΩÜ‰∏çÂΩ±Âìç‰ΩøÁî®(ÊîØÊåÅpjaxË∑≥ËΩ¨)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // ÊúâÊä•ÈîôÔºå‰ΩÜ‰∏çÂΩ±Âìç‰ΩøÁî®(ÊîØÊåÅpjaxË∑≥ËΩ¨)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax="" src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script>
  <script data-pjax="" src="https://cdn.jsdelivr.net/gh/Zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script>
  <script data-pjax="">
        function GithubCalendarConfig(){
            var git_githubapiurl ="https://python-github-calendar-api.vercel.app/api?XuRui314";
            var git_color =['#ebedf0', '#fdcdec', '#fc9bd9', '#fa6ac5', '#f838b2', '#f5089f', '#c4067e', '#92055e', '#540336', '#48022f', '#30021f'];
            var git_user ="XuRui314";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="height:100%;display: flex;align-items: center;justify-content: center;"><svg style="height:50px" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>';
            if(parent_div_git && location.pathname =='/'){
                console.log('Â∑≤ÊåÇËΩΩgithub calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // Êó†Êä•ÈîôÔºå‰ΩÜ‰∏çÂΩ±Âìç‰ΩøÁî®(ÊîØÊåÅpjaxË∑≥ËΩ¨)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // ÊúâÊä•ÈîôÔºå‰ΩÜ‰∏çÂΩ±Âìç‰ΩøÁî®(ÊîØÊåÅpjaxË∑≥ËΩ¨)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:248px}@media screen and (max-width:650px) {#github_container{background-image:;min-height:0px}}</style>
    <style></style><script async="" src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"live2d-widget-model-wanko"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.7},"log":false});</script></body></html>