<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>HW1P1 | XuRui-Blog</title><meta name="keywords" content="Deep Learning"><meta name="author" content="zxr"><meta name="copyright" content="zxr"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="In this HW, iâ€™m gonna to complete the basic MLP (aka the simplest NN) by designing my own mytorch library which can be reused in the subsequent HW â€‚&nbsp;Here is the layout of this note (blog):  Brief In">
<meta property="og:type" content="article">
<meta property="og:title" content="HW1P1">
<meta property="og:url" content="https://xurui314.github.io/2022/12/15/HW1P1/index.html">
<meta property="og:site_name" content="XuRui-Blog">
<meta property="og:description" content="In this HW, iâ€™m gonna to complete the basic MLP (aka the simplest NN) by designing my own mytorch library which can be reused in the subsequent HW â€‚&nbsp;Here is the layout of this note (blog):  Brief In">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://s2.loli.net/2022/12/15/dGcSa6TvyYk5riO.jpg">
<meta property="article:published_time" content="2022-12-15T13:20:39.000Z">
<meta property="article:modified_time" content="2023-03-03T03:10:12.478Z">
<meta property="article:author" content="zxr">
<meta property="article:tag" content="Deep Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2022/12/15/dGcSa6TvyYk5riO.jpg"><link rel="shortcut icon" href="https://i.loli.net/2021/07/27/lSHRJbx7dYwTk8f.jpg"><link rel="canonical" href="https://xurui314.github.io/2022/12/15/HW1P1/"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'HW1P1',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-03-03 11:10:12'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    document.addEventListener('pjax:complete', detectApple)})(window)</script><link rel="stylesheet" href="/css/badge.css"><link rel="stylesheet" href="/css/modify.css"><link rel="stylesheet" href="/css/mouse.css"><link rel="stylesheet" href="/dist/APlayer.min.css"><link rel="stylesheet" href="/css/custom.css"><link rel="stylesheet" href="/css/bilibiliBanner.css" media="defer" onload="this.media='screen'"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper/swiper/swiper.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper/swiper/swiperstyle.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css">
<style>#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags:before {content:"\A";
  white-space: pre;}#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags > .article-meta__separator{display:none}</style>
<link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script async="" src="https://unpkg.zhimg.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://s2.loli.net/2021/12/08/yTYthVwXD4IPbJ9.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">70</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">33</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">16</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> ä¸»é¡µğŸ­</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> æ¡£æ¡ˆğŸŒŠ</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> æ ‡ç­¾ğŸ“‘</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> åˆ†ç±»ğŸŒˆ</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> å¥½åº·çš„âœ¨</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener" href="https://ocw.mit.edu/"><i class="fa-fw fas fa-link"></i><span> æ¥å­¦éº»å­¦</span></a></li><li><a class="site-page child" href="/bangumis/"><i class="fa-fw fas fa-video"></i><span> zxrã®è¿½ç•ªè®¡åˆ’</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=RyOyXsKuUgI"><i class="fa-fw fas fa-heart"></i><span> zxræœ€çˆ±æ»´upå˜‰å€©</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://oskarstalberg.com/game/planet/planet.html"><span> Planet</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> å‹é“¾ğŸ’•</span></a></div><div class="menus_item"><a class="site-page" href="https://xurui314.github.io/aboutme/"><span> AboutMeğŸ‚</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.foreverblog.cn/go.html"><span> è™«æ´</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://s2.loli.net/2022/12/15/dGcSa6TvyYk5riO.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">XuRui-Blog</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> ä¸»é¡µğŸ­</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> æ¡£æ¡ˆğŸŒŠ</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> æ ‡ç­¾ğŸ“‘</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> åˆ†ç±»ğŸŒˆ</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> å¥½åº·çš„âœ¨</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener" href="https://ocw.mit.edu/"><i class="fa-fw fas fa-link"></i><span> æ¥å­¦éº»å­¦</span></a></li><li><a class="site-page child" href="/bangumis/"><i class="fa-fw fas fa-video"></i><span> zxrã®è¿½ç•ªè®¡åˆ’</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=RyOyXsKuUgI"><i class="fa-fw fas fa-heart"></i><span> zxræœ€çˆ±æ»´upå˜‰å€©</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://oskarstalberg.com/game/planet/planet.html"><span> Planet</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> å‹é“¾ğŸ’•</span></a></div><div class="menus_item"><a class="site-page" href="https://xurui314.github.io/aboutme/"><span> AboutMeğŸ‚</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.foreverblog.cn/go.html"><span> è™«æ´</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">HW1P1</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2022-12-15T13:20:39.000Z" title="Created 2022-12-15 21:20:39">2022-12-15</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-03-03T03:10:12.478Z" title="Updated 2023-03-03 11:10:12">2023-03-03</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/cmu/">cmu</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">5.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>28min</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="HW1P1"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><div class="top-img" style="background-image: url('https://s2.loli.net/2022/12/15/dGcSa6TvyYk5riO.jpg');"></div><article class="post-content" id="article-container"><p>â€‚ In this HW, iâ€™m gonna to complete the basic MLP (aka the simplest NN) by designing my own <code>mytorch</code> library which can be reused in the subsequent HW</p>
<p>â€‚&nbsp;Here is the layout of this note (blog):</p>
<ol>
<li>Brief Introduction</li>
<li>Python Implementation</li>
<li>Torch Pipeline</li>
</ol>
<h2 id="Introduction">Introduction</h2>
<h3 id="Representation">Representation</h3>
<p>â€‚&nbsp;MLPs are universal function approximators , they can model any Boolean function, classification function, or regression. Now, I will explain this powerful representation ability in an intuitive way.</p>
<p>â€‚&nbsp;First, MLPs can be viewed as universal Boolean functions, because perceptrons can model<code>AND </code>, <code>OR</code>, <code>NOT</code> gate. Any truth table can be expressed in one-hidden-layer MLP, if we just get every item from the table and compose an expression, it costs <img src="https://math.now.sh?inline=2%5E%7BN-1%7D" style="display:inline-block;margin: 0;"> neurons.</p>
<p>â€‚&nbsp;But what if using more layers instead of just one-hidden-layer, by increasing the depth of the network, we are able to use less perceptrons, because it captures the relations between neurons.</p>
<p>â€‚&nbsp;The decision boundary captured by the boolean network can be any convex region, and can be composed together by adding one more layer to get a bigger maybe non-convex region. In this way, we can get any region we want in theory.</p>
<img src="\image\HW1P1_image1.png" alt="image-20221215153529805" style="zoom:80%;">
<p>â€‚But can one-hidden-layer MLP model all the decision boundary, in another word, is one-hidden-layer MLP a universal classifier?</p>
<p>â€‚&nbsp;The answer is YES, the intuition behind this is as follows. Consider now we want to model <img src="https://math.now.sh?inline=%5Csum_%7Bi%3D1%7D%5ENy_i%5Cgeq%20N" style="display:inline-block;margin: 0;">, when we push <img src="https://math.now.sh?inline=N" style="display:inline-block;margin: 0;"> to infinite, we will get a circle region in 2d, and a cylinder in 3d.</p>
<img src="\image\HW1P1_image2.png" alt="image-20221215153609086" style="zoom:80%;">
<p>â€‚ So in theory, we can achieve this:</p>
<img src="\image\HW1P1_image3.png" alt="image-20221215153753410" style="zoom:80%;">
<p>â€‚&nbsp;But this is true only when N is infinite, this actually wonâ€™t work in practice. However, deeper networks can require far fewer neuronsâ€“ 12 vs. ~infinite hidden neurons in this example. And in many cases, increase the depth can help a lot, a special case for this is the sum-product problem, also can be viewed as kind of DP idea.</p>
<p>â€‚&nbsp;How can MLP model any function? The intuition is as behind:</p>
<img src="\image\HW1P1_image4.png" alt="image-20221215154409190" style="zoom:80%;">
<img src="\image\HW1P1_image5.png" alt="image-20221215154523328" style="zoom:80%;">
<p>â€‚&nbsp;The network is actually a universal map from the entire domain of input values to the entire range of the output activation</p>
<p>â€‚&nbsp;Next i will cover the trade-off between width, depth and sufficiency of architecture. Not all architectures can represent any function. If your layers width is narrow, and without proper activation function, the network may be not sufficient to represent some functions. However, narrow layers can still pass information to subsequent layers if the activation function is sufficiently graded. But will require greater depth, to permit later layers to capture patterns.</p>
<p>â€‚ In a short summary, deeper MLPs can achieve the same precision with far fewer neurons, but must still have sufficient capacity:</p>
<ul>
<li>
<p>The activations must pass information through</p>
</li>
<li>
<p>Each layer must still be sufficiently wide to convey all relevant information to subsequent layers.</p>
</li>
</ul>
<p>â€‚ There are some supplement material analyzing the â€œcapacityâ€ of a network using VC dimension. I donâ€™t want to cover them all here. :)</p>
<p>â€‚ Then here let me introduce a variant network called RBF network. If you know Kernel SVM before, you must be familiar with the word RBF. So a RBF network is like this:</p>
<img src="\image\HW1P1_image6.png" alt="image-20221215183217223" style="zoom:80%;">
<p>â€‚ The difference between RBF network and BP network lies on the way they combine weights and inputs, see more here <a target="_blank" rel="noopener" href="https://stats.stackexchange.com/a/228596/363445">link</a>.</p>
<p>â€‚ RBF network is the best approximation to continuous funcitons:</p>
<img src="\image\HW1P1_image9.png" style="zoom:80%;">
<p>â€‚ See more material on <a target="_blank" rel="noopener" href="https://www.cnblogs.com/pinking/p/9349695.html">RBFNN and SVM</a>, <a target="_blank" rel="noopener" href="https://qr.ae/prpqSu">RBFNN and GMM</a></p>
<h3 id="Learning">Learning</h3>
<p>â€‚&nbsp;We know that MLP can be constructed to represent any function, but there is a huge gap between â€œcanâ€ and â€œhow toâ€. One naive approach is to handcraft a network to satisfy it, but only for the simplest case. More generally, given the function to model, we want to derive the parameters of the network to model it, through computation. We learn networks (The network must have sufficient capacity to model the function) by â€œfittingâ€ them to training instances drawn from a target function. Estimate parameters to minimize the error between the target function <img src="https://math.now.sh?inline=g%28X%29" style="display:inline-block;margin: 0;"> and the network function <img src="https://math.now.sh?inline=f%28X%2CW%29" style="display:inline-block;margin: 0;">.</p>
<img src="\image\HW1P1_image10.png" alt="image-20221217160346417" style="zoom:80%;">
<p>â€‚&nbsp;But <img src="https://math.now.sh?inline=g%28X%29" style="display:inline-block;margin: 0;"> is unknow, we only get the sampled input-output pairs for a number of samples of input <img src="https://math.now.sh?inline=X_i" style="display:inline-block;margin: 0;"> , <img src="https://math.now.sh?inline=%28X_i%2C%20d_i%29" style="display:inline-block;margin: 0;"> , where <img src="https://math.now.sh?inline=d_i%20%3D%20g%28X_i%29%20%2B%20noise" style="display:inline-block;margin: 0;">. We must learn the entire function from these few â€œtrainingâ€ samples.</p>
<img src="\image\HW1P1_image11.png" alt="image-20221217160601273" style="zoom:80%;">
<p>â€‚&nbsp;For classification problem, thereâ€™s an old method called perceptorn algorithm. So iâ€™ll only cover the main idea here, which is the update rule. Everytime we mis-classified a data point, we adjust our <img src="https://math.now.sh?inline=W" style="display:inline-block;margin: 0;"> vector to fit this point. The detailed proof can be found in mit 6.036.</p>
<img src="\image\HW1P1_image12.png" alt="image-20221217161120280" style="zoom:80%;">
<img src="\image\HW1P1_image13.png" alt="image-20221217161323356" style="zoom:80%;">
<img src="\image\HW1P1_image14.png" alt="image-20221217161338657" style="zoom:80%;">
<p>â€‚&nbsp;So can we apply the perceptron algorithm idea to the training process of MLP using the threshold function? The answer is NO. Even using the perfect architecture, it will still cost exponential time because we are using threshold function, so nobody tells us how far is it to the right answer, we have to try out every possible combinations.</p>
<p>â€‚&nbsp;Suppose we get every perceptron right except for the yellow cricle one, we need to train it to get the line as follows:</p>
<img src="\image\HW1P1_image15.png" alt="image-20221217163051488" style="zoom:80%;">
<p>â€‚ The individual classifier actually requires the kind of labelling shown below which is not given. So we need to try out every possible way of relabeling the blue dots such that we can learn a line that keeps all the red dots on one side</p>
<img src="\image\HW1P1_image16.png" alt="image-20221217164916738" style="zoom:80%;">
<img src="\image\HW1P1_image17.png" alt="image-20221217165158501" style="zoom:80%;">
<img src="\image\HW1P1_image18.png" alt="image-20221217165331580" style="zoom:80%;">
<p>â€‚&nbsp;So how to get rid of this limitation? In fact, it costs people more than a decade to give the solution XD. The problem is binary error metric is not useful, there is no indication of which direction to change the weights to reduce error, so we have to try out every possibility.</p>
<p>â€‚&nbsp;The solution is to change our way of computing the mismatch such that modifying the classifier slightly lets us know if we are going the right way or no.</p>
<ul>
<li>This requires changing both, our activation functions, and the manner in which we evaluate the mismatch between the classifier output and the target output</li>
<li>Our mismatch function will now not actually count errors, but a proxy for it</li>
</ul>
<p>â€‚&nbsp;So we need our mismatch function to be differentiable. Small changes in weight can result in non-negligible changes in output. This enables us to estimate the parameters using gradient descent techniques.</p>
<p>â€‚&nbsp;Come back to the problem of learning, we use divergence ( actually a Functional, take function as input, output a number ) to measure the mismatch, which is an abstract compared with the error defined before. Because when we are talking about â€œErrorâ€, this is often referred to the data-point-wise terminology, and we use â€œTotal Errorâ€ to measure the overall dismatch. But when we step into the probability distribution world, this is not sufficient enough, so we proposed the concept of divergence, just an abstract of the â€œErrorâ€ we talked before.</p>
<p>â€‚&nbsp;Divergence is a functional, because we want to measure the difference between functions given the input. We donâ€™t really care about the input <img src="https://math.now.sh?inline=X" style="display:inline-block;margin: 0;"> here, because we just use all the input values to calculate the divergence. We are more concerned about the relation between output of the divergence and the weights( which determines how our <img src="https://math.now.sh?inline=f" style="display:inline-block;margin: 0;"> changes).</p>
<img src="\image\HW1P1_image19.png" alt="image-20221217171018978" style="zoom:80%;">
<p>â€‚More generally, assuming <img src="https://math.now.sh?inline=X" style="display:inline-block;margin: 0;"> is a random variable, we donâ€™t need to consider the range we never cover, so we introduce the expectation to get the best <img src="https://math.now.sh?inline=W" style="display:inline-block;margin: 0;">:</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Cwidehat%7B%5Cboldsymbol%7BW%7D%7D%3D%20%26%20%5Cunderset%7BW%7D%7B%5Coperatorname%7Bargmin%7D%7D%20%5Cint_X%20%5Coperatorname%7Bdiv%7D%28f(X%20%3B%20W%29%2C%20g(X))%20P(X)%20d%20X%20%5C%5C%0A%26%20%3D%5Cunderset%7BW%7D%7B%5Coperatorname%7Bargmin%7D%7D%20E%5B%5Coperatorname%7Bdiv%7D(f(X%20%3B%20W)%2C%20g(X))%5D%0A%5Cend%7Baligned%7D%0A"></p><p>â€‚&nbsp;We used the concept â€œRiskâ€ associated with hypothesis <img src="https://math.now.sh?inline=h%28x%29" style="display:inline-block;margin: 0;">, which is defined as follows:</p>
<p style=""><img src="https://math.now.sh?from=R%28h%29%3D%7B%5Cmathbf%20%20%7BE%7D%7D%5BL(h(x)%2Cy)%5D%3D%5Cint%20L(h(x)%2Cy)%5C%2CdP(x%2Cy).%0A"></p><p>â€‚&nbsp;In practice, we can only get few sampled data, so we need to define â€œEmpirical riskâ€:</p>
<p style=""><img src="https://math.now.sh?from=%7B%5Cdisplaystyle%20%5C!R_%7B%5Ctext%7Bemp%7D%7D%28h%29%3D%7B%5Cfrac%20%7B1%7D%7Bn%7D%7D%5Csum%20_%7Bi%3D1%7D%5E%7Bn%7DL(h(x_%7Bi%7D)%2Cy_%7Bi%7D).%7D%0A"></p><img src="\image\HW1P1_image21.png" alt="image-20221217180102605" style="zoom:80%;">
<img src="\image\HW1P1_image20.png" alt="image-20221217194520685" style="zoom:80%;">
<p>â€‚Its really a measure of error, but using standard terminology, we will call it a â€œLossâ€ . The empirical risk is only an empirical approximation to the true risk which is our actual minimization objective. For a given training set the loss is only a function of W.</p>
<p>â€‚  Breif summary: We learn networks by â€œfittingâ€ them to training instances drawn from a target function. Learning networks of threshold-activation perceptrons requires solving a hard combinatorial-optimization problem.Because we cannot compute the influence of small changes to the parameters on the overall error. Instead we use continuous activation functions with non-zero derivatives to enables us to estimate network parameters. This makes the output of the network differentiable w.r.t every parameter in the networkâ€“ The logistic activation perceptron actually computes the a posteriori probability of the output given the input. We define differentiable divergence between the output of the network and the desired output for the training instances. And a total error, which is the average divergence over all training instances. We optimize network parameters to minimize this errorâ€“Empirical risk minimization. This is an instance of function minimization</p>
<h3 id="Backpropagation">Backpropagation</h3>
<p>â€‚ In the previous part, we have talked about Empirical risk minimization, which is a kind of function minimization. So itâ€™s natural to use gradient decent to optimize the objective function. The big picture of training a network(no loops, no residual connections) is described as the following.</p>
<img src="\image\HW1P1_image22.png" alt="image-20221224210413766" style="zoom:80%;">
<p>â€‚As you see,  the first step of gradient decent is to calculate the gradient of the loss value with respect to the parameters. In this section, I will introduce backpropagatoin, which is a really efficient way to calculate gradient on the network.</p>
<p>â€‚&nbsp;Our goal is to calculate <img src="https://math.now.sh?inline=%5Cfrac%7Bd%20%5Cboldsymbol%7BD%20i%20v%7D%28Y%2C%20%5Cboldsymbol%7Bd%7D%29%7D%7Bd%20w_%7Bi%2C%20j%7D%5E%7B(k)%7D%7D" style="display:inline-block;margin: 0;"> on the network, the naive approach is to just calculate one by one without using the properties of a network, which costs unacceptable computation. A more reasonable way is to take the idea of chain rule and dynamic programming into consideration, which is backpropagation.</p>
<p>â€‚Here are the <strong>assumptions</strong> (All of these conditions are frequently not applicable):</p>
<ol>
<li>The computation of the output of one neuron does not directly affect computation of other neurons in the same (or previous) layers</li>
<li>Inputs to neurons only combine through weighted addition</li>
<li>Activations are actually differentiable</li>
</ol>
<p>â€‚&nbsp;So now letâ€™s work on the math part. Actually, we just need to figure out one layerâ€™s  computation, since the other layersâ€™ calculations are actually similar.  I will choose to start from the end of the network.</p>
<img src="\image\HW1P1_image23.png" alt="image-20221224214406340" style="zoom:80%;">
<p>â€‚&nbsp;Start from the grey box (loss function calculation):</p>
<p style=""><img src="https://math.now.sh?from=%5Cfrac%7B%5Cpartial%20%5Coperatorname%7BDiv%7D%28Y%2C%20d%29%7D%7B%5Cpartial%20y_i%5E%7B(N)%7D%7D%3D%5Cfrac%7B%5Cpartial%20%5Coperatorname%7BDiv%7D(Y%2C%20d)%7D%7B%5Cpartial%20y_i%7D%0A"></p><p>â€‚Then we walk through the activation function:</p>
<p style=""><img src="https://math.now.sh?from=%5Cfrac%7B%5Cpartial%20D%20i%20v%7D%7B%5Cpartial%20z_1%5E%7B%28N%29%7D%7D%3D%5Cfrac%7B%5Cpartial%20y_1%5E%7B(N)%7D%7D%7B%5Cpartial%20z_1%5E%7B(N)%7D%7D%20%5Cfrac%7B%5Cpartial%20D%20i%20v%7D%7B%5Cpartial%20y_1%5E%7B(N)%7D%7D%3Df_N%5E%7B%5Cprime%7D%5Cleft(z_1%5E%7B(N)%7D%5Cright)%20%5Cfrac%7B%5Cpartial%20D%20i%20v%7D%7B%5Cpartial%20y_1%5E%7B(N)%7D%7D%0A"></p><img src="\image\HW1P1_image24.png" alt="image-20221224220206074" style="zoom:80%;">
<p>â€‚We get the desired gradient on layer N, Yeah~. But itâ€™s not the time for cheering up, we have to move forward because we just computed one layer gradients, the backpropagation is still continuing. So we also have to calculate the derivative with respect to <img src="https://math.now.sh?inline=y_i%5E%7BN-1%7D" style="display:inline-block;margin: 0;">.</p>
<img src="\image\HW1P1_image25.png" alt="image-20221224221058953" style="zoom:80%;">
<p>â€‚&nbsp;Afer iteratively calculating gradients like this till the last layer, backpropagation is finished. So let me take a brief summary bellow:</p>
<img src="\image\HW1P1_image26.png" alt="image-20221224221204602" style="zoom:80%;">
<img src="\image\HW1P1_image27.png" alt="image-20221224213345087" style="zoom:80%;">
<p>â€‚In our assumptions, the activation function is scale-wise and all the fucntions are differentiable, but we donâ€™t get the two conditions in many cases. So for vector activation function, we need to do one more summation, and instead of directly using the gradient, we can choose subgradients sometimes.</p>
<img src="\image\HW1P1_image28.png" alt="image-20221224230903495" style="zoom:80%;">
<p>â€‚&nbsp;The matrix form is as the following, and i think the only equation needed to be clarify is the term <img src="https://math.now.sh?inline=%5Cgrad_%7BW_N%7DDiv" style="display:inline-block;margin: 0;">, note that the dim of the derivative of a scaler with respect to a vector or matrix is the same as its transpose dim. And the dim of this expression looks resonable right? <img src="\image\HW1P1_image31.png" alt="image-20221225220955510" style="zoom:80%;"></p>
<p>â€‚Now iâ€™m gonna show you the math in detail. Our convention is to multiply gradient on the left, so to calculate the derivative  <img src="https://math.now.sh?inline=%5Cgrad_%7BW_N%7Dz_N" style="display:inline-block;margin: 0;">, we need to transpose the expression <img src="https://math.now.sh?inline=z_N%20%3D%20W_Ny_%7BN-1%7D%20%2B%20b_N" style="display:inline-block;margin: 0;"> to get <img src="https://math.now.sh?inline=z_N%5ET%20%3D%20y_%7BN-1%7D%5ETW_N%5ET%20%2B%20b_N%5ET" style="display:inline-block;margin: 0;">. By applying the chain rule, we can get:</p>
<p style=""><img src="https://math.now.sh?from=%5Cgrad_%7BW_N%5ET%7DDiv%20%3D%20%5Cgrad_%7Bz_N%5ET%7DDiv%5Cgrad_%7BW_N%5ET%7Dz_N%5ET%3D%5Cgrad_%7Bz_N%5ET%7DDiv%20%5C%20y_N%5ET%0A"></p><p>â€‚&nbsp;Adding transpose, we get:</p>
<p style=""><img src="https://math.now.sh?from=%5Cgrad_%7BW_N%5ET%7DDiv%20%3D%20y_%7BN-1%7D%5Cgrad_%7Bz_N%7DDiv%0A"></p><img src="\image\HW1P1_image30.png" alt="image-20221225214643166" style="zoom:80%;">
<img src="\image\HW1P1_image29.png" alt="image-20221225214508846" style="zoom:80%;">
<blockquote>
<p>åšäº†CMUçš„å®éªŒä»¥åå‘ç°æŒ‡å¯¼ä¹¦å†™çš„å’Œè¯¾å ‚ä¸Šè®²çš„ä¸ä¸€æ ·XDï¼Œè¯¾ä¸Šè®²çš„æ˜¯åˆ†å­å¸ƒå±€ï¼Œå®éªŒæ˜¯åˆ†æ¯å¸ƒå±€ï¼Œæ‰€ä»¥ä¸‹é¢ä¼šæŠŠçŸ©é˜µæ±‚å¯¼è®²çš„å…¨ä¸€ç‚¹ï¼Œäº‰å–åˆ‡å‰²è¿™ä¸€èŠ‚ã€‚</p>
</blockquote>
<p>å‘é‡ï¼ˆæˆ–è€…æ ‡é‡ï¼‰å¯¹å‘é‡çš„å¯¼æ•°å¾ˆç®€å•ï¼ŒJacobianå°±å¤Ÿäº†ï¼Œè¿™ä¸ªæˆ‘åœ¨HW0è®²çš„æ¯”è¾ƒç»†äº†ï¼Œä¸»è¦è¿˜æ˜¯è®¨è®ºä¸€ä¸‹çŸ©é˜µå¯¹çŸ©é˜µæ±‚å¯¼ã€‚æ¥ä¸‹æ¥æˆ‘è®²çš„å†…å®¹åªæ˜¯é’ˆå¯¹æ·±åº¦å­¦ä¹ é‡Œçš„çŸ©é˜µæ±‚å¯¼ï¼Œå› ä¸ºå¯èƒ½ä¸åŒé¢†åŸŸå¯¹è¿™å—å®šä¹‰ä¸ä¸€æ ·ï¼Œæˆ‘ä¹Ÿä¸å¤ªæ‡‚hhã€‚</p>
<p>å¼•ç”¨bä¹å¤§ä½¬çš„å›ç­”ï¼Œç®—æ˜¯å¯¹çŸ©é˜µæ±‚å¯¼åšäº†ä¸€ä¸ªå®šä¹‰ï¼š</p>
<p>æ¥ä¸¾ä¸ªæ —å­å§ï¼Œ<img src="https://math.now.sh?inline=A%20B%3DC" style="display:inline-block;margin: 0;">ï¼Œ<img src="https://math.now.sh?inline=%5Cleft%5B%5Cbegin%7Barray%7D%7Bll%7Da_1%20%26%20a_2%20%5C%5C%20a_3%20%26%20a_4%5Cend%7Barray%7D%5Cright%5D%5Cleft%5B%5Cbegin%7Barray%7D%7Bll%7Db_1%20%26%20b_2%20%5C%5C%20b_3%20%26%20b_4%5Cend%7Barray%7D%5Cright%5D%3D%5Cleft%5B%5Cbegin%7Barray%7D%7Bll%7Dc_1%20%26%20c_2%20%5C%5C%20c_3%20%26%20c_4%5Cend%7Barray%7D%5Cright%5D" style="display:inline-block;margin: 0;"><br>
å…¶ä¸­</p>
<p style=""><img src="https://math.now.sh?from=%5Cleft%5C%7B%5Cbegin%7Barray%7D%7Bl%7D%0Ac_1%3Da_1%20b_1%2Ba_2%20b_3%20%5C%5C%0Ac_2%3Da_1%20b_2%2Ba_2%20b_4%20%5C%5C%0Ac_3%3Da_3%20b_1%2Ba_4%20b_3%20%5C%5C%0Ac_4%3Da_3%20b_2%2Ba_4%20b_4%0A%5Cend%7Barray%7D%5Cright.%0A"></p><p>é‚£ä¹ˆ</p>
<p style=""><img src="https://math.now.sh?from=%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20A%7D%20%5CRightarrow%5Cleft%5C%7B%5Cbegin%7Barray%7D%7Bc%7D%0A%5Cpartial%20c_1%20%2F%20%5Cpartial%20a_1%3Db_1%20%5C%5C%0A%5Cpartial%20c_1%20%2F%20%5Cpartial%20a_2%3Db_3%20%5C%5C%0A%5Cpartial%20c_1%20%2F%20%5Cpartial%20a_3%3D0%20%5C%5C%0A%5Cpartial%20c_1%20%2F%20%5Cpartial%20a_4%3D0%20%5C%5C%0A%5Cpartial%20c_2%20%2F%20%5Cpartial%20a_1%3Db_2%20%5C%5C%0A%5Cvdots%20%5C%5C%0A%5Cpartial%20c_4%20%2F%20%5Cpartial%20a_4%3Db_4%0A%5Cend%7Barray%7D%5Cright.%0A"></p><p>å…¶å®ç›¸å½“äºæ‰©å±•äº†Jacobiançš„å®šä¹‰ï¼Œå³<img src="https://math.now.sh?inline=C" style="display:inline-block;margin: 0;">ä¸­æ¯ä¸€ä¸ªå…ƒç´ ï¼Œå¯¹äº<img src="https://math.now.sh?inline=A" style="display:inline-block;margin: 0;">ä¸­æ¯ä¸€ä¸ªå…ƒç´ è¿›è¡Œæ±‚å¯¼ã€‚è½¬åŒ–æˆæ ‡é‡çš„å½¢å¼å°±å¥½ç†è§£äº†å§~è‡³äºæŠŠä»¥ä¸Š16ä¸ªæ ‡é‡æ±‚å¯¼å†™æˆ<img src="https://math.now.sh?inline=4%20%5Ctimes%204" style="display:inline-block;margin: 0;">çš„çŸ©é˜µä¹Ÿå¥½è¿˜æ˜¯16ç»´çš„å‘é‡ä¹Ÿå¥½ï¼Œå¤§å¤šæ˜¯ä¸ºäº†å½¢å¼ï¼ˆç†è®ºï¼‰ä¸Šçš„ç¾è§‚ï¼Œæˆ–æ˜¯æ–¹ä¾¿å¯¹æ±‚å¯¼ç»“æœçš„åç»­ä½¿ç”¨ï¼Œäº¦æˆ–æ˜¯æ–¹ä¾¿ç¼–ç¨‹å®ç°ï¼Œ<strong>æŒ‰éœ€è‡ªå–</strong>ï¼Œå…¶æœ¬è´¨ä¸å˜ã€‚</p>
<p>åœ¨ç¥ç»ç½‘ç»œé‡Œï¼Œæ‰€è°“çš„çŸ©é˜µå½¢å¼éƒ½æ˜¯é€šè¿‡æ ‡é‡è¿›è¡Œå½¢å¼åŒ–åŒ…è£…çš„ï¼Œå®é™…ä¸Šçš„æ±‚å¯¼è§„åˆ™è¿˜æ˜¯è¦å’Œæ ‡é‡å¯¼æ•°è¿›è¡Œå¯¹åº”ï¼Œå› ä¸ºå‰å‘ä¼ æ’­ä¸­ä¸åŒæ ·æœ¬ä¹‹é—´æ˜¯äº’ä¸å½±å“çš„ï¼ˆæš‚æ—¶ä¸è€ƒè™‘batch normç­‰ï¼‰ï¼Œä¹Ÿå°±æ˜¯åªè€ƒè™‘affine functionå’Œelement-wiseçš„æ¿€æ´»å‡½æ•°çš„æƒ…å†µï¼ˆvectoræ¿€æ´»å‡½æ•°å°±å•ç‹¬ç®—ä¸€ä¸‹å°±è¡Œï¼‰ï¼Œæ‰€ä»¥å¯¹äºä¸Šé¢çš„ä¾‹å­ï¼Œæ•°å­¦ä¸Šçš„ç­”æ¡ˆåº”è¯¥æ˜¯<img src="https://math.now.sh?inline=B%5E%5Ctop%20%5Cotimes%20I" style="display:inline-block;margin: 0;">ï¼Œå…¶ä¸­ <img src="https://math.now.sh?inline=%5Cotimes" style="display:inline-block;margin: 0;"> æ˜¯kroneckerç§¯ï¼Œkronecker productçš„å®šä¹‰å¯ä»¥çœ‹è¿™é‡Œ <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/457055092">here</a> ï¼Œå…·ä½“ä¸ºå•¥æ˜¯è¿™ç»“æœå¯ä»¥çœ‹çŸ©é˜µæ±‚å¯¼æœ¯ã€‚ä½†æ˜¯åœ¨ç¥ç»ç½‘ç»œé‡Œï¼Œæˆ‘ä»¬çš„ç­”æ¡ˆåªæ˜¯<img src="https://math.now.sh?inline=B%5E%5Ctop" style="display:inline-block;margin: 0;">ï¼Œå› ä¸ºæœ¬è´¨ä¸Šæˆ‘ä»¬è¿˜æ˜¯åœ¨å¤„ç†ä¸€ä¸ªå¤šå…ƒå‡½æ•°çš„ä¼˜åŒ–ï¼ŒçŸ©é˜µçš„å½¢å¼åªæ˜¯ç»„ç»‡ç»“æœçš„ä¸€ç§æ–¹å¼ï¼Œæˆ‘ä»¬æŠŠå¤šä¸ªè®­ç»ƒæ ·æœ¬ç»„æˆä¸€æ‰¹å½¢æˆçŸ©é˜µï¼Œå®é™…ä¸Šå’Œå•ä¸ªæ ·æœ¬å‘é‡çš„å¤„ç†å·®åˆ«åªåœ¨äºéœ€è¦å¯¹ä¸åŒbatchæ ·æœ¬å¾—åˆ°çš„æ¢¯åº¦ç»“æœæ±‚å’Œï¼Œä¸‹é¢ä¸¾ä¸ªä¾‹å­ï¼ˆæ²¿ç”¨bä¹å¤§ä½¬çš„<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/37916911">ä¾‹å­</a>ï¼‰ï¼š</p>
<p>å‡è®¾batch sizeä¸º3ï¼Œå¯ä»¥å¾—åˆ°</p>
<p style=""><img src="https://math.now.sh?from=Y_%7B2%20%5Ctimes%203%7D%3DW_%7B2%20%5Ctimes%203%7D%20%5Ccdot%20X_%7B3%20%5Ctimes%203%7D%2BB_%7B2%20%5Ctimes%201%7D%0A"></p><p>å¯¹äºå…¶ä¸­çš„æŸä¸ªp sampleè€Œè¨€</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%26%20y_%7B1p%7D%3Dw_%7B11%7D%20x_%7B1p%7D%2Bw_%7B12%7D%20x_%7B2p%7D%2Bw_%7B13%7D%20x_%7B3p%7D%2Bb_1%20%5C%5C%0A%26%20y_%7B2p%7D%3Dw_%7B21%7D%20x_%7B1p%7D%2Bw_%7B22%7D%20x_%7B2p%7D%2Bw_%7B23%7D%20x_%7B3p%7D%2Bb_2%0A%5Cend%7Baligned%7D%0A"></p><p>ä»è€Œ</p>
<p style=""><img src="https://math.now.sh?from=%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20w_%7Bi%20j%7D%7D%3D%5Csum_%7Bp%7D%20%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20y_%7Bip%7D%7D%20%5Cfrac%7B%5Cpartial%20y_%7Bip%7D%7D%7B%5Cpartial%20w_%7Bi%20j%7D%7D%3D%5Csum_%7Bp%7D%20x_%7Bjp%7D%20%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20y_%7Bip%7D%7D%0A"></p><p>è¿™é‡Œçš„æ±‚å’Œå…¶å®å°±æ˜¯å…³é”®æ‰€åœ¨ï¼Œæˆ‘ä»¬æ˜¯åˆ©ç”¨batchè®¡ç®—å‡ºçš„æ¢¯åº¦è¿›è¡Œæ›´æ–°ï¼Œæ‰€ä»¥å¯ä»¥å¾—åˆ°</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20W%7D%20%26%20%3D%5Cleft%28%5Cbegin%7Barray%7D%7Blll%7D%0A%5Csum_p%20x_%7B1p%7D%20%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20y_%7B1p%7D%7D%20%26%20%5Csum_p%20x_%7B2p%7D%20%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20y_%7B1p%7D%7D%20%26%20%5Csum_p%20x_%7B3p%7D%20%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20y_%7B1p%7D%7D%20%5C%5C%0A%5Csum_p%20x_%7B1p%7D%20%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20y_%7B2p%7D%7D%20%26%20%5Csum_p%20x_%7B2p%7D%20%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20y_%7B2p%7D%7D%20%26%20%5Csum_p%20x_%7B3p%7D%20%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20y_%7B2p%7D%7D%0A%5Cend%7Barray%7D%5Cright%29%20%5C%5C%0A%26%20%3D%5Cleft(%5Cbegin%7Barray%7D%7Bc%7D%0A%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20y_%7B11%7D%7D%20%26%20%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20y_%7B12%7D%7D%20%26%20%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20y_%7B13%7D%7D%5C%5C%0A%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20y_%7B21%7D%7D%20%26%20%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20y_%7B22%7D%7D%20%26%20%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20y_%7B23%7D%7D%0A%5Cend%7Barray%7D%5Cright)%20%5Ccdot%5Cleft(%5Cbegin%7Barray%7D%7Blll%7D%0Ax_%7B11%7D%20%26%20x_%7B21%7D%20%20%26%20x_%7B31%7D%20%5C%5C%0Ax_%7B12%7D%20%26%20x_%7B22%7D%20%26%20x_%7B32%7D%20%5C%5C%0Ax_%7B13%7D%20%26%20x_%7B23%7D%20%26%20x_%7B33%7D%20%0A%5Cend%7Barray%7D%5Cright)%20%5C%5C%0A%26%20%3D%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20Y%7D%20%5Ccdot%20X%5ET%0A%5Cend%7Baligned%7D%0A"></p><p>ä¸‹é¢æ±‚ <img src="https://math.now.sh?inline=%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20X%7D" style="display:inline-block;margin: 0;"> :</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%26%20%5Cbecause%20%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20x_%7Bjp%7D%20%7D%3D%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20y_%7B1p%7D%7D%20%5Cfrac%7B%5Cpartial%20y_%7B1p%7D%7D%7B%5Cpartial%20x_%7Bjp%7D%7D%2B%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20y_%7B2p%7D%7D%20%5Cfrac%7B%5Cpartial%20y_%7B2p%7D%7D%7B%5Cpartial%20x_%7Bjp%7D%7D%3D%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20y_%7B1p%7D%7D%20w_%7B1%20j%7D%2B%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20y_%7B2p%7D%7D%20w_%7B2%20j%7D%20%5C%5C%0A%26%20%5Ctherefore%20%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20X%7D%3D%5Cleft%28%5Cbegin%7Barray%7D%7Bl%7D%0A%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20x_%7B11%7D%7D%20%26%20%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20x_%7B12%7D%7D%20%26%20%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20x_%7B31%7D%7D%5C%5C%0A%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20x_%7B21%7D%7D%20%26%20%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20x_%7B22%7D%7D%20%26%20%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20x_%7B32%7D%7D%5C%5C%0A%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20x_%7B31%7D%7D%20%26%20%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20x_%7B32%7D%7D%20%26%20%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20x_%7B33%7D%7D%0A%5Cend%7Barray%7D%5Cright%29%20%5C%5C%0A%0A%26%20%3D%5Cleft(%5Cbegin%7Barray%7D%7Bll%7D%0Aw_%7B11%7D%20%26%20w_%7B21%7D%20%5C%5C%0Aw_%7B12%7D%20%26%20w_%7B22%7D%20%5C%5C%0Aw_%7B13%7D%20%26%20w_%7B23%7D%0A%5Cend%7Barray%7D%5Cright)%20%5Ccdot%5Cleft(%5Cbegin%7Barray%7D%7Bc%7D%0A%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20y_%7B11%7D%7D%20%26%20%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20y_%7B12%7D%7D%20%26%20%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20y_%7B13%7D%7D%5C%5C%0A%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20y_%7B21%7D%7D%20%26%20%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20y_%7B22%7D%7D%20%26%20%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20y_%7B23%7D%7D%0A%5Cend%7Barray%7D%5Cright)%20%5C%5C%0A%26%20%3DW%5ET%20%5Ccdot%20%5Cfrac%7B%5Cpartial%20C%7D%7B%5Cpartial%20Y%7D%20%5C%5C%0A%26%0A%5Cend%7Baligned%7D%0A"></p><p>labä¸­çš„ä¾‹å­æ˜¯ï¼š</p>
<p style=""><img src="https://math.now.sh?from=Z%3DA%20%5Ccdot%20W%5ET%2B%5Ciota%20%5Ccdot%20b%5ET%20%5Cquad%20%5Cin%20%5Cmathbb%7BR%7D%5E%7BN%20%5Ctimes%20C_1%7D%0A"></p><p>å¯¹äºä½œä¸šä¸Šçš„æ±‚å¯¼ç»“æœæ˜¯è¿™æ ·çš„ï¼Œå¯èƒ½å”¯ä¸€è¿˜éœ€è¦æƒ³æƒ³çš„å°±æ˜¯ç¬¬ä¸€ä¸ªå¼å­ï¼ŒæŒ‰é“ç†ä¸åº”è¯¥ç¬¬ä¸€é¡¹çš„<img src="https://math.now.sh?inline=%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20Z%7D" style="display:inline-block;margin: 0;">åº”è¯¥åŠ ä¸Šè½¬ç½®ä¹ˆï¼ˆå› ä¸ºæ˜¯åˆ†æ¯å¸ƒå±€ï¼‰ï¼Œå®é™…ä¸Šå› ä¸ºé“¾å¼æ³•åˆ™ä¹Ÿæ˜¯æœ‰æ–¹å‘æ€§ï¼Œåˆ†æ¯å¸ƒå±€éƒ½æ˜¯ä¹˜åœ¨å·¦ä¾§çš„ï¼ˆè¯¦ç»†çš„è§£é‡Šçœ‹ä¸Šé¢çš„ä¾‹å­å’Œä¸‹é¢çš„æ€»ç»“ï¼‰ï¼Œæˆ‘ä»¬éœ€è¦å…ˆæŠŠ<img src="https://math.now.sh?inline=Z" style="display:inline-block;margin: 0;">è½¬ç½®ï¼Œå¾—åˆ°<img src="https://math.now.sh?inline=WA%5ET" style="display:inline-block;margin: 0;">çš„å½¢å¼ï¼Œå†å»å¯¹<img src="https://math.now.sh?inline=A%5ET" style="display:inline-block;margin: 0;">æ±‚å¯¼ï¼Œç„¶åå†æŠŠç­”æ¡ˆè½¬ç½®è¿‡æ¥å°±èƒ½å¾—åˆ°ç»“æœäº†ã€‚</p>
<p style=""><img src="https://math.now.sh?from=%5Cbegin%7Baligned%7D%0A%26%20%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20A%7D%3D%5Cleft%28%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20Z%7D%5Cright%29%20%5Ccdot%5Cleft(%5Cfrac%7B%5Cpartial%20Z%7D%7B%5Cpartial%20A%7D%5Cright)%5ET%20%5Cquad%20%5Cin%20%5Cmathbb%7BR%7D%5E%7BN%20%5Ctimes%20C_0%7D%20%5C%5C%0A%26%20%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20W%7D%3D%5Cleft(%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20Z%7D%5Cright)%5ET%20%5Ccdot%5Cleft(%5Cfrac%7B%5Cpartial%20Z%7D%7B%5Cpartial%20W%7D%5Cright)%20%5Cquad%20%5Cin%20%5Cmathbb%7BR%7D%5E%7BC_1%20%5Ctimes%20C_0%7D%20%5C%5C%0A%26%20%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20b%7D%3D%5Cleft(%5Cfrac%7B%5Cpartial%20L%7D%7B%5Cpartial%20Z%7D%5Cright)%5ET%20%5Ccdot%5Cleft(%5Cfrac%7B%5Cpartial%20Z%7D%7B%5Cpartial%20b%7D%5Cright)%20%5Cquad%20%5Cin%20%5Cmathbb%7BR%7D%5E%7BC_1%20%5Ctimes%201%7D%20%5C%5C%0A%26%0A%5Cend%7Baligned%7D%0A"></p><p>For any linear equation of the kind <img src="https://math.now.sh?inline=Z%20%3D%20AX%20%2B%20c" style="display:inline-block;margin: 0;">, the derivative of <img src="https://math.now.sh?inline=Z" style="display:inline-block;margin: 0;"> with respect to <img src="https://math.now.sh?inline=A" style="display:inline-block;margin: 0;"> is <img src="https://math.now.sh?inline=X" style="display:inline-block;margin: 0;">. The derivative of <img src="https://math.now.sh?inline=Z" style="display:inline-block;margin: 0;"> with respect to <img src="https://math.now.sh?inline=X" style="display:inline-block;margin: 0;"> is <img src="https://math.now.sh?inline=A%5ET" style="display:inline-block;margin: 0;"> . Also the derivative with respect to a transpose is the transpose of the derivative, so the derivative of <img src="https://math.now.sh?inline=Z" style="display:inline-block;margin: 0;"> with respect to <img src="https://math.now.sh?inline=X" style="display:inline-block;margin: 0;"> is <img src="https://math.now.sh?inline=A%5ET" style="display:inline-block;margin: 0;"> but the derivative of <img src="https://math.now.sh?inline=Z" style="display:inline-block;margin: 0;"> with respect to <img src="https://math.now.sh?inline=X%5ET" style="display:inline-block;margin: 0;"> is <img src="https://math.now.sh?inline=A" style="display:inline-block;margin: 0;">.</p>
<p>æ€»ç»“ä¸‹å°±æ˜¯:</p>
<p style=""><img src="https://math.now.sh?from=z%3Df%28Y%29%2C%20Y%3DA%20X%2BB%20%5Crightarrow%20%5Cfrac%7B%5Cpartial%20z%7D%7B%5Cpartial%20X%7D%3DA%5ET%20%5Cfrac%7B%5Cpartial%20z%7D%7B%5Cpartial%20Y%7D%0A"></p><p>è¿™ç»“è®ºåœ¨ <img src="https://math.now.sh?inline=%5Cmathbf%7Bx%7D" style="display:inline-block;margin: 0;"> æ˜¯ä¸€ä¸ªå‘é‡çš„æ—¶å€™ä¹Ÿæˆç«‹, å³:</p>
<p style=""><img src="https://math.now.sh?from=z%3Df%28%5Cmathbf%7By%7D%29%2C%20%5Cmathbf%7By%7D%3DA%20%5Cmathbf%7Bx%7D%2B%5Cmathbf%7Bb%7D%20%5Crightarrow%20%5Cfrac%7B%5Cpartial%20z%7D%7B%5Cpartial%20%5Cmathbf%7Bx%7D%7D%3DA%5ET%20%5Cfrac%7B%5Cpartial%20z%7D%7B%5Cpartial%20%5Cmathbf%7By%7D%7D%0A"></p><p>å¦‚æœè¦æ±‚å¯¼çš„è‡ªå˜é‡åœ¨å·¦è¾¹, çº¿æ€§å˜æ¢åœ¨å³è¾¹, ä¹Ÿæœ‰ç±»ä¼¼ç¨æœ‰ä¸åŒçš„ç»“è®ºå¦‚ä¸‹, è¯æ˜æ–¹æ³•æ˜¯ç±»ä¼¼çš„, è¿™é‡Œç›´æ¥ç»™å‡ºç»“è®º:</p>
<p style=""><img src="https://math.now.sh?from=z%3Df%28Y%29%2C%20Y%3DX%20A%2BB%20%5Crightarrow%20%5Cfrac%7B%5Cpartial%20z%7D%7B%5Cpartial%20X%7D%3D%5Cfrac%7B%5Cpartial%20z%7D%7B%5Cpartial%20Y%7D%20A%5ET%0A"></p><p style=""><img src="https://math.now.sh?from=z%3Df%28%5Cmathbf%7By%7D%29%2C%20%5Cmathbf%7By%7D%3DX%20%5Cmathbf%7Ba%7D%2B%5Cmathbf%7Bb%7D%20%5Crightarrow%20%5Cfrac%7B%5Cpartial%20z%7D%7B%5Cpartial%20%5Cmathbf%7BX%7D%7D%3D%5Cfrac%7B%5Cpartial%20z%7D%7B%5Cpartial%20%5Cmathbf%7By%7D%7D%20a%5ET%0A"></p><p>æœ€åè¿˜æ˜¯æä¸€å˜´ï¼Œåˆ«çŠ¯è¿·ç³Šäº†ï¼Œç®—å‡ºæ¥çš„æ¢¯åº¦æ˜¯ç”¨æ¥æ›´æ–°åŸå‚æ•°çš„ï¼Œä¹Ÿå°±æ˜¯ç›¸å½“äº<img src="https://math.now.sh?inline=%5CDelta%20x" style="display:inline-block;margin: 0;">çš„æ„Ÿè§‰ï¼Œå› ä¸ºæ˜¯å¤šå…ƒå‡½æ•°ï¼Œæ‰€ä»¥æœ€åå¯¹ç›®æ ‡å‡½æ•°çš„å¢ç›Šåº”è¯¥æ˜¯<img src="https://math.now.sh?inline=%5Cgrad%20grad%20%5Ccdot%20%5CDelta%20x" style="display:inline-block;margin: 0;">ï¼Œä¹‹å‰å¤ªä¹…æ²¡çœ‹è¿™éƒ¨åˆ†æ™•äº†ä¸€æ¬¡ã€‚</p>
<blockquote>
<p>å‚è€ƒèµ„æ–™ï¼š<a target="_blank" rel="noopener" href="https://github.com/FelixFu520/README/blob/main/train/optim/matrix_bp.md">https://github.com/FelixFu520/README/blob/main/train/optim/matrix_bp.md</a></p>
</blockquote>
<h3 id="Optimization">Optimization</h3>
<blockquote>
<p>ç”¨è‹±æ–‡å†™å¥½ç´¯å“‡ï¼Œå¼€æ‘†äº†ï¼Œä»¥åä¸­è‹±æ··ç€å†™ï¼Œå¯èƒ½åªæœ‰è‡ªå·±çœ‹å¾—æ‡‚å§ğŸ¤£ï¼Œhhè¿˜æ˜¯è¦ä¿è¯é€šä¿—æ˜“æ‡‚</p>
</blockquote>
<h4 id="Material">Material</h4>
<p>å‚è€ƒèµ„æ–™ï¼š</p>
<p><a target="_blank" rel="noopener" href="http://deeplearning.cs.cmu.edu/F22/document/slides/lec6.optimization.pdf">http://deeplearning.cs.cmu.edu/F22/document/slides/lec6.optimization.pdf</a></p>
<p><a target="_blank" rel="noopener" href="http://deeplearning.cs.cmu.edu/F22/document/slides/lec7.stochastic_gradient.pdf">http://deeplearning.cs.cmu.edu/F22/document/slides/lec7.stochastic_gradient.pdf</a></p>
<p>æ–‡ç« æ¡†æ¶æŒ‰ç…§ä¸‹é¢ä¸¤ä¸ªblogå™è¿°ï¼Œå…·ä½“çš„ç»†èŠ‚å’Œç»„ç»‡æ–¹å¼ä¼šä¸°å¯Œå¾ˆå¤šï¼š</p>
<p><a target="_blank" rel="noopener" href="https://blog.paperspace.com/intro-to-optimization-in-deep-learning-gradient-descent/">https://blog.paperspace.com/intro-to-optimization-in-deep-learning-gradient-descent/</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.paperspace.com/intro-to-optimization-momentum-rmsprop-adam/">https://blog.paperspace.com/intro-to-optimization-momentum-rmsprop-adam/</a></p>
<h4 id="Basic-conceptions">Basic conceptions</h4>
<p>é¦–å…ˆè¿˜æ˜¯æ¥ä»‹ç»ä¸€äº›åŸºç¡€çš„æ¦‚å¿µå’Œideaï¼Œä¼šä»æœ€ç®€å•çš„æ¢¯åº¦ã€æµ·å¡çŸ©é˜µã€æ³°å‹’å±•å¼€è°ˆèµ·ï¼Œæˆ‘ä¼šåˆ†äº«æˆ‘çš„ä¸€äº›æ€è€ƒæ–¹å¼ã€‚ç„¶åä¼šä»‹ç»äºŒæ¬¡ä¼˜åŒ–çš„æ–¹æ³•ï¼Œå†è¿‡æ¸¡åˆ°ç¥ç»ç½‘ç»œçš„ä¼˜åŒ–æ–¹æ³•ã€‚</p>
<p>æ¢¯åº¦èƒ½åæ˜ å¢é•¿æœ€å¿«çš„æ–¹å‘ï¼Œè¿™ä¸ªå¯ä»¥ä»hyperplaneçš„è§’åº¦å»ç†è§£ï¼Œå¯ä»¥å‚è€ƒbä¹çš„è¿™ä¸ªå›ç­” <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/36301367/answer/198887937">here</a>ã€‚äºŒé˜¶å¯¼é™¤äº†å¯ä»¥ç†è§£ä¸ºå¯¼æ•°çš„å¢é•¿ç‡ï¼Œè¿˜å¯ä»¥ä»åŸå‡½æ•°å±€éƒ¨å‡å€¼çš„è§’åº¦ç†è§£ï¼Œä¹Ÿå°±æ˜¯<strong>Laplace</strong> ç®—å­çš„è§’åº¦ï¼Œå¯ä»¥å‚è€ƒè¿™ä¸ªè§†é¢‘ <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=JQSC0lCPG24&amp;list=PLSQl0a2vh4HC5feHa6Rc5c0wbRTx56nF7&amp;index=68">here</a>ã€‚å¤šå…ƒå‡½æ•°çš„æ³°å‹’å±•å¼€å¯ä»¥å†™ä½œçŸ©é˜µä¹˜æ³•çš„å½¢å¼å…¶å®ä¹Ÿæ˜¯ä»scaleæ¨çš„ï¼ŒäºŒé˜¶çš„å±•å¼€æ¨å¯¼å¯ä»¥çœ‹è¿™é‡Œ <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/33316479">here</a>ã€‚</p>
<p>æ¥ä¸‹æ¥å°±æ˜¯å’Œå‡¸ä¼˜åŒ–æœ‰å…³çš„ç†è®ºäº†ï¼Œå¯¹æœ€ç®€å•çš„äºŒæ¬¡ä¼˜åŒ–ï¼Œå…¶å®ç‰›é¡¿æ³•å°±å¯ä»¥ç»™å‡ºæ¯æ¬¡æ›´æ–°çš„æœ€ä¼˜æ–¹å‘å’Œæ­¥é•¿ï¼Œå…¶å®ä¹Ÿå°±æ˜¯æ³°å‹’äºŒé˜¶å±•å¼€åï¼Œè®¡ç®—å¾—åˆ°çš„æœ€ä¼˜å€¼ï¼Œä¸€ç»´scaleçš„æƒ…å†µæ—¶ï¼Œè¿™ä¸ªæœ€ä¼˜çš„å­¦ä¹ ç‡å…¶å®å°±æ˜¯äºŒé˜¶å¯¼çš„å€’æ•°ï¼Œè€Œå¯¹äºå¤šå…ƒå˜é‡ï¼Œå°±å˜æˆäº†æµ·å¡çŸ©é˜µçš„é€†äº†ã€‚</p>
<p>æœ‰å…³Lipschitzå¹³æ»‘ã€å¼ºå¯¹å¶çš„ç†è®ºç›´è§‚ä¸Šçš„æ„Ÿå—å¯ä»¥çœ‹è¿™é‡Œ<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/27554191">here</a>ï¼Œå’Œæ¢¯åº¦ä¸‹é™æ”¶æ•›æ€§è¯æ˜çš„æœ‰å…³ç†è®ºå¯ä»¥çœ‹è¿™ä¸ª <a target="_blank" rel="noopener" href="https://cs.mcgill.ca/~wlh/comp451/files/comp451_chap8.pdf">here</a>ï¼Œè¿˜æœ‰è¿™é‡Œ <a target="_blank" rel="noopener" href="https://www.cs.ubc.ca/~schmidtm/SVAN16/L4.pdf">here</a> (åŠ æ‹¿å¤§çš„å­¦æ ¡çš„æ•™å­¦èµ„æ–™æ˜¯çœŸå¥½å•Š)ï¼Œè¯¦ç»†çš„æˆ‘å°±ä¸ä»‹ç»äº†ã€‚å¤§æ¦‚å°±æ˜¯è¯´å¼ºçªçš„æ”¶æ•›çš„ä¼šæ›´å¿«ï¼Œå¦‚æœåªæ˜¯Lipschitzå¹³æ»‘ä¹Ÿèƒ½æ”¶æ•›ã€‚</p>
<img src="/image/HW1P1_image32.png" alt="image-20230107230430281" style="zoom:80%;">
<img src="/image/HW1P1_image33.png" alt="image-20230107230509280" style="zoom:80%;">
<p>ç°åœ¨æ¥è®²è®²æµ·å¡çŸ©é˜µç‰¹å¾å€¼å’Œæ”¶æ•›çš„å…³ç³»ï¼Œæˆ‘ä»¬çŸ¥é“é€šè¿‡äºŒé˜¶å±•å¼€å¯ä»¥å¾—åˆ°å±€éƒ¨çš„è¿‘ä¼¼ï¼Œè¿™ä¸ªè¿‘ä¼¼åœ¨å±€éƒ¨æœ€å€¼é™„è¿‘çš„ç­‰å€¼çº¿ä½“ç°ä¸ºä¸€ä¸ªæ¤­åœ†ï¼Œè€Œè¿™ä¸ªæ¤­åœ†çš„é•¿çŸ­è½´å°±æ˜¯å’Œæµ·å¡çŸ©é˜µçš„ç‰¹å¾å€¼æˆæ¯”ä¾‹ï¼ŒåŸå› è¿™æ ·çš„ï¼Œé€šè¿‡æ³°å‹’å±•å¼€æˆ‘ä»¬å¯ä»¥æŠŠå‡½æ•°è¿‘ä¼¼å†™ä¸ºäºŒæ¬¡å‹çš„è¡¨è¾¾å¼ï¼Œå¯¹åº”çš„ç­‰å€¼çº¿å°±æ˜¯äºŒæ¬¡æ›²çº¿è¿™ç§ï¼Œé•¿çŸ­è½´å’Œç‰¹å¾å€¼çš„å…³ç³»å°±å¾ˆæ˜æ˜¾äº†ï¼Œé€šè¿‡SVDçš„å‡ ä½•æ„ä¹‰ä¹Ÿå¾ˆå®¹æ˜“å¾—åˆ°ã€‚å¦‚æœæµ·å¡çŸ©é˜µçš„æ¡ä»¶æ•°å¾ˆå¤§ï¼Œä¹Ÿå°±æ˜¯æ¤­åœ†çš„é•¿çŸ­è½´ç›¸å·®å¾ˆå¤§ï¼Œè¯´æ˜è¿™ä¸ªæŸå¤±å‡½æ•°å¹³é¢æ˜¯ç—…æ€çš„ï¼Œå°±æ¯”è¾ƒéš¾æ”¶æ•›ã€‚</p>
<img src="/image/HW1P1_image34.png" alt="image-20230107222504865" style="zoom:80%;">
<img src="/image/HW1P1_image35.png" alt="image-20230107222557585" style="zoom:80%;">
<p>ä½†æ˜¯æµ·å¡çŸ©é˜µçš„é€†è®¡ç®—ä»£ä»·å¤§æ¦‚æ˜¯<img src="https://math.now.sh?inline=O%28N%5E3%29" style="display:inline-block;margin: 0;">çš„ï¼Œæ”¾åˆ°ç¥ç»ç½‘ç»œé‡Œé¢è‚¯å®šæ˜¯å«©ç®—ç®—ä¸å‡ºæ¥çš„ï¼Œä¹Ÿå°±æ˜¯è¯´å¯¹å‚æ•°çš„æ¯ä¸ªåˆ†é‡ç¡®å®šæœ€ä¼˜çš„å­¦ä¹ ç‡æ˜¯å¾ˆéš¾çš„ï¼Œæˆ‘ä»¬è€ƒè™‘ä¸¤ç§ä¸åŒçš„åšæ³•ï¼Œç¬¬ä¸€ç§è¿˜æ˜¯é‡‡å–æ¯ä¸ªåˆ†é‡ç‹¬ç«‹çš„å­¦ä¹ ç‡ï¼Œä½†æ˜¯ä½¿ç”¨å¯å‘å¼çš„æ€è·¯è€Œä¸æ˜¯å«©ç®—ï¼ˆRpropç®—æ³•ï¼‰ï¼Œç¬¬äºŒç§å°±æ˜¯æ‰€æœ‰åˆ†é‡ä¸€ä¸ªå­¦ä¹ ç‡ï¼Œå°±æ˜¯å¸¸è§çš„å­¦ä¹ ç‡ç›´æ¥ä¹˜æ¢¯åº¦å‘é‡ï¼Œä½†æ˜¯è¿™æ ·çš„è¯æ”¶æ•›æ€§å°±ä¸ä¸€å®šèƒ½ä¿è¯äº†ï¼Œä»¥äºŒæ¬¡ä¼˜åŒ–ä¸ºä¾‹ï¼Œå¦‚æœå­¦ä¹ ç‡å¤§äºä»»ä¸€åˆ†é‡æœ€ä¼˜å­¦ä¹ ç‡çš„äºŒå€ï¼Œå°±ä¼šå‘æ•£ï¼Œä¹Ÿç”±æ­¤æå‡ºäº†å­¦ä¹ ç‡è¡°å‡å’Œæ”¶æ•›çš„ç†è®ºï¼ŒRobbins-Munroe conditionsç®—æ˜¯æœ€ç»å…¸çš„æ”¶æ•›æ¡ä»¶ï¼Œä¹Ÿå°±æ˜¯SGDå¯¹äºæ»¡è¶³å‡¸æ€§å’Œå¹³æ»‘çš„æ¨¡å‹ï¼Œåªè¦å­¦ä¹ ç‡æ»¡è¶³ä¸‹é¢çš„æ¡ä»¶å°±ä¼šæ”¶æ•›</p>
<p style=""><img src="https://math.now.sh?from=%5Csum_%7Bk%3D0%7D%5E%7B%5Cinfty%7D%20%5Calpha%5E%7B%28k%29%7D%3D%5Cinfty%20%5Cquad%20%5Csum_%7Bk%3D0%7D%5E%7B%5Cinfty%7D%5Cleft(%5Calpha%5E%7B(k)%7D%5Cright)%5E2%3C%5Cinfty%0A"></p><p>æ­¤å¤–åœ¨æ¢¯åº¦ä¸‹é™çš„è¿‡ç¨‹ä¸­è¿˜å­˜åœ¨ä¸»è¦çš„ä¸¤ä¸ªé—®é¢˜éœ€è¦è§£å†³ï¼Œé’ˆå¯¹è¿™ä¸¤ä¸ªé—®é¢˜æå‡ºçš„å„ç§è§£å†³æ–¹æ³•å°±æ˜¯è¿™èŠ‚çš„é‡ç‚¹å­¦ä¹ å†…å®¹äº†ã€‚ç¬¬ä¸€ä¸ªé—®é¢˜æ˜¯è¾¾ä¸åˆ°å…¨å±€æœ€å€¼ï¼Œä¼šæ”¶æ•›åˆ°å±€éƒ¨æœ€ä¼˜ç‚¹ï¼Œç¬¬äºŒä¸ªé—®é¢˜æ˜¯å¯¹äºç—…æ€çš„æŸå¤±å‡½æ•°å¹³é¢å¾ˆå¯èƒ½ä¼šå‡ºç°éœ‡è¡çš„ç°è±¡ï¼Œå¯¼è‡´æ”¶æ•›æ…¢æ•ˆæœå¾ˆå·®ã€‚</p>
<h4 id="SGD-and-Batch">SGD and Batch</h4>
<p>ç›´æ¥ç”¨å…¨æ ·æœ¬å»è®¡ç®—loss functionä¼šæœ‰è‡³å°‘ä¸¤ä¸ªé—®é¢˜ï¼Œç¬¬ä¸€ä¸ªæ˜¯cycleçš„è¡¨ç°ï¼Œç¬¬äºŒä¸ªæ˜¯ä¸èƒ½é¿å…å±€éƒ¨æœ€å€¼ã€‚é’ˆå¯¹è¿™ä¸ªé—®é¢˜ï¼Œå¯ä»¥åˆ©ç”¨éšæœºé‡‡æ ·è®¡ç®—æ¢¯åº¦ï¼Œæœ€ç®€å•çš„ç­–ç•¥å°±æ˜¯éšæœºå–ä¸€ä¸ªæ ·æœ¬ï¼Œè¿™æ˜¯SGDçš„æ€è·¯ï¼Œä½†æ˜¯è¿™æ ·ä¼šä½¿æ”¶æ•›è¿‡ç¨‹çš„æ–¹å·®å˜å¾—å¾ˆå¤§ï¼Œè€Œä¸”æŸå¤±å‡½æ•°ä¹Ÿä¸ä¼šå˜å¾—è¶³å¤Ÿå°ã€‚</p>
<img src="/image/HW1P1_image36.png" alt="image-20230108115028332" style="zoom:80%;">
<img src="/image/HW1P1_image37.png" alt="image-20230108115100729" style="zoom:80%;">
<p>é’ˆå¯¹è¿™ä¸ªé—®é¢˜ä¹Ÿæ˜¯æå‡ºäº†mini-batchå»è§£å†³ï¼ŒåŒæ ·ä½œä¸ºæ— åä¼°è®¡ï¼Œä½†æ˜¯å…¶æ–¹å·®ç¼©å°ä¸ºåŸæœ¬çš„<img src="https://math.now.sh?inline=%7B1%5Cover%20batch%7D" style="display:inline-block;margin: 0;">å€ï¼Œæ”¶æ•›çš„æ•ˆæœä¹Ÿæ˜¯å¾—åˆ°äº†æå‡ï¼š</p>
<img src="/image/HW1P1_image38.png" alt="image-20230108115150825" style="zoom:80%;">
<img src="/image/HW1P1_image39.png" alt="image-20230108115259488" style="zoom:80%;">
<img src="/image/HW1P1_image40.png" alt="image-20230108115336885" style="zoom:80%;">
<h4 id="Learning-Rate-and-Grad-direction">Learning Rate and Grad direction</h4>
<p>é’ˆå¯¹ç—…æ€çš„éœ‡è¡æƒ…å†µï¼Œå› ä¸ºæˆ‘ä»¬åªèƒ½åˆ©ç”¨ä¸€é˜¶å¯¼çš„ä¿¡æ¯ï¼Œå¦‚æœå¯ä»¥åˆ©ç”¨äºŒé˜¶å¯¼å…¶å®å¯ä»¥è·å¾—æ›²ç‡ç­‰ä¿¡æ¯è¿›è¡Œé¿å…ï¼Œä½†æ˜¯ç”±äºè®¡ç®—é‡æˆ‘ä»¬è¿˜æ˜¯æƒ³ä¸€äº›å¯å‘å¼çš„æ–¹æ³•å»è§£å†³ï¼Œæœªæ¥çš„æ”¹è¿›æ–¹å‘è‚¯å®šå°±æ˜¯ä½•å¦‚å…¼é¡¾äºŒé˜¶ä¿¡æ¯åˆå‡å°‘è¿ç®—é‡ã€‚</p>
<p>è¿™éƒ¨åˆ†è¯´å®è¯èµ„æ–™éƒ½å¾ˆå…¨äº†ï¼Œå€¼å¾—æä¸€å˜´çš„æ˜¯åŸºäºå­¦ä¹ ç‡æ”¹è¿›çš„ç®—æ³•ï¼Œ<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/29920135">AdaGrad</a> å’Œ RMS Propçš„å…³ç³»ï¼ŒRMS Propé€šè¿‡ç§»åŠ¨å¹³å‡è§£å†³äº†Adagradä¸­å¹³æ–¹å’Œç´¯åŠ è¿‡å¤§ç¼ºä¹æ­£åˆ™åŒ–çš„é—®é¢˜ã€‚</p>
<h3 id="Normalization">Normalization</h3>
<img src="/image/HW1P1_image41.png" alt="image-20230108145934082" style="zoom:80%;">
<img src="/image/HW1P1_image42.png" alt="image-20230108150349572" style="zoom:80%;">
<p>å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä½¿ç”¨batch-normçš„è¯ ï¼Œçº¿æ€§å±‚å°±ä¸éœ€è¦é¢å¤–çš„biasé¡¹äº†ï¼Œä¼šè¢«å½’ä¸€åŒ–æ‰ï¼Œç®—æ˜¯ä¸ªArbitraryçš„é€‰æ‹©ï¼Œå¯åŠ å¯ä¸åŠ ã€‚</p>
<img src="/image/HW1P1_image43.png" alt="image-20230108150531429" style="zoom:80%;">
<h2 id="Python-Implementation">Python Implementation</h2>
<p>è¿™éƒ¨åˆ†ç›´æ¥çœ‹æˆ‘ä»“åº“å§ï¼Œå°±ä¸æ”¾åˆ°è¿™é‡Œå†™äº†ï¼š<a target="_blank" rel="noopener" href="https://github.com/XuRui314/CMU-11-785">code</a></p>
<h2 id="Torch-Pipeline">Torch Pipeline</h2>
<p>â€‚Colloquially,training a model can be described like this:</p>
<ol>
<li>
<p>We get data-pairs of questions and answers.</p>
</li>
<li>
<p>For a pair <code>(x, y)</code>, we run <code>x</code> through the model to get the modelâ€™s answer <code>y</code>.</p>
</li>
<li>
<p>Then, a â€œteacherâ€ gives the model a grade depending on â€œhow wrongâ€ <code>y</code>  is compared to the true answer <code>y</code>.</p>
</li>
<li>
<p>Then based on the grade,we figure out whoâ€™s fault the error is.</p>
</li>
<li>
<p>Then, we fix the faults so the model can do better next time.</p>
</li>
</ol>
<p>â€‚To train a model using Pytorch, in general, there are 5 main parts:</p>
<ol>
<li>Data</li>
<li>Model</li>
<li>Loss Function</li>
<li>Backpropagation</li>
<li>Optimizer</li>
</ol>
<h3 id="Data">Data</h3>
<p>â€‚When training a model, data is generally a long list of <code>(x, y)</code> pairs, where you want the model to see <code>x</code> and predict <code>y</code>.</p>
<p>â€‚Pytorch has two classes you will need to use to deal with data:</p>
<ul>
<li><code>torch.utils.data.Dataset</code></li>
<li><code>torch.utils.data.Dataloader</code></li>
</ul>
<p>â€‚Dataset class is used to preprocess data and load single pairs <code>(x, y)</code></p>
<p>â€‚Dataloader class uses your Dataset class to get single pairs and group them into batches</p>
<img src="\image\HW1P1_image7.png" alt="image-20221215214237507" style="zoom:80%;">
<p>â€‚When defining a Dataset, there are three class methods that you need to implement 3 methods: <code>__init__</code>, <code>__len__</code>, <code>__getitem__</code>.</p>
<p>â€‚Use <code>__init__</code> to load the data to the class so it can be accessed later, Pytorch will use <code>__len__</code> to know how many <code>(x, y)</code> pairs (training samples) are in your dataset. After using <code>__len__</code> to figure out how many samples there are, Pytorch will use <code>__getitem__</code> to ask for() a certain sample. So <code>__getitem__(i)</code> should return the â€œi-thâ€ sample, with order chosen by you. You should use <code>getitem</code> to do some final processing on the data before itâ€™s sent out. Since <code>__getitem__</code> will be called maybe millions of times, so make sure you do as little work in here as possible for fast code. Try to keep heavy preprocessing in <code>__init__</code>, which is only called once</p>
<p>â€‚Here is a simple Dataset example:</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDataset</span>(<span class="params">data.Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, X, Y</span>):</span></span><br><span class="line">        self.X = X</span><br><span class="line">        self.Y = Y</span><br><span class="line">      </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self.Y</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.Y)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        X = self.X[index].<span class="built_in">float</span>().reshape(-<span class="number">1</span>) <span class="comment">#flatten the input</span></span><br><span class="line">        Y = self.Y[index].long()</span><br><span class="line">        <span class="keyword">return</span> X, Y</span><br></pre></td></tr></tbody></table></figure>
<p>â€‚Here is a simple Dataloader example:</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Training</span></span><br><span class="line">train_dataset = MyDataset(train.train_data, train.train_labels)</span><br><span class="line"></span><br><span class="line">train_loader_args = <span class="built_in">dict</span>(shuffle = <span class="literal">True</span>, batch_size = <span class="number">256</span>, num_workers = num_workers, pin_memory = <span class="literal">True</span>)\</span><br><span class="line"><span class="keyword">if</span> cuda <span class="keyword">else</span> <span class="built_in">dict</span>(shuffle = <span class="literal">True</span>, batch_size = <span class="number">64</span>)</span><br><span class="line"></span><br><span class="line">train_loader = data.DataLoader(train_dataset, **train_loader_args)</span><br></pre></td></tr></tbody></table></figure>
<h3 id="Model">Model</h3>
<p>â€‚This section will be in two parts:</p>
<p>â€¢ How to generate the model youâ€™ll use</p>
<p>â€¢ How to run the data sample through the model.</p>
<img src="\image\HW1P1_image8.png" alt="image-20221215224941804" style="zoom:80%;">
<p>â€‚One key point in neural network is modularity, this means when coding a network, we can break down the structure into small parts and take it step by step.</p>
<p>â€‚Now, letâ€™s get into coding a model in Pytorch. Networks in Pytorch are (generally) classes that are based off of the <code>nn.Module class</code>. Similar to the Dataset class, Pytorch wants you to implement the <code>__init__ </code> and <code>forward</code> methods.</p>
<p>â€¢ <code>__init__</code>: this is where you define the actual model itself (along with other</p>
<p>stuff you might need)</p>
<p>â€¢ <code>Forward</code>: given an input <code>x</code>, you run it through the model defined in <code>__init__</code></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Our_Model</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        </span><br><span class="line">        self.layer1 = nn.Linear(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">        self.layer2 = nn.Linear(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">        self.layer3 = nn,Linear(<span class="number">4</span>, <span class="number">1</span>)</span><br><span class="line">      </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        out = self.layer1(x)</span><br><span class="line">        out = self.layer2(out)</span><br><span class="line">        out = self.layer3(out)</span><br><span class="line">      </span><br><span class="line">    	<span class="keyword">return</span> out</span><br></pre></td></tr></tbody></table></figure>
<p>â€‚However, it can get annoying to type each of the layers twice â€“ once in <code>__init__ </code>and once in forward. Since on the right, we take the output of each layer and directly put it into the next, we can use the <strong>nn.Sequential</strong> module.</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Our_Model</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        layers = {</span><br><span class="line">            nn.Linear(<span class="number">3</span>, <span class="number">4</span>),</span><br><span class="line">            nn.Linear(<span class="number">4</span>, <span class="number">4</span>),</span><br><span class="line">            nn.Linear(<span class="number">4</span>, <span class="number">1</span>)</span><br><span class="line">        }</span><br><span class="line">        self.layers = nn.Sequential(*layers) <span class="comment"># * operator opens up the lsit and directly puts them in as arguments of nn.Sequential</span></span><br><span class="line">        </span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.layers(out)</span><br></pre></td></tr></tbody></table></figure>
<p>â€‚As a beginner to Pytorch, you should definitely have <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/nn.html">link</a> open. The documentation is very thorough. Also, for optimizers: <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/optim.html">link</a>.</p>
<p>â€‚Now that we have our model generated, how do we use it? First, we want to put the model on GPU. Note that for <code>nn.Module</code> classes, <code>.to(device)</code> is in-place. However, for tensors, you must do <code>x = x.to(device)</code></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">"cuda"</span> <span class="keyword">if</span> cuda <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line">model.to(device)</span><br></pre></td></tr></tbody></table></figure>
<p>â€‚Also, models have <code>.train()</code> and <code>.eval()</code> methods. Before training, you should run <code>model.train()</code> to tell the model to save gradients. When validating or testing, run <code>model.eval()</code> to tell the model it doesnâ€™t need to save gradients (save memory and time). A common mistake is to forget to toggle back to .train(), then your model doesnâ€™t learn anything.</p>
<p>â€‚So far, we can build:</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Dataset Stuff</span></span><br><span class="line">train_dataset = MyDataset(train.train_data, train.train_labels)</span><br><span class="line"></span><br><span class="line">train_loader_args = <span class="built_in">dict</span>(shuffle = <span class="literal">True</span>, batch_size = <span class="number">256</span>, num_workers = num_workers, pin_memory = <span class="literal">True</span>)\</span><br><span class="line"><span class="keyword">if</span> cuda <span class="keyword">else</span> <span class="built_in">dict</span>(shuffle = <span class="literal">True</span>, batch_size = <span class="number">64</span>)</span><br><span class="line"></span><br><span class="line">train_loader = data.DataLoader(train_dataset, **train_loader_args)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Model Stuff</span></span><br><span class="line">model = nn.Sequential(nn.Linear(<span class="number">3</span>,<span class="number">4</span> ), nn.Linear(<span class="number">4</span>, <span class="number">4</span>), nn.Linear(<span class="number">4</span>, <span class="number">1</span>))</span><br><span class="line">device = torch.device[<span class="string">"cuda"</span> <span class="keyword">if</span> cuda <span class="keyword">else</span> <span class="string">"cpu"</span>]</span><br><span class="line">model.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Optimization Stuff</span></span><br><span class="line">NUM_EPOCHS = <span class="number">100</span></span><br><span class="line"><span class="comment"># ----------------- #</span></span><br><span class="line"><span class="comment"># |	Not	cover yet | # initialize the criterion</span></span><br><span class="line"><span class="comment"># ----------------- #</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Training</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(NUM_EPOCHS):</span><br><span class="line">    model.train()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(x, y) <span class="keyword">in</span> train_loaders:</span><br><span class="line">        <span class="comment"># ----------------- #</span></span><br><span class="line">		<span class="comment"># |	Not	cover yet | # optimizer initialize</span></span><br><span class="line">		<span class="comment"># ----------------- #</span></span><br><span class="line">        x.to(device)</span><br><span class="line">        y.to(device)</span><br><span class="line">        </span><br><span class="line">        output = model(x)</span><br><span class="line">        <span class="comment"># ----------------- #</span></span><br><span class="line">		<span class="comment"># |	Not	cover yet | # calculate loss, minimize this loss and backpropagate</span></span><br><span class="line">		<span class="comment"># ----------------- #</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="Loss-Function">Loss Function</h3>
<p>To recap, we have run x through our model and gotten â€œoutput,â€ or <code>y</code>. Recall we need something to tell us how wrong it is compared to the true answer <code>y</code>. We rely on a â€œloss function,â€ also called a â€œcriterionâ€ to tell us this. The choice of a criterion will depend on the model/application/task,  but for classification, a criterion called â€œCrossEntropyLossâ€ is commonly used.</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Optimization Stuff</span></span><br><span class="line">NUM_EPOCHS = <span class="number">100</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"><span class="comment"># ----------------- #</span></span><br><span class="line"><span class="comment"># |	Not	cover yet | #</span></span><br><span class="line"><span class="comment"># ----------------- #</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Training</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(NUM_EPOCHS):</span><br><span class="line">    model.train()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(x, y) <span class="keyword">in</span> train_loaders:</span><br><span class="line">        <span class="comment"># ----------------- #</span></span><br><span class="line">		<span class="comment"># |	Not	cover yet | #</span></span><br><span class="line">		<span class="comment"># ----------------- #</span></span><br><span class="line">        x.to(device)</span><br><span class="line">        y.to(device)</span><br><span class="line">        </span><br><span class="line">        output = model(x)</span><br><span class="line">        loss = criterion(output, y)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># ----------------- #</span></span><br><span class="line">		<span class="comment"># |	Not	cover yet | #</span></span><br><span class="line">		<span class="comment"># ----------------- #</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="Backpropagation-2">Backpropagation</h3>
<p>Backpropagation is the process of working backwards from the loss and calculating the gradients of every single (trainable) parameter w.r.t the loss. The gradients tell us the direction in which to move to minimize the loss.</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Training</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(NUM_EPOCHS):</span><br><span class="line">    model.train()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(x, y) <span class="keyword">in</span> train_loaders:</span><br><span class="line">        <span class="comment"># ----------------- #</span></span><br><span class="line">		<span class="comment"># |	Not	cover yet | #</span></span><br><span class="line">		<span class="comment"># ----------------- #</span></span><br><span class="line">        x.to(device)</span><br><span class="line">        y.to(device)</span><br><span class="line">        </span><br><span class="line">        output = model(x)</span><br><span class="line">        loss = criterion(output, y)</span><br><span class="line">        </span><br><span class="line">        loss.backward() <span class="comment"># add here</span></span><br><span class="line">        <span class="comment"># ----------------- #</span></span><br><span class="line">		<span class="comment"># |	Not	cover yet | #</span></span><br><span class="line">		<span class="comment"># ----------------- #</span></span><br></pre></td></tr></tbody></table></figure>
<p>By doing <code>loss.backward()</code>, we get gradients w.r.t the loss. Remember model.train()? That allowed us to compute the gradients. If it had been in the eval state, we wouldnâ€™t be able to even compute the gradients, much less train.</p>
<h3 id="Optimizer">Optimizer</h3>
<p>Now, backprop only <em>computes</em> the <img src="https://math.now.sh?inline=%E2%88%87p" style="display:inline-block;margin: 0;"> values â€“ it doesnâ€™t do anything with them. We want to <em>update</em> the value of <img src="https://math.now.sh?inline=p" style="display:inline-block;margin: 0;"> using <img src="https://math.now.sh?inline=%E2%88%87p" style="display:inline-block;margin: 0;">. This is the optimizerâ€™s job.</p>
<p>A crucial component of any optimizer is the â€œlearning rate.â€ This is a hyperparameter that controls how much we should believe in <img src="https://math.now.sh?inline=%E2%88%87p" style="display:inline-block;margin: 0;">.  Again, this will be covered in more detail in a future lecture. Ideally, <img src="https://math.now.sh?inline=%E2%88%87p" style="display:inline-block;margin: 0;"> is a perfect assignment of blame w.r.t the <strong>entire</strong> dataset. However, itâ€™s likely that optimizing to perfectly match the <em>current</em> (x, y) sample <img src="https://math.now.sh?inline=%E2%88%87p" style="display:inline-block;margin: 0;"> was generated from wonâ€™t be great for matching the entire dataset.</p>
<p>Among other concerns, the optimizer <em>weights</em> the <img src="https://math.now.sh?inline=%E2%88%87p" style="display:inline-block;margin: 0;"> with the learning rate and use the weighted âˆ‡p to update <img src="https://math.now.sh?inline=p" style="display:inline-block;margin: 0;">.</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Optimization Stuff</span></span><br><span class="line">NUM_EPOCHS = <span class="number">100</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr = <span class="number">1e-4</span>) <span class="comment"># add here</span></span><br><span class="line"><span class="comment">#Training</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(NUM_EPOCHS):</span><br><span class="line">    model.train()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(x, y) <span class="keyword">in</span> train_loaders:</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        x.to(device)</span><br><span class="line">        y.to(device)</span><br><span class="line">        </span><br><span class="line">        output = model(x)</span><br><span class="line">        loss = criterion(output, y)</span><br><span class="line">        </span><br><span class="line">        loss.backward() <span class="comment"># add here</span></span><br><span class="line">        optimizer.step()</span><br></pre></td></tr></tbody></table></figure>
<p>What is zero_grad? Every call to .backward() saves gradients for each parameter in the model. However, calling <code>optimizer.step()</code> <strong>does not</strong> delete these gradients after using them. So, you want to remove them so they donâ€™t interfere with the gradients of the next sample.</p>
<p>By doing <code>optimizer.step()</code>, we update the weights of the model using the computed gradients.</p>
<p>After here, you would generally perform validation (after every epoch or a couple), to see how your model performs on data it is not trained on. Validation follows a similar format as training, but without <code>loss.backward()</code> or <code>optimizer.step()</code>. You should  check the notebooks for more guidance.</p>
<blockquote>
<p>The complete code: <a target="_blank" rel="noopener" href="https://colab.research.google.com/drive/1huAQcxM9jMqSNb4h6XJ78Xd8EM1-UF_x#scrollTo=Sg8IUZ1er0dl">link</a></p>
</blockquote>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">zxr</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://xurui314.github.io/2022/12/15/HW1P1/">https://xurui314.github.io/2022/12/15/HW1P1/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Deep-Learning/">Deep Learning</a></div><div class="post_share"><div class="social-share" data-image="https://s2.loli.net/2022/12/15/dGcSa6TvyYk5riO.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer=""></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/12/15/HW0/"><img class="prev-cover" src="https://s2.loli.net/2023/01/10/PJvrBojwE1F3KIR.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">HW0</div></div></a></div><div class="next-post pull-right"><a href="/2022/10/25/Deep-Generative-Model/"><img class="next-cover" src="https://s2.loli.net/2022/10/25/XhxITA72oyGnDEQ.webp" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Deep Generative Model</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2022/06/16/nlp-learning-recording/" title="nlp learning recording"><img class="cover" src="https://images.unsplash.com/photo-1501555088652-021faa106b9b?ixlib=rb-1.2.1&amp;ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&amp;auto=format&amp;fit=crop&amp;w=873&amp;q=80" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-06-16</div><div class="title">nlp learning recording</div></div></a></div><div><a href="/2022/06/01/Multimodal-NER/" title="Multimodal NER"><img class="cover" src="https://s2.loli.net/2022/06/01/NGZoMHJQIyVS5Ab.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-06-01</div><div class="title">Multimodal NER</div></div></a></div><div><a href="/2023/01/14/HW2P1/" title="HW2P1"><img class="cover" src="https://s2.loli.net/2023/01/14/wlGYSmRduNIpHCc.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-14</div><div class="title">HW2P1</div></div></a></div><div><a href="/2023/03/03/HW1P2/" title="HW1P2"><img class="cover" src="https://s2.loli.net/2023/03/03/gFraLwmNBfkz9Dy.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-03</div><div class="title">HW1P2</div></div></a></div><div><a href="/2023/03/03/HW2P2/" title="HW2P2"><img class="cover" src="https://s2.loli.net/2023/03/03/Qav93NjokKmWh7A.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-03</div><div class="title">HW2P2</div></div></a></div><div><a href="/2023/03/08/HW3P1/" title="HW3P1"><img class="cover" src="https://s2.loli.net/2023/03/08/CSvgBbyca1RNiEF.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-08</div><div class="title">HW3P1</div></div></a></div></div></div><hr><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div><div id="comment-switch"><span class="first-comment">Valine</span><span class="switch-btn"></span><span class="second-comment">Disqus</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div><div><div id="disqus_thread"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://s2.loli.net/2021/12/08/yTYthVwXD4IPbJ9.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"></div><div class="author-info__name">zxr</div><div class="author-info__description">Think and Do like an MIT student</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">70</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">33</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">16</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/XuRui314"><i class="fab fa-github"></i><span>This is zxr!ğŸš€</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/XuRui314" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://mail.qq.com/" target="_blank" title="Email-1977289398@qq.com"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">zxrçš„ç”Ÿæ´»ï¼Œmathï¼Œç¼–ç¨‹è®°å½•,<div class="twopeople"><div class="container" style="height:200px;"><canvas class="illo" width="800" height="800" style="max-width: 200px; max-height: 200px; touch-action: none; width: 640px; height: 640px;"></canvas></div><script src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/js/twopeople1.js"></script><script src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/js/zdog.dist.js"></script><script id="rendered-js" src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/js/twopeople.js"></script><style>.twopeople{margin: 0;align-items: center;justify-content: center;text-align: center;}canvas{display: block;margin: 0 auto;cursor: move;}</style></div><div class="twopeople"></div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduction"><span class="toc-number">1.</span> <span class="toc-text">Introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Representation"><span class="toc-number">1.1.</span> <span class="toc-text">Representation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Learning"><span class="toc-number">1.2.</span> <span class="toc-text">Learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Backpropagation"><span class="toc-number">1.3.</span> <span class="toc-text">Backpropagation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Optimization"><span class="toc-number">1.4.</span> <span class="toc-text">Optimization</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Material"><span class="toc-number">1.4.1.</span> <span class="toc-text">Material</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Basic-conceptions"><span class="toc-number">1.4.2.</span> <span class="toc-text">Basic conceptions</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#SGD-and-Batch"><span class="toc-number">1.4.3.</span> <span class="toc-text">SGD and Batch</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Learning-Rate-and-Grad-direction"><span class="toc-number">1.4.4.</span> <span class="toc-text">Learning Rate and Grad direction</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Normalization"><span class="toc-number">1.5.</span> <span class="toc-text">Normalization</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Python-Implementation"><span class="toc-number">2.</span> <span class="toc-text">Python Implementation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Torch-Pipeline"><span class="toc-number">3.</span> <span class="toc-text">Torch Pipeline</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Data"><span class="toc-number">3.1.</span> <span class="toc-text">Data</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Model"><span class="toc-number">3.2.</span> <span class="toc-text">Model</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Loss-Function"><span class="toc-number">3.3.</span> <span class="toc-text">Loss Function</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Backpropagation-2"><span class="toc-number">3.4.</span> <span class="toc-text">Backpropagation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Optimizer"><span class="toc-number">3.5.</span> <span class="toc-text">Optimizer</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/03/13/2023-deep-learning/" title="2023 deep learning"><img src="https://www.csail.mit.edu/sites/default/files/2017-08/15473005358_576e646680_o.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2023 deep learning"></a><div class="content"><a class="title" href="/2023/03/13/2023-deep-learning/" title="2023 deep learning">2023 deep learning</a><time datetime="2023-03-13T08:03:35.000Z" title="Created 2023-03-13 16:03:35">2023-03-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/08/HW3P1/" title="HW3P1"><img src="https://s2.loli.net/2023/03/08/CSvgBbyca1RNiEF.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="HW3P1"></a><div class="content"><a class="title" href="/2023/03/08/HW3P1/" title="HW3P1">HW3P1</a><time datetime="2023-03-08T14:18:15.000Z" title="Created 2023-03-08 22:18:15">2023-03-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/03/HW2P2/" title="HW2P2"><img src="https://s2.loli.net/2023/03/03/Qav93NjokKmWh7A.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="HW2P2"></a><div class="content"><a class="title" href="/2023/03/03/HW2P2/" title="HW2P2">HW2P2</a><time datetime="2023-03-03T03:08:13.000Z" title="Created 2023-03-03 11:08:13">2023-03-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/03/HW1P2/" title="HW1P2"><img src="https://s2.loli.net/2023/03/03/gFraLwmNBfkz9Dy.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="HW1P2"></a><div class="content"><a class="title" href="/2023/03/03/HW1P2/" title="HW1P2">HW1P2</a><time datetime="2023-03-03T03:07:57.000Z" title="Created 2023-03-03 11:07:57">2023-03-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/01/31/2023-1-31/" title="2023/1/31"><img src="https://s2.loli.net/2023/01/31/brpA1VLFRYXxt2T.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2023/1/31"></a><div class="content"><a class="title" href="/2023/01/31/2023-1-31/" title="2023/1/31">2023/1/31</a><time datetime="2023-01-31T14:40:46.000Z" title="Created 2023-01-31 22:40:46">2023-01-31</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">Â©2020 - 2023 By zxr</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="github-badge"><a style="color: #fff" rel="license" href="https://hexo.io/" target="_blank" title="ç”± Hexo å¼ºåŠ›é©±åŠ¨"><span class="badge-subject">Powered</span><span class="badge-value bg-blue">Hexo</span></a><a style="color: #fff" rel="license" href="https://gitee.com/" target="_blank" title="é™æ€ç½‘é¡µæ‰˜ç®¡äº GitHub Pages å’Œ Coding Pages å’Œ Gitee Pages"><span class="badge-subject">Hosted</span><span class="badge-value bg-brightgreen">GitHub &amp; Coding &amp; Gitee</span></a><a style="color: #fff" rel="license" href="https://www.jsdelivr.com/" target="_blank" title="jsDelivr æä¾› CDN åŠ é€ŸæœåŠ¡"><span class="badge-subject">CDN</span><span class="badge-value bg-orange">jsDelivr</span></a><a style="color: #fff" rel="license" href="https://jerryc.me" target="_blank" title="ç«™ç‚¹ä½¿ç”¨ Butterflyä¸»é¢˜"><span class="badge-subject">Theme</span><span class="badge-value bg-blue">Butterfly</span></a><a style="color: #fff" rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" title="æœ¬ç«™ç‚¹é‡‡ç”¨çŸ¥è¯†å…±äº«ç½²å-éå•†ä¸šæ€§ä½¿ç”¨-ç›¸åŒæ–¹å¼å…±äº« 4.0 å›½é™…è®¸å¯åè®®è¿›è¡Œè®¸å¯"><span class="badge-subject"><i class="fa fa-copyright"></i></span><span class="badge-value bg-lightgrey">BY-NC-SA 4.0  </span></a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="Increase font size"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="Decrease font size"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = '[object Object]'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: '',
      appKey: '',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script>function loadDisqus () {
  var disqus_config = function () {
    this.page.url = 'https://xurui314.github.io/2022/12/15/HW1P1/'
    this.page.identifier = '2022/12/15/HW1P1/'
    this.page.title = 'HW1P1'
  };

  window.disqusReset = () => {
    DISQUS.reset({
      reload: true,
      config: disqus_config
    })
  }

  if (window.DISQUS) disqusReset()
  else {
    (function() { 
      var d = document, s = d.createElement('script');
      s.src = 'https://.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  }
}

if ('Valine' === 'Disqus' || !false) {
  if (false) btf.loadComment(document.getElementById('disqus_thread'), loadDisqus)
  else loadDisqus()
} else {
  function loadOtherComment () {
    loadDisqus()
  }
}
</script></div><script src="https://cdn.jsdelivr.net/gh/XuRui314/live2d-widget@1.0.1/autoload.js"></script><script src="/js/title.js"></script><script src="/dist/nochocolate.js"></script><div id="aplayer"></div><script type="text/javascript" src="/dist/APlayer.min.js"></script><script type="text/javascript" src="/dist/music.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/gh/metowolf/MetingJS@1.2/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = [
  'title',
  '#config-diff',
  '#body-wrap',
  '#rightside-config-hide',
  '#rightside-config-show',
  '.js-pjax'
]

if (false) {
  pjaxSelectors.unshift('meta[property="og:image"]', 'meta[property="og:title"]', 'meta[property="og:url"]')
}

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.removeEventListener('scroll', window.tocScrollFn)
  window.removeEventListener('scroll', scrollCollect)

  typeof preloader === 'object' && preloader.initLoading()
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // Analytics
  if (false) {
    MtaH5.pgv()
  }

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async="" data-pjax="" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax="">if(document.getElementById('recent-posts') && (location.pathname ==='all'|| 'all' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/Math/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">ğŸ“š zxrã®æ•°å­¦ä¸–ç•Œ (12)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/ç®—æ³•å­¦ä¹ /"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">ğŸ® zxrã®ç®—æ³•å­¦ä¹  (6)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/ç”Ÿæ´»è¶£é—»/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">ğŸ±â€ğŸ‘“ zxrã®ç”Ÿæ´»è¶£é—» (4)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/ç¼–ç¨‹å®ä¾‹/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">ğŸ‘©â€ğŸ’» zxrã®ç¼–ç¨‹å­¦ä¹  (4)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/ç”Ÿæ´»æ„Ÿæ‚Ÿ/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">ğŸš´â€â™‚ zxrã®ç”Ÿæ´»æ„Ÿæ‚Ÿ (11)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/Hexo/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">ğŸ’Œ zxrã®Blogè®°å½• (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="https://XuRui314.github.io/categories" style="flex:1;text-align: center;margin-bottom: 10px;">æŸ¥çœ‹æ›´å¤š...</a></div></div>';
    console.log('å·²æŒ‚è½½magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style> <script data-pjax="">if(document.getElementById('recent-posts') && location.pathname =='/'){
    
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/09/17/9H5WSbTrVejOdkz.jpg" alt="https://i.loli.net/2021/09/17/9H5WSbTrVejOdkz.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-09-17</span><a class="blog-slider__title" href="2021/09/17/æ¦‚ç‡å’Œæµ‹åº¦/">æ¦‚ç‡å’Œæµ‹åº¦(ZJUå¤§ä½¬)</a><div class="blog-slider__text">æ¥çœ‹çœ‹ZJUè®¡ç§‘å¤§ä½¬è§£é‡Šæ¦‚ç‡å’Œæµ‹åº¦ğŸ¥™</div><a class="blog-slider__button" href="2021/09/17/æ¦‚ç‡å’Œæµ‹åº¦/">è¯¦æƒ…</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/25/bPy5m3j9QAilwr2.jpg" alt="https://i.loli.net/2021/08/25/bPy5m3j9QAilwr2.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-08-26</span><a class="blog-slider__title" href="2021/08/26/ç®—æ³•é¢˜ç›®ç»ƒä¹ /">AcWing-Oj-åˆ·é¢˜å­¦ä¹ è®°å½•(åŸºç¡€ç®—æ³•)</a><div class="blog-slider__text">æ¥çœ‹ç®—æ³•è’Ÿè’»çš„ä¸¢äººæ—¥å¸¸å•ŠğŸ‘©â€ğŸ¦½</div><a class="blog-slider__button" href="2021/08/26/ç®—æ³•é¢˜ç›®ç»ƒä¹ /">è¯¦æƒ…</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/15/NYcSXrECnvzOiLP.jpg" alt="https://i.loli.net/2021/08/15/NYcSXrECnvzOiLP.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-08-15</span><a class="blog-slider__title" href="2021/08/15/ä¸¤å±‚ç¥ç»ç½‘ç»œè¯†åˆ«æ‰‹å†™æ•°å­—/">ä¸¤å±‚ç¥ç»ç½‘ç»œè¯†åˆ«æ‰‹å†™æ•°å­—</a><div class="blog-slider__text">è¯†åˆ«æ‰‹å†™æ•°å­—æœ€ç®€å•çš„å®ç°ğŸ§¦</div><a class="blog-slider__button" href="2021/08/15/ä¸¤å±‚ç¥ç»ç½‘ç»œè¯†åˆ«æ‰‹å†™æ•°å­—/">è¯¦æƒ…</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/15/F8aP7R36IidpCt5.jpg" alt="https://i.loli.net/2021/08/15/F8aP7R36IidpCt5.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-08-14</span><a class="blog-slider__title" href="2021/08/14/ç¥ç»ç½‘ç»œæ­å»ºå‡†å¤‡å†…å®¹/">ç¥ç»ç½‘ç»œæ­å»ºå‡†å¤‡å†…å®¹</a><div class="blog-slider__text">å¦‚ä½•è¯†åˆ«æ‰‹å†™ğŸ”¢ï¼Œzxrå¸¦ä½ ä¸€æ­¥ä¸€æ­¥å®ç°ğŸ¼</div><a class="blog-slider__button" href="2021/08/14/ç¥ç»ç½‘ç»œæ­å»ºå‡†å¤‡å†…å®¹/">è¯¦æƒ…</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/12/SJs3MgYC7x8IU26.jpg" alt="https://i.loli.net/2021/08/12/SJs3MgYC7x8IU26.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-08-12</span><a class="blog-slider__title" href="2021/08/12/xuperchain-solidity/">xuperchain&solidity</a><div class="blog-slider__text">åŒºå—é“¾ä¸æ­¢æ˜¯æŒ–å¸ï¼Œè¿˜æœ‰vç¥å’ŒsolidityğŸˆ</div><a class="blog-slider__button" href="2021/08/12/xuperchain-solidity/">è¯¦æƒ…</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/07/27/6fy8mTCbAOWPkrq.png" alt="https://i.loli.net/2021/07/27/6fy8mTCbAOWPkrq.png"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-07-26</span><a class="blog-slider__title" href="2021/07/26/FFT/">FFTçš„è¯¦è§£</a><div class="blog-slider__text">è¿™ä¹ˆå¥½çœ‹çš„FFTï¼Œä¿¡å·ç‹—éƒ½é¦‹å“­äº†ğŸ’¦</div><a class="blog-slider__button" href="2021/07/26/FFT/">è¯¦æƒ…</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/09/zdt4YKoehQvR96S.jpg" alt="https://i.loli.net/2021/08/09/zdt4YKoehQvR96S.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-08-09</span><a class="blog-slider__title" href="2021/08/09/ç‚’é¸¡å¥½ç†è§£çš„æµ‹åº¦è®º/">ç‚’é¸¡å¥½ç†è§£çš„æµ‹åº¦è®º</a><div class="blog-slider__text">ä¸‰æ®µå­—ï¼Œè®©ä½ è¯»æ‡‚æµ‹åº¦è®º</div><a class="blog-slider__button" href="2021/08/09/ç‚’é¸¡å¥½ç†è§£çš„æµ‹åº¦è®º/">è¯¦æƒ…</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/12/wF7TJlqxOLEWGQk.png" alt="https://i.loli.net/2021/08/12/wF7TJlqxOLEWGQk.png"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-07-27</span><a class="blog-slider__title" href="2021/07/27/FT/">å‚…é‡Œå¶å­¦ä¹ èµ„æ–™</a><div class="blog-slider__text">ç®€å•å¥½å­¦çš„å‚…é‡Œå¶å­¦ä¹ èµ„æ–™</div><a class="blog-slider__button" href="2021/07/27/FT/">è¯¦æƒ…</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/07/27/f7jO8hlNpzWVXSP.jpg" alt="https://i.loli.net/2021/07/27/f7jO8hlNpzWVXSP.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-07-26</span><a class="blog-slider__title" href="2021/07/26/hello-world/">å¤§é¸Ÿè½¬è½¬è½¬é…’å§å†…éƒ¨ç»å¯†æ¡£æ¡ˆ</a><div class="blog-slider__text">ä¸è¦ç‚¹è¿›æ¥QAQï¼</div><a class="blog-slider__button" href="2021/07/26/hello-world/">è¯¦æƒ…</a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('å·²æŒ‚è½½swiper')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script>
<script data-pjax="" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper/swiper/swiper.min.js"></script>
<script data-pjax="" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper@0.18/swiper/swiperindex.js"></script>
<style></style><script data-pjax="">function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('å·²æŒ‚è½½electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // æ— æŠ¥é”™ï¼Œä½†ä¸å½±å“ä½¿ç”¨(æ”¯æŒpjaxè·³è½¬)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // æœ‰æŠ¥é”™ï¼Œä½†ä¸å½±å“ä½¿ç”¨(æ”¯æŒpjaxè·³è½¬)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax="" src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script>
  <script data-pjax="" src="https://cdn.jsdelivr.net/gh/Zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script>
  <script data-pjax="">
        function GithubCalendarConfig(){
            var git_githubapiurl ="https://python-github-calendar-api.vercel.app/api?XuRui314";
            var git_color =['#ebedf0', '#fdcdec', '#fc9bd9', '#fa6ac5', '#f838b2', '#f5089f', '#c4067e', '#92055e', '#540336', '#48022f', '#30021f'];
            var git_user ="XuRui314";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="height:100%;display: flex;align-items: center;justify-content: center;"><svg style="height:50px" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>';
            if(parent_div_git && location.pathname =='/'){
                console.log('å·²æŒ‚è½½github calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // æ— æŠ¥é”™ï¼Œä½†ä¸å½±å“ä½¿ç”¨(æ”¯æŒpjaxè·³è½¬)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // æœ‰æŠ¥é”™ï¼Œä½†ä¸å½±å“ä½¿ç”¨(æ”¯æŒpjaxè·³è½¬)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:248px}@media screen and (max-width:650px) {#github_container{background-image:;min-height:0px}}</style>
    <style></style><script async="" src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"live2d-widget-model-wanko"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.7},"log":false});</script></body></html>