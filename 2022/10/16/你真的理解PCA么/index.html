<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>你真的理解PCA么 | XuRui-Blog</title><meta name="keywords" content="PCA"><meta name="author" content="zxr"><meta name="copyright" content="zxr"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="你好，这是一份关于PCA的介绍指南，希望看完全文后你能对PCA和他的小伙伴们有个全新的认识😃  still updating  前言 说起来写这篇文章原因，一方面是自己留个复习的记录，对PCA做个了结😋，之前总是处于复习完又忘掉，不是很有自己的体系，这次要建立一个全面而清晰的总结。另一方面是我自己本身就对PCA相关的理论有过思考和尝试，算是接触比较多。  事实上，对于某个专题写文章不是特别的容">
<meta property="og:type" content="article">
<meta property="og:title" content="你真的理解PCA么">
<meta property="og:url" content="https://xurui314.github.io/2022/10/16/%E4%BD%A0%E7%9C%9F%E7%9A%84%E7%90%86%E8%A7%A3PCA%E4%B9%88/index.html">
<meta property="og:site_name" content="XuRui-Blog">
<meta property="og:description" content="你好，这是一份关于PCA的介绍指南，希望看完全文后你能对PCA和他的小伙伴们有个全新的认识😃  still updating  前言 说起来写这篇文章原因，一方面是自己留个复习的记录，对PCA做个了结😋，之前总是处于复习完又忘掉，不是很有自己的体系，这次要建立一个全面而清晰的总结。另一方面是我自己本身就对PCA相关的理论有过思考和尝试，算是接触比较多。  事实上，对于某个专题写文章不是特别的容">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://s2.loli.net/2022/10/16/7S4fnGCBTi5jxtN.jpg">
<meta property="article:published_time" content="2022-10-16T15:27:37.000Z">
<meta property="article:modified_time" content="2022-10-25T03:19:15.524Z">
<meta property="article:author" content="zxr">
<meta property="article:tag" content="PCA">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2022/10/16/7S4fnGCBTi5jxtN.jpg"><link rel="shortcut icon" href="https://i.loli.net/2021/07/27/lSHRJbx7dYwTk8f.jpg"><link rel="canonical" href="https://xurui314.github.io/2022/10/16/%E4%BD%A0%E7%9C%9F%E7%9A%84%E7%90%86%E8%A7%A3PCA%E4%B9%88/"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '你真的理解PCA么',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-10-25 11:19:15'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    document.addEventListener('pjax:complete', detectApple)})(window)</script><link rel="stylesheet" href="/css/badge.css"><link rel="stylesheet" href="/css/modify.css"><link rel="stylesheet" href="/css/mouse.css"><link rel="stylesheet" href="/dist/APlayer.min.css"><link rel="stylesheet" href="/css/custom.css"><link rel="stylesheet" href="/css/bilibiliBanner.css" media="defer" onload="this.media='screen'"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper/swiper/swiper.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper/swiper/swiperstyle.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css">
<style>#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags:before {content:"\A";
  white-space: pre;}#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags > .article-meta__separator{display:none}</style>
<link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script async="" src="https://unpkg.zhimg.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://s2.loli.net/2021/12/08/yTYthVwXD4IPbJ9.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">60</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">30</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">14</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页🍭</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 档案🌊</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签📑</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类🌈</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 好康的✨</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener" href="https://ocw.mit.edu/"><i class="fa-fw fas fa-link"></i><span> 来学麻学</span></a></li><li><a class="site-page child" href="/bangumis/"><i class="fa-fw fas fa-video"></i><span> zxrの追番计划</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=RyOyXsKuUgI"><i class="fa-fw fas fa-heart"></i><span> zxr最爱滴up嘉倩</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://oskarstalberg.com/game/planet/planet.html"><span> Planet</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链💕</span></a></div><div class="menus_item"><a class="site-page" href="https://xurui314.github.io/aboutme/"><span> AboutMe🏂</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.foreverblog.cn/go.html"><span> 虫洞</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://s2.loli.net/2022/10/16/7S4fnGCBTi5jxtN.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">XuRui-Blog</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页🍭</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 档案🌊</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签📑</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类🌈</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 好康的✨</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener" href="https://ocw.mit.edu/"><i class="fa-fw fas fa-link"></i><span> 来学麻学</span></a></li><li><a class="site-page child" href="/bangumis/"><i class="fa-fw fas fa-video"></i><span> zxrの追番计划</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=RyOyXsKuUgI"><i class="fa-fw fas fa-heart"></i><span> zxr最爱滴up嘉倩</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://oskarstalberg.com/game/planet/planet.html"><span> Planet</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链💕</span></a></div><div class="menus_item"><a class="site-page" href="https://xurui314.github.io/aboutme/"><span> AboutMe🏂</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://www.foreverblog.cn/go.html"><span> 虫洞</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">你真的理解PCA么</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2022-10-16T15:27:37.000Z" title="Created 2022-10-16 23:27:37">2022-10-16</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2022-10-25T03:19:15.524Z" title="Updated 2022-10-25 11:19:15">2022-10-25</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Math/">Math</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">9.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>37min</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="你真的理解PCA么"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><div class="top-img" style="background-image: url('https://s2.loli.net/2022/10/16/7S4fnGCBTi5jxtN.jpg');"></div><article class="post-content" id="article-container"><p>你好，这是一份关于PCA的介绍指南，希望看完全文后你能对PCA和他的小伙伴们有个全新的认识😃</p>
<blockquote>
<p>still updating</p>
</blockquote>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><blockquote>
<p>说起来写这篇文章原因，一方面是自己留个复习的记录，对PCA做个了结😋，之前总是处于复习完又忘掉，不是很有自己的体系，这次要建立一个全面而清晰的总结。另一方面是我自己本身就对PCA相关的理论有过思考和尝试，算是接触比较多。</p>
</blockquote>
<p>事实上，对于某个专题写文章不是特别的容易，如何保证介绍的精准全面，又不被参考的资料影响，兼容自己的见解与特色，我想这是决定最后文章质量的关键要素吧 :)</p>
<p>zxr和PCA的渊源是在高中的时候，当时学完最小二乘以后我就在思考一个问题，如果把误差定义为点到直线a的距离，这样的话怎么求解？当时我自己确实也是试了，奈何数学功底太差，最后也就不了了之，但是这个问题确实是被我带到了大学，在MIT 18.06线代的课程中，我第一次知道了答案，也是这个时候，我接触到了PCA。</p>
<blockquote>
<p>其实是问过hjb的，他说求导就可以，但也没写给我看，懂不懂FDUer口算的含金量👍</p>
</blockquote>
<p><img src="https://s2.loli.net/2022/10/17/GhkmzqZ3rNyp5dR.png" style="zoom: 33%;"></p>
<p>在后续的ML学习中，我发现PCA这个方法在不同的板块都会有对应的新形式，甚至对于PCA及其变体的学习，就反映了机器学习的一般框架模式，颇有一种“见一叶而知深秋,窥一斑而见全豹”的感觉。</p>
<h2 id="Intuition"><a href="#Intuition" class="headerlink" title="Intuition"></a>Intuition</h2><p>对于现实中记录的数据，当我们想要从中发现新规律或者想要挖掘信息的时候，往往需要考虑数据的分布情况，因为实际上记录的维度可能存在冗余，事实上，很多情况下，数据都是分布在远小于原空间维度的流形上。举个栗子，观察下面的几张手写数字，不难看出对于这种图像的数据集，只有三个变化的自由度（degrees of freedom），对应于垂直平移、水平平移和旋转。于是，数据点会位于数据空间的⼀个⼦空间中，它的本质维度（intrinsic dimensionality）等于3。</p>
<p><img src="https://s2.loli.net/2022/10/16/XdTi9EJDSWhcH5G.png" alt="image-20221009114150411.png" style="zoom:80%;"></p>
<p>另⼀个例子来源于石油流数据集，其中只有两个自由度，对应于管道中石油的比例和水的比例（之后就可以确定天然气的比例）。虽然数据空间由12个度量组成，但是⼀组数据点会近似位于这个空间内的⼀个⼆维流形当中。在这种情况下，流形由几个不同的片段组成，对应于不同的流的形式，每⼀个片段都是⼀个（带有噪声的）连续⼆维流形。如果我们的目标是数据压缩，或者对概率密度建模，那么利用这个流形结构是很有用的。</p>
<p>在实际应用中，数据点不会被精确限制在⼀个光滑的低维流形中，我们可以将数据点关于流形的偏移看做噪声。我们的目标就是去寻找这样的一种数据”最佳“呈现方式，而这存在至少<strong>两个视角</strong>去分析：第一种是用原数据进行变换，得到对应假设下的最优表示，去除冗余和噪声。第二种则是从生成的角度，其中我们首先根据某种隐变量的概率分布在流形中选择⼀个点，然后通过添加噪声的方式生成观测数据点。噪声服从给定隐变量下的数据变量的某个条件概率分布。</p>
<p>但无论是基于哪种视角提出的方法，都是遵循一定假设，符合某种物理实际情况的，PCA也不例外。现在就让我们跳出Big Picture的感知，从现实遇到的一些特定问题来引出PCA的故事 :)</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p><img src="https://s2.loli.net/2022/10/16/M29pjCVdPTDimzI.png" alt="image-20221008165126460.png" style="zoom:80%;"></p>
<p>想象一下你回到了高中时代，这节物理实验课的主题是弹簧，你用了3台摄像机记录了弹簧伸缩的过程，所以你现在得到了3组数据，每组都记录了2维的坐标，所以整体上你拥有了维度是6的若干个采样点。</p>
<script type="math/tex; mode=display">
\vec{X}=\left[\begin{array}{c}
x_A \\
y_A \\
x_B \\
y_B \\
x_C \\
y_C
\end{array}\right]</script><p>现在你的老板要求你挖掘弹簧伸缩遵循的背后规律，<em>how do you get from this data set to a simple equation of x?</em></p>
<p>显然如果直接利用这个6维的数据来说明一个维度的变化规律，相对会很繁琐，所以是要对原数据去进行一些预处理的，我们需要考虑的因素有：数据的噪音和数据的冗余性。</p>
<p>因为理论上上弹簧的运动轨迹肯定是条直线，所以要对实际数据去噪，这个思路就是寻找方差最大的轴，方差最大对应的信息保留通常也是最大的。</p>
<p><img src="https://s2.loli.net/2022/10/16/jsbSnTJkxwNIUao.png" alt="image-20221009144351145.png" style="zoom:80%;"></p>
<p>其次是数据记录的冗余性，记录的3组数据实际上是强相关的，而且对于每组数据里面的坐标变量，也会存在一定的相关性，我们的目标就是去发现并消除这种冗余性，这里我们只去消除<strong>correlation</strong>（如果是<strong>independence</strong>的话就是ICA的思想了）。</p>
<p><img src="https://s2.loli.net/2022/10/16/JoD6qLc8UKjaYwM.png" alt="image-20221009144706680.png" style="zoom:80%;"></p>
<p>我们考虑的情况框定在线性假设下，这使得我们的目标变为：</p>
<blockquote>
<p> <em>Is there another basis, which is a linear combination of the original basis, that best re-expresses our data set?</em></p>
</blockquote>
<p>更好的数据表示应该是在原数据空间中选择一组更好的基，使得数据在这组基的表示下相关性最小，并且我们可以按照方差的大小来对基进行筛选，达到降噪的效果，得到更好的数据表示。</p>
<h2 id="Linear-Algebra"><a href="#Linear-Algebra" class="headerlink" title="Linear Algebra"></a>Linear Algebra</h2><blockquote>
<p>博主贴心地准备好了数学扶贫资料，这里是PCA所涉及到的线性代数内容，如果你已经了解，那就可以直接看下一章节~</p>
<p>向量 $\mathbf{x}$ 默认都是column vector，数据矩阵的维度是$(D,N)$的，也记作$(d,n)$。</p>
</blockquote>
<h3 id="协方差矩阵"><a href="#协方差矩阵" class="headerlink" title="协方差矩阵"></a>协方差矩阵</h3><p>数据矩阵表示如下：</p>
<script type="math/tex; mode=display">
X_{D \times N}=\left[\begin{array}{cccc}
x_{11} & x_{12} & \cdots & x_{1 n} \\
x_{21} & x_{22} & \cdots & x_{2 n} \\
\vdots & \vdots & \vdots & \vdots \\
x_{d 1} & x_{d 2} & \cdots & x_{d n}
\end{array}\right]=\left[\mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x}_n\right] =\left[\begin{array}{c}
\mathbf{u}_1 \\
\mathbf{u}_2 \\
\vdots
\\
\mathbf{u}_d
\end{array}\right]</script><p>$\mathbf{u}_i$和$\mathbf{u}_j$是两个随机变量，则它们的协方差定义为：</p>
<script type="math/tex; mode=display">
\operatorname{cov}(\mathbf{u}_i, \mathbf{u}_j)=E\left[\left(\mathbf{u}_i-\mu_i\right)\left(\mathbf{u}_j-\mu_j\right)\right]</script><p>这个定义和方差很像，只不过是描述的是变量之间的关系，而不是变量本身分布。</p>
<p>$\mathbf{u}_i$和$\mathbf{u}_j$的相关系数定义如下：</p>
<script type="math/tex; mode=display">
\rho_{\mathbf{u}_i, \mathbf{u}_j}=\frac{\sigma_{\mathbf{u}_i, \mathbf{u}_j}}{\sqrt{\sigma_{\mathbf{u}_i, \mathbf{u}_i} \sigma_{\mathbf{u}_j, \mathbf{u}_j}}}</script><p>协方差矩阵是针对维度间的，而不是样本间的，所以最后求出来的协方差矩阵维度是$(D,D)$的。</p>
<script type="math/tex; mode=display">
\begin{aligned}
&\hat{\Sigma}=\left[\begin{array}{cccc}
\operatorname{cov}\left(\mathbf{u}_1, \mathbf{u}_1\right) & \operatorname{cov}\left(\mathbf{u}_1, \mathbf{u}_2\right) & \cdots & \operatorname{cov}\left(\mathbf{u}_1, \mathbf{u}_d\right) \\
\operatorname{cov}\left(\mathbf{u}_2, \mathbf{u}_1\right) & \operatorname{cov}\left(\mathbf{u}_2, \mathbf{u}_2\right) & \cdots & \operatorname{cov}\left(\mathbf{u}_2, \mathbf{u}_d\right) \\
\vdots & \vdots & \vdots & \vdots \\
\operatorname{cov}\left(\mathbf{u}_d, \mathbf{u}_1\right) & \operatorname{cov}\left(\mathbf{u}_d, \mathbf{u}_2,\right) & \cdots & \operatorname{cov}\left(\mathbf{u}_d, \mathbf{u}_d\right)
\end{array}\right]\\
&=\frac{1}{n-1}\left[\begin{array}{cccc}
\sum_{i=1}^n\left(x_{1 i}-\bar{\mu}_1\right)\left(x_{1 i}-\bar{\mu}_1\right) & \sum_{i=1}^n\left(x_{1 i}-\bar{x}_1\right)\left(x_{2 i}-\bar{\mu}_2\right) & \ldots & \sum_{i=1}^n\left(x_{1 i}-\bar{x}_1\right)\left(x_{d i}-\bar{\mu}_d\right) \\
\sum_{i=1}^n\left(x_{2 i}-\bar{x}_2\right)\left(x_{1 i}-\bar{\mu}_1\right) & \sum_{i=1}^n\left(x_{2 i}-\bar{\mu}_2\right)\left(x_{2 i}-\bar{\mu}_2\right) & \ldots & \sum_{i=1}^n\left(x_{2 i}-\bar{\mu}_2\right)\left(x_{d i}-\bar{\mu}_d\right) \\
\vdots & \vdots & \vdots & \vdots \\
\sum_{i=1}^n\left(x_{d i}-\bar{x}_n\right)\left(x_{1 i}-\bar{\mu}_1\right) & \sum_{i=1}^n\left(x_{d i}-\bar{\mu}_n\right)\left(x_{2 i}-\bar{\mu}_2\right) & \ldots & \sum_{i=1}^n\left(x_{d i}-\bar{\mu}_n\right)\left(x_{d i}-\bar{\mu}_d\right)
\end{array}\right]\\
&=\frac{1}{n-1}\sum_{i=1}^n\left[\begin{array}{cccc}
\left(x_{1 i}-\bar{\mu}_1\right)\left(x_{1 i}-\bar{\mu}_1\right) & \left(x_{1 i}-\bar{x}_1\right)\left(x_{2 i}-\bar{\mu}_2\right) & \ldots & \left(x_{1 i}-\bar{x}_1\right)\left(x_{d i}-\bar{\mu}_d\right) \\
\left(x_{2 i}-\bar{x}_2\right)\left(x_{1 i}-\bar{\mu}_1\right) & \left(x_{2 i}-\bar{\mu}_2\right)\left(x_{2 i}-\bar{\mu}_2\right) & \ldots & \left(x_{2 i}-\bar{\mu}_2\right)\left(x_{d i}-\bar{\mu}_d\right) \\
\vdots & \vdots & \vdots & \vdots \\
\left(x_{d i}-\bar{x}_d\right)\left(x_{1 i}-\bar{\mu}_1\right) & \left(x_{d i}-\bar{\mu}_d\right)\left(x_{2 i}-\bar{\mu}_2\right) & \ldots & \left(x_{d i}-\bar{\mu}_n\right)\left(x_{d i}-\bar{\mu}_d\right)
\end{array}\right]\\
&=\frac{1}{n-1} \sum_{i=1}^n\left(\mathbf{x}_i-\bar{\mathbf{x}}\right)\left(\mathbf{x}_i-\bar{\mathbf{x}}\right)^T
\end{aligned}</script><blockquote>
<p>上面用$n-1$的原因是无偏估计，有兴趣可以自己找些资料看，这里推荐mit 6.041概率论。</p>
</blockquote>
<p>接下来介绍协方差矩阵和相关系数矩阵的关系：</p>
<p>$P:$ <code>correlation matrix</code>， $\Sigma:$ <code>covariance matrix</code>， $V:$ <code>diagonal variance matrix</code><br>上式中的矩阵 $V$ 是包含了每一个attribute的方差的对角矩阵。</p>
<script type="math/tex; mode=display">
V=\operatorname{diag}\left(\left[\sigma_{\mathbf{u}_1 \mathbf{u}_1}^2, \sigma_{\mathbf{u}_2 \mathbf{u}_2}^2, \ldots, \sigma_{\mathbf{u}_d \mathbf{u}_d}^2\right]\right)</script><p>那么，相关矩阵 $P$ 和协方差矩阵 $\Sigma$ 的关系如下:</p>
<script type="math/tex; mode=display">
\begin{aligned}
&V^{-1 / 2} \Sigma V^{-1 / 2}=P \\
&\Sigma=V^{1 / 2} P V^{1 / 2}
\end{aligned}</script><p>可以发现，消除变量间相关性其实也是等价于变量间协方差的值为0，所以这也是为什么后面我们就用协方差去分析。</p>
<h3 id="SVD分解"><a href="#SVD分解" class="headerlink" title="SVD分解"></a>SVD分解</h3><p>参考18.06的引入，对于一般的矩阵$\mathbf{A}_{n\times n}$，如果$\mathbf{A}$有$n$个线性无关的特征向量，那么可以得到特征值分解$\mathbf{A}=\mathbf{S^{-1} \Lambda S}$，而对于实对称矩阵，可以分解为正交矩阵和对角矩阵乘积的形式$\mathbf{A}=\mathbf{Q D Q}^T$，那么会不会存在一种对角正交的分解，对于一般的矩阵也是适用的呢？其实SVD就是反映了这样性质，下面我会逐步引入介绍 :)。</p>
<p>首先介绍一下比较一般的特征值分解：</p>
<p>给定矩阵 $\mathbf{A}_{n\times n}$的$n$ 个线性无关的特征向量，按列组成方阵，即:</p>
<script type="math/tex; mode=display">
\mathbf{S}:\left[\mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x}_n\right]</script><p>那么有</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbf{A S} &=\mathbf{A}\left[\mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x}_n\right] \\
&=\left[\lambda_1 \mathbf{x}_1, \lambda_2 \mathbf{x}_2, \ldots, \lambda_n \mathbf{x}_n\right] \\
&=\left[\mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x}_n\right] \mathbf{\Lambda} \\
&=\mathbf{S \Lambda} 
\end{aligned}</script><p>其中 $\Lambda$ 为特征值组成的对角矩阵，因为假设组成特征向量矩阵 $S$ 的 $n$ 个特征向量线性无关，所 以 $S$ 可逆，从上式中就可以推导出对角化以及特征值分解的公式:</p>
<script type="math/tex; mode=display">
\mathbf{S^{-1} A S}= \mathbf{\Lambda}</script><script type="math/tex; mode=display">
\mathbf{A}=\mathbf{S^{-1} \Lambda S}</script><p>接下来介绍一下对阵矩阵的特征值分解：</p>
<p>对于实对称矩阵 $\mathbf{A}$，存在实数$\lambda$ 和向量 $\mathbf{x}$ 使得</p>
<script type="math/tex; mode=display">
\mathbf{A x}=\lambda \mathbf{x}</script><p>$\lambda$是 $\mathbf{A}$ 的一个特征值，$\mathbf{x}$ 是对应的特征向量。如果 $\mathbf{A}$ 有两个不同的特征值 $\lambda_1$ 和$\lambda_2, \lambda_1 \neq \lambda_2$, 对应的特征向量分别是 $\mathbf{x}_1$ 和 $\mathbf{x}_2$ ,</p>
<script type="math/tex; mode=display">
\lambda_1 \mathbf{x}_1^T \mathbf{x}_2=\mathbf{x}_1^T \mathbf{A}^T \mathbf{x}_2=\mathbf{x}_1^T \mathbf{A} \mathbf{x}_2=\lambda_2 \mathbf{x}_1^T \mathbf{x}_2</script><p>由于$\lambda_1 \neq \lambda_2$, 我们可以得到 $\mathbf{x}_1^T \mathbf{x}_2=0$, i.e., $\mathbf{x}_1$ 和 $\mathbf{x}_2$ 是正交的。<br>对于$\mathbf{A} \in \mathcal{R}^{n \times n}$, 我们可以找到 $n$ 个特征值以及 $n$ 个特征向量，所以， $\mathbf{A}$ 可以被分解为</p>
<script type="math/tex; mode=display">
\mathbf{A}=\mathbf{Q D Q}^T</script><p>$\mathbf{Q}$ 是个正交矩阵 (i.e., $\mathbf{Q} \mathbf{Q}^T=\mathbf{I}$ ) ，$\mathbf{D}=\operatorname{diag}\left(\lambda_1, \lambda_2, \cdots, \lambda_n\right)$. 我们可以将 $\mathbf{Q}$ 表示成列向量形式：</p>
<script type="math/tex; mode=display">
\mathbf{Q}=\left(\mathbf{q}_1, \mathbf{q}_2, \cdots, \mathbf{q}_n\right)</script><p>那么：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbf{A}=\mathbf{Q D Q}^T &=\left(\mathbf{q}_1, \mathbf{q}_2, \cdots, \mathbf{q}_n\right)\left(\begin{array}{lll}
\lambda_1 & & \\
& \lambda_2 & \\
& & \\
& & \lambda_n
\end{array}\right)\left(\begin{array}{c}
\mathbf{q}_1^T \\
\mathbf{q}_2^T \\
\vdots \\
\mathbf{q}_n^T
\end{array}\right) \\
&=\left(\lambda_1 \mathbf{q}_1, \lambda_2 \mathbf{q}_2, \cdots, \lambda_n \mathbf{q}_n\right)\left(\begin{array}{c}
\mathbf{q}_1^T \\
\mathbf{q}_2^T \\
\vdots \\
\mathbf{q}_n^T
\end{array}\right) \\
&=\sum_{i=1}^n \lambda_i \mathbf{q}_i \mathbf{q}_i^T
\end{aligned}</script><p>这里$\left{\mathbf{q}<em>i\right}</em>{i=1}^n$ 是$\mathcal{R}^n$的一组正交基。</p>
<p>那么SVD其实就是这样的一种矩阵分解技术，对于任意的矩阵都可以找到对应的正交对角分解，具体的推导由来可以看：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/114550672">link</a>，由$\mathbf{A}\mathbf{A^T}$和$\mathbf{A^T A}$的特征值和特征向量引出的构造性证明。</p>
<p>根据矩阵乘法的几何意义，每个线性变换都可以分解为如下的旋转拉伸旋转操作，实际上可以变换到高维空间（$U$和$V$的维度可以是不同的，因此最后$U$的变换是可以到高维的subspace），这里只展示二维的过程。</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/bb/Singular-Value-Decomposition.svg/1920px-Singular-Value-Decomposition.svg.png" style="zoom: 25%;"></p>
<p>可以将矩阵 $\mathbf{A}$ 视为一种线性变换操作，将其行空间中的一个向量 $\mathbf{v} 1$,变为其列空间中的向量 $\mathbf{u}_1=\mathbf{A} \mathbf{v}_1$ 。奇异值分解就是要在行空间中寻找一组正交基，将其通过矩阵 $\mathbf{A}$ 线性变换生成列空间 中的一组正交基 $\mathbf{A} \mathbf{v}_i=\sigma_i \mathbf{u}_i$ 。</p>
<p><img src="https://pic1.zhimg.com/v2-2661c185a567047804e7831766cd79f0_r.jpg" style="zoom:80%;"></p>
<p>对于SVD中的那三个矩阵的求解，可以采用如下的方法：</p>
<script type="math/tex; mode=display">
\mathbf{A  A^T=U \Sigma V^T V \Sigma U^T=U \Sigma^2 U^T}</script><script type="math/tex; mode=display">
\mathbf{A^T  A=V \Sigma U^T U \Sigma V^T =V \Sigma^2 V^T}</script><p>其实就是求这俩对阵矩阵的特征向量和特征值就行了。</p>
<p>PCA和SVD都能用于求解Col X的basis，而且它们求解出来的basis可以‘认为’是同一个。两种方法的理论出发点不一样，PCA是从$XX^T$出发，考虑的是change of variable，目的是使的替换之后的variable是uncorrelated，即新的covariance matrix是对角阵。SVD是从$XX^T$出发，矩阵分解时得到Col X的一个basis，而该basis也可以验证得到是$XX^T$的eigenvectors set。两者都是建立在symmetric matrix对角化分解理论的基础上。SVD计算得到的basis更多是算一种副产品，主要目的是matrix decomposition，PCA的目的就是找basis。在计算时，PCA一般也是用SVD来计算。</p>
<h3 id="基变换"><a href="#基变换" class="headerlink" title="基变换"></a>基变换</h3><p>我推荐看3b1b的：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1ys411472E?p=13&amp;vd_source=78821760a099022a284c04eeb639e1ae">link</a></p>
<h2 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h2><h3 id="Intuition-1"><a href="#Intuition-1" class="headerlink" title="Intuition"></a>Intuition</h3><p>假设就是线性，具体来说就是我们想要找的基是由原基向量线性组合得到的，让我来复述一下我们的目标：</p>
<ol>
<li>最小化冗余，这里的冗余我们认为是变量间的协方差</li>
<li>最大化信息，这里的信息我们认为是变量的方差</li>
</ol>
<p>也就是说，对于在新基下的数据表示，我们希望协方差矩阵是对角化的，<code>off-diagnoal</code>的元素都是0，达到去相关(<code>decorrelated</code>)。实际上有很多方法（变换）可以使得变换后的数据去相关，而PCA选取新的基向量都是<code>orthonormal</code>的，这个原因其实是根据数学证明来的（后面会提到），暂且我们可以先认为是为了简单和方便起见，因为<code>orthonormal matrix</code>可以认为是旋转让新的坐标轴和最大方差的方向对齐，就像在<code>Introduction</code>章节里的那张图一样。</p>
<blockquote>
<p>这里说的最大方差是在当前假设下，<strong>投影</strong>得到的最大方差，没有任何假设下的最大方差的轴向可能不是正交基向量的方向，这个后面会说，也就是ICA。</p>
</blockquote>
<p>假设我们进行变换后得到的数据向量表示是$\mathbf{Y}$，设我们的基向量组成的<code>orthonormal matrix</code>为$\mathbf{S}$，那么就有$\mathbf{Y}=\mathbf{S^{-1} X}=\mathbf{S^T X}$，此时得到的$\mathbf{Y}$的协方差矩阵为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbf{C_Y} &=\mathbf{\frac{1}{n-1} Y Y^T} \\
&=\mathbf{\frac{1}{n-1} S^T X\left(S^T X\right)^T}\\
&=\mathbf{\frac{1}{n-1} S^T X X^T S} \\
\end{aligned}</script><p>而我们知道每个对称矩阵都有对应的正交对角分解，如果我们就取$\mathbf{X X^T}$ 分解得到的正交矩阵为 $\mathbf{S}$，那么则有：</p>
<script type="math/tex; mode=display">
\mathbf{\frac{1}{n-1} S^T S \Lambda S^T S=\frac{\Lambda}{n-1}}</script><p>嘿！这不就是我们想要的结果么，变换后的协方差矩阵已经变成了对角化😀，我们的目标达成了，这样的$\mathbf{S}$就是我们要找的新的基向量矩阵，而具体对于$\mathbf{S}$的计算可以通过协方差矩阵的SVD得到 :)</p>
<p>不妨让我们再挖掘更深一些，这样得到的数据表示能不能为我们提供一些分析处理数据的insight，比如<code>dimensional reduction</code>，以及对于选取的主成分（基向量）的解释，是否确实是满足了投影方差最大化，保留了最多的信息。</p>
<p>这就需要我们去明确定义一些优化问题，以降维为例，我们需要定义什么是一个好的结果：</p>
<blockquote>
<p>we must define what we consider optimal results. In the context of dimensional reduction, one measure of success is the degree to which a reduced representation can predict the original data. In statistical terms, we must define an error function (or loss function). It can be proved that under a common loss function, mean squared error (i.e. L2 norm), PCA provides the optimal reduced representation of the data. This means that selecting orthogonal directions for principal components is the best solution to predicting the original data.</p>
</blockquote>
<h3 id="最大方差"><a href="#最大方差" class="headerlink" title="最大方差"></a>最大方差</h3><p>考虑观测到的数据集${\mathbf x_n },n=1,…,N$，每条数据都是长度为$D$的向量，我们的目标是把数据投影到一个维度为$M &lt; D$的子空间，使得投影后的数据方差最大，假设$M$是已知的（后面会介绍可以自动确定$M$的方法，但是普通的PCA是需要提前确定，毕竟没有关于这方面的假设）。</p>
<p>首先让我们考虑投影到一维的子空间，也就是$M=1$，用长度为$D$的单位向量$\mathbf u_1$表示这个空间的方向，$\mathbf u_1^T \mathbf u_1 = 1$，因为我们只关心方向，而不在意$\mathbf u_1$的大小，这样的话每个数据$\mathbf x_n$就可以投影到这个子空间内，得到一个标量$\mathbf u_1^T \mathbf x_n$，原数据的均值投影后可以得到 $\mathbf{u}_1^{\mathrm{T}} \overline{\mathbf{x}}$。 $\overline{\mathbf{x}}$ 是样本的均值：</p>
<script type="math/tex; mode=display">
\overline{\mathbf{x}}=\frac{1}{N} \sum_{n=1}^N \mathbf{x}_n</script><p>投影后得到的方差可以定义为：</p>
<script type="math/tex; mode=display">
\frac{1}{N} \sum_{n=1}^N\left\{\mathbf{u}_1^{\mathrm{T}} \mathbf{x}_n-\mathbf{u}_1^{\mathrm{T}} \overline{\mathbf{x}}\right\}^2=\mathbf{u}_1^{\mathrm{T}} \mathbf{S} \mathbf{u}_1</script><p>$\mathbf{S}$ 是原数据的协方差矩阵：</p>
<script type="math/tex; mode=display">
\mathbf{S}=\frac{1}{N} \sum_{n=1}^N\left(\mathbf{x}_n-\overline{\mathbf{x}}\right)\left(\mathbf{x}_n-\overline{\mathbf{x}}\right)^{\mathrm{T}} .</script><p>我们现在想要改变$\mathbf{u}_1$，得到最大化投影方差 $\mathbf{u}_1^{\mathrm{T}} \mathbf{S} \mathbf{u}_1$ 。显然这需要是一个约束优化问题，为了防止$\left|\mathbf{u}_1\right| \rightarrow \infty$。而一个合适的约束条件，正是我们上面所定义的 $\mathbf{u}_1^{\mathrm{T}} \mathbf{u}_1=1$。为了强制这个约束条件生效，我们引入拉格朗日乘子 $\lambda_1$，讲约束优化问题转为非约束最大化的形式：</p>
<script type="math/tex; mode=display">
\mathbf{u}_1^{\mathrm{T}} \mathbf{S} \mathbf{u}_1+\lambda_1\left(1-\mathbf{u}_1^{\mathrm{T}} \mathbf{u}_1\right) .</script><p>取关于 $\mathbf{u}_1$ 的梯度为0，我们可以得到一个驻点满足：</p>
<script type="math/tex; mode=display">
\mathbf{S} \mathbf{u}_1=\lambda_1 \mathbf{u}_1</script><p>这说明 $\mathbf{u}_1$ 必须是 $\mathbf{S}$ 的特征向量，如果我们在左侧乘上 $\mathbf{u}_1^{\mathrm{T}}$ ，利用 $\mathbf{u}_1^{\mathrm{T}} \mathbf{u}_1=1$，可以看出方差可以表示为$\lambda_1$。</p>
<script type="math/tex; mode=display">
\mathbf{u}_1^{\mathrm{T}} \mathbf{S} \mathbf{u}_1=\lambda_1</script><p>所以为了让方差取到最大，我们可以设置$\mathbf{u}_1$为$\mathbf{S}$最大特征值对应的特征向量，这样就得到了我们想要的投影方向，也称为是主成分。</p>
<p>类似的，我们逐步得到$M$个主成分，这样就构建起了我们想要的子空间，以及数据的表示。</p>
<h3 id="最小重构误差"><a href="#最小重构误差" class="headerlink" title="最小重构误差"></a>最小重构误差</h3><p>现在我们来从最小投影误差的角度讨论，首先引入一个$D$维的完备正交标准化基向量集${ \mathbf{u}_i },i=1,…,D$，满足</p>
<script type="math/tex; mode=display">
\mathbf{u}_i^T\mathbf{u}_i=\delta_{i j}</script><p>因为基是完备的，所以数据点可以表示为基向量的线性组合：</p>
<script type="math/tex; mode=display">
\mathbf{x}_n=\sum_{i=1}^D \alpha_{n i} \mathbf{u}_i</script><p>系数 $\alpha<em>{n i}$ 对于不同的数据点是不同的。 这对应将原坐标系旋转到由 $\left{\mathbf{u}_i\right}$定义的新的坐标系下，原始的 $D$  个分量$\left{x</em>{n 1}, \ldots, x<em>{n D}\right}$ 被一个等价的集合取代 $\left{\alpha</em>{n 1}, \ldots, \alpha<em>{n D}\right}$. 和 $\mathbf{u}_j$ 取内积，利用正交标准化的性质，我们得到 $\alpha</em>{n j}=\mathbf{x}_n^{\mathrm{T}} \mathbf{u}_j$，不失一般性，我们写成如下形式：</p>
<script type="math/tex; mode=display">
\mathbf{x}_n=\sum_{i=1}^D\left(\mathbf{x}_n^{\mathrm{T}} \mathbf{u}_i\right) \mathbf{u}_i .</script><p>我们的目标是只用限定数量 $M &lt; D$ 个变量的一种表示方法近似这个数据点，对应于低维度子空间的一个投影。不失一般性， $M$,维线性子空间可以由前 $M$ 个基向量表示,，所以我们可以如下近似每个数据点 $\mathbf{x}_n$ ：</p>
<script type="math/tex; mode=display">
\widetilde{\mathbf{x}}_n=\sum_{i=1}^M z_{n i} \mathbf{u}_i+\sum_{i=M+1}^D b_i \mathbf{u}_i</script><p>${z<em>{ni}}$依赖于特定的数据点，${b_i}$对于所有数据点都是一样的（子空间），对于$\left{\mathbf{u}_i\right}$、${z</em>{ni}}$和${b_i}$我们可以任意选择，从而最小化由降维导致的失真。作为失真的度量，我们使⽤原始数据点与它的近似点$\widetilde{\mathbf{x}}_n$之间的平方距离，在数据集上取平均。因此我们的目标是最小化</p>
<script type="math/tex; mode=display">
J=\frac{1}{N} \sum_{n=1}^N\left\|\mathbf{x}_n-\widetilde{\mathbf{x}}_n\right\|^2 .</script><p>首先考虑关于 $\left{z<em>{n i}\right}$ 的最小化，带入 $\widetilde{\mathbf{x}}_n$，将关于 $z</em>{n j}$ 的导数设置为0, 利用正交标准化的条件，我们可以得到：</p>
<script type="math/tex; mode=display">
z_{n j}=\mathbf{x}_n^{\mathrm{T}} \mathbf{u}_j</script><p>其中 $j=1, \ldots, M$ 类似的，将 $J$ 关于 $b_i$ 的导数设置为0，再次利用正交标准化的条件，可以得到：</p>
<script type="math/tex; mode=display">
b_j=\overline{\mathbf{x}}^{\mathrm{T}} \mathbf{u}_j</script><p>其中$j=M+1, \ldots, D$。如果带入 $z_{n i}$ 和 $b_i$，利用上面$\mathbf{x}_n$ 和 $\widetilde{\mathbf{x}}_n$的展开式可以得到：</p>
<script type="math/tex; mode=display">
\mathbf{x}_n-\widetilde{\mathbf{x}}_n=\sum_{i=M+1}^D\left\{\left(\mathbf{x}_n-\overline{\mathbf{x}}\right)^{\mathrm{T}} \mathbf{u}_i\right\} \mathbf{u}_i</script><p>从中我们看到， 从 $\mathbf{x}_n$ 到 $\widetilde{\mathbf{x}}_n$ 的位移向量位于与主⼦空间垂直的空间中，因为它是 $\left{\mathbf{u}_i\right}$ 的线性组 合，其中 $i=M+1, \ldots, D$。这与预期相符，因为投影点 $\widetilde{\mathbf{x}}_n$ ⼀定位于主子空间内，但是我们可以在那个子空间内自由移动投影点，因此最小的误差由正交投影给出。</p>
<p>于是，我们得到了失真度量（其实也就是重构损失） $J$ 的表达式，它是⼀个只关于 $\left{\mathbf{u}_i\right}$ 的 函数，形式为：</p>
<script type="math/tex; mode=display">
J=\frac{1}{N} \sum_{n=1}^N \sum_{i=M+1}^D\left(\mathbf{x}_n^{\mathrm{T}} \mathbf{u}_i-\overline{\mathbf{x}}^{\mathrm{T}} \mathbf{u}_i\right)^2=\sum_{i=M+1}^D \mathbf{u}_i^{\mathrm{T}} \mathbf{S} \mathbf{u}_i .</script><p>接下来就剩下$J$关于${\mathbf u_i}$的最小化了，这显然是个约束优化问题，否则就会得到$\mathbf u_i = 0$这样不合理的解，约束来自之前正交标准化的定义。</p>
<p>推导出正式的结果之前，让我们用一个简单的例子来获取一些直观的感受，考虑$D=2$的数据空间，以及$M=1$的主成分子空间（<code>principal subspace</code>，也就是由主成分向量张成的空间），我们要选择一个方向$\mathbf u_2$来最小化$J = \mathbf{u_2^T S u_2}$，满足约束$\mathbf{u_2^T u_2} = 1$，用拉格朗日乘子法就可以得到如下的表达式：</p>
<script type="math/tex; mode=display">
\tilde{J}=\mathbf{u}_2^{\mathrm{T}} \mathbf{S u}_2+\lambda_2\left(1-\mathbf{u}_2^{\mathrm{T}} \mathbf{u}_2\right)</script><p>将关于 $\mathbf{u}_2$ 的导数设置为0，我们可以得到 $\mathbf{S u}_2=\lambda_2 \mathbf{u}_2$ ，所以 $\mathbf{u}_2$ 是 $\mathbf{S}$ 具有特征值 $\lambda_2$的特征向量。 因此任何特征向量都是上面重构误差的一个驻点。为了找到 $J$ 的最小值，我们将 $\mathbf{u}_2$ 回代到上面的重构误差中得到 $J=\lambda_2$。于是，我们通过选择$\mathbf{u}_2$ 成为两个特征值中较小的对应的特征向量，得到了 $J$ 的最小值。 因此，我们应该将主子空间与具有较大的特征值的特征向量对齐。这个结果与我们的直觉相符，即为了最小化平均平方投影距离，我们应该将主成分子空间选为穿过数据点的均值并且与最大方差的方向对齐。对于特征值相等的情形，任何主方向的选择都会得到同样的 $J$值。</p>
<p> 在一般的情况下，也就是对任意 $D$ 和 $M &lt;$ $D$ ，可以通过选择 $\left{\mathbf{u}_i\right}$ 为协方差矩阵的特征向量来最小化$J$：</p>
<script type="math/tex; mode=display">
\mathbf{S u}_i=\lambda_i \mathbf{u}_i</script><p>其中$i=1, \ldots, D$，特征向量 $\left{\mathbf{u}_i\right}$ 和往常一样选成正交标准化的。 重构误差的值相应可以表示为：</p>
<script type="math/tex; mode=display">
J=\sum_{i=M+1}^D \lambda_i</script><p>其实也就是正交于主成分子空间的特征向量的特征值之和，因此我们可以通过选择$D-M$个最小的特征值对应的特征向量来最小化$J$的值，因此组成主成分子空间的特征向量就是最大的$M$个特征值所对应的。</p>
<p>尽管我们考虑的是$M &lt; D$，事实上对于$M = D$也是成立的，只是没有降维，仅仅对原坐标系做了旋转，和主成分对齐。</p>
<h3 id="统一的视角"><a href="#统一的视角" class="headerlink" title="统一的视角"></a>统一的视角</h3><p><img src="https://s2.loli.net/2022/10/17/G6VoPL5BuXtF9rD.png" alt="image-20221017201837388.png" style="zoom: 67%;"></p>
<p>上面的两种定义和之前我们提出的<code>Intuition</code>的解法是一致的，这说明PCA是兼顾这三者的性质。那么不妨再深入的想一想，为什么最大方差和最小重构误差是等价的，从直观的感受和数学推导两个角度应该如何说明。</p>
<p>下面这张图很清晰的展示了方差和重构误差之间的联系，其实就是高维的勾股定理：</p>
<p><img src="http://alexhwilliams.info/itsneuronalblog/img/pca/projection_intuition.png" style="zoom: 50%;"></p>
<p>我们知道$(\mathbf u_j^T \mathbf x_i)\mathbf u_j$是$\mathbf x_i$在$\mathbf u_j$方向上的投影，因此$(\mathbf u_j^T \mathbf x_i)\mathbf u_j$、$\mathbf x_i$可以视为直角边和斜边，对应上面图里的$D_1$和$D_3$，而 $\mathbf x_i- (\mathbf u_j^T \mathbf x_i)\mathbf u_j$也就是对应$D_2$了。（origin其实就是中心点）</p>
<p>直观上的理解就是这样，对应的数学推导也自然能写出来（这里默认已经中心化了）：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbf{u}^* &=\underset{\mathbf{u}:\|\mathbf{u}\|^2=1}{\operatorname{argmin}} \frac{1}{N} \sum_{i=1}^N\left\|\mathbf{x}_i-\left(\mathbf{u}^T \mathbf{x}_i\right) \mathbf{u}\right\|^2 \\
&=\underset{\mathbf{u}:\|\mathbf{u}\|^2=1}{\operatorname{argmin}} \frac{1}{N} \sum_{i=1}^N\left\|\mathbf{x}_i\right\|^2-\left(\mathbf{u}^T \mathbf{x}_i\right)^2 \\
&=\underset{\mathbf{u}:\|\mathbf{u}\|^2=1}{\operatorname{argmax}} \frac{1}{N} \sum_{i=1}^N\left(\mathbf{u}^T \mathbf{x}_i\right)^2
\end{aligned}</script><blockquote>
<p>参考：<a target="_blank" rel="noopener" href="http://alexhwilliams.info/itsneuronalblog/2016/03/27/pca/">http://alexhwilliams.info/itsneuronalblog/2016/03/27/pca/</a></p>
</blockquote>
<h3 id="High-Dimensional-data"><a href="#High-Dimensional-data" class="headerlink" title="High Dimensional data"></a>High Dimensional data</h3><p>事实上，在许多实际应用中，我们只能获取数量有限，而维度又很高的数据，对于这种数据的分析往往是比较困难，因为很多机器学习的方法都是基于矩阵和逆运算的，而小批量高维的数据，它的一些统计量矩阵是不可逆的，此外运算的开销也和数据的维度有关，高维往往会来带不可实现的计算量。但对这种数据的分析又是极为重要的，我们就要去思考创造一些对应的策略。</p>
<p>不知道大家有没有过这种经历，对于$D&gt;N$的数据应用PCA，如果你想要降维到$M$维，$D&gt; M &gt; N$，用<code>sklearn</code>的话，实际上调库返回的降维后只有$N-1$维，因为在⼀个$D$维空间中，$N$个数据点（$N &lt; D）$定义的一个线性子空间，它的维度最多为$N − 1$，实际上，如果我们运行PCA，我们会发现⾄少$D − N + 1$个特征值为零，对应于沿着数据集 的方差为零的方向的特征向量。</p>
<p>如果将PCA应用于几百张图片的数据集，每张图片是对应的向量是几百万维，要知道通常对于寻找$D \times D$ 矩阵的特征向量的算法是$O(D^3)$的，实际中这显然不可接受。</p>
<p>针对这种情况的解决方法其实很简单，如果你有仔细了解过SVD相关的知识的话，不难想到我们的目的就是得到$Cov(\mathbf{X})$的特征向量，其中$\mathbf{X}$ 是 $D \times N$ 维中心化后矩阵，而$\mathbf{X}$ 可以看做是把行空间的基$\mathbf{v}_i$ 变换到列空间的基 $\mathbf{u}_i$，但同时进行了一定的长度拉伸，这里的$\mathbf{v}_i$对应的是${1\over N}\mathbf{X^T X}$的特征向量，而$\mathbf{u}_i$ 对应的是 ${1\over N}\mathbf{X X^T}$ 的特征向量。也就是可以写作$\mathbf{u}_i = c \mathbf{X} \mathbf{v}_i$，其中的$c$是对应的系数，根据SVD分解得到的$\mathbf{U \Sigma V^T}$中的$\mathbf{\Sigma}$就能确定$c$的值了，不难得到$c={1\over \left(N \lambda_i\right)^{1 / 2}} $，这样就把$ O(D^3) $ 的计算转换成了 $ O(N^3) $。</p>
<p>为了严谨性，我还是再推一遍：</p>
<script type="math/tex; mode=display">
\frac{1}{N} \mathbf{X} \mathbf{X}^{\mathrm{T}} \mathbf{u}_i=\lambda_i \mathbf{u}_i</script><p>两边乘上 $\mathbf{X}^{\mathrm{T}}$得到</p>
<script type="math/tex; mode=display">
\frac{1}{N} \mathbf{X^{\mathrm{T}} X}\left(\mathbf{X}^{\mathrm{T}} \mathbf{u}_i\right)=\lambda_i\left(\mathbf{X}^{\mathrm{T}} \mathbf{u}_i\right) .</script><p>我们定义$\mathbf{v}_i=\mathbf{X}^{\mathrm{T}} \mathbf{u}_i$ ，得到</p>
<script type="math/tex; mode=display">
\frac{1}{N} \mathbf{X^{\mathrm{T}} X} \mathbf{v}_i=\lambda_i \mathbf{v}_i</script><p>这是 $N \times N$ 矩阵 $N^{-1} \mathbf{X^{\mathrm{T}} X}$ 的一个特征向量的方程。我们看到这个矩阵与原始的协方差矩阵具有相同的 $N-1$ 个特征值，原始的协方差矩阵额外含有 $D-N+1$ 个为0的特征值。因此我们可以在低维空间中解决特征向量计算的问题，计算代价是 $O\left(N^3\right)$ 而不是 $O\left(D^3\right)$。为了确定特征向量，我们将上式两侧乘以 $\mathbf{X}$ 得到：</p>
<script type="math/tex; mode=display">
\left(\frac{1}{N} \mathbf{X}\mathbf{X}^{\mathrm{T}}\right)\left(\mathbf{X}\mathbf{v}_i\right)=\lambda_i\left(\mathbf{X} \mathbf{v}_i\right)</script><p>我们可以从中看出 $\left(\mathbf{X} \mathbf{v}_i\right)$ 是 $\mathbf{S}$ 的一个特征值为 $\lambda_i$ 的特征向量。但是注意，这些特征向量长度不一定是1，为了确定合适的归一化，我们需要一个常数来对 $\mathbf{u}_i \propto \mathbf{X} \mathbf{v}_i$ 重新规范，使得 $\left|\mathbf{u}_i\right|=1$, 假设 $\mathbf{v}_i$ 长度已经归一化，那么我们有：</p>
<script type="math/tex; mode=display">
\mathbf{u}_i=\frac{1}{\left(N \lambda_i\right)^{1 / 2}} \mathbf{X}\mathbf{v}_i</script><p>总结⼀下，为了应⽤这种⽅法，我们⾸先计算$\mathbf{X^{\mathrm{T}} X}$ ，然后找到它的特征向量和特征值，之后利用上面的公式计算原始数据空间的特征向量。</p>
<h3 id="Applications-of-PCA"><a href="#Applications-of-PCA" class="headerlink" title="Applications of PCA"></a>Applications of PCA</h3><h4 id="Whitening"><a href="#Whitening" class="headerlink" title="Whitening"></a>Whitening</h4><p>白化其实就是定义了一个满足如下性质的变换：</p>
<ul>
<li>消除了特征之间的相关性</li>
<li>所有特征的方差都为 1</li>
</ul>
<p>是不是感觉很熟悉，只要把PCA的步骤稍作改动就可以了，首先我们定义：</p>
<script type="math/tex; mode=display">
\mathbf{SU=UL}</script><p>$\mathbf{L}$ 是 $D \times D$ 对角矩阵，对角元素是 $\lambda_i$ ，其实就是 $\mathbf{U}$ is a $D \times D$ 主成分正交矩阵 $\mathbf{u}_i$。 然后我们对每个数据点 $\mathbf{x}_n$ 定义一个变换：</p>
<script type="math/tex; mode=display">
\mathbf{y}_n=\mathbf{L}^{-1 / 2} \mathbf{U}^{\mathrm{T}}\left(\mathbf{x}_n-\overline{\mathbf{x}}\right)</script><p>很显然 $\mathbf y_n$ 的协方差矩阵是单位阵：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\frac{1}{N} \sum_{n=1}^N \mathbf{y}_n \mathbf{y}_n^{\mathrm{T}} &=\frac{1}{N} \sum_{n=1}^N \mathbf{L}^{-1 / 2} \mathbf{U}^{\mathrm{T}}\left(\mathbf{x}_n-\overline{\mathbf{x}}\right)\left(\mathbf{x}_n-\overline{\mathbf{x}}\right)^{\mathrm{T}} \mathbf{U L}^{-1 / 2} \\
&=\mathbf{L}^{-1 / 2} \mathbf{U}^{\mathrm{T}} \mathbf{S} \mathbf{U L}^{-1 / 2}=\mathbf{L}^{-1 / 2} \mathbf{L L}^{-1 / 2}=\mathbf{I}
\end{aligned}</script><p>这样的 $\mathbf y_n$就是白化后的数据了。</p>
<h4 id="Mahalanobis-Distance"><a href="#Mahalanobis-Distance" class="headerlink" title="Mahalanobis Distance"></a>Mahalanobis Distance</h4><p><img src="https://pic2.zhimg.com/v2-e2661f3587e74803540afceffc900887_r.jpg?source=1940ef5c" style="zoom:80%;"></p>
<p> 马氏距离定义为：</p>
<script type="math/tex; mode=display">
d_M(x, y)=\sqrt{(x-y) \Sigma^{-1}(x-y)}</script><p>其实可以看作是，$A = L^{-1/2} U^T$，和白化如出一辙：</p>
<script type="math/tex; mode=display">
d_M(x, y)=\sqrt{(x-y) A A^T(x-y)}=\left|A^T x-A^T y\right|</script><p>因此马氏距离可以理解为白化后数据的欧几里得距离。</p>
<h3 id="Limitations"><a href="#Limitations" class="headerlink" title="Limitations"></a>Limitations</h3><p>然而当我们尝试着用PCA解决下面的两种问题时，似乎PCA看起来失效了，也就是并不符合我们想要的预期，这是由于什么原因呢？（注意B图实际上主成分方向有点问题，应该是两条数据线之间的）</p>
<p><img src="https://s2.loli.net/2022/10/16/hKFrZdVm7Q4wODM.png" alt="image-20221007224537337.png" style="zoom: 50%;"></p>
<p>因为我们之前的假设只是去相关，而变量间更高层次的依赖关系并没有完全去除，因此有时候，只是去除相关关系对于揭示数据的结构是不够的，这就启发我们去寻找解决新问题的方法。</p>
<p>去除更高层次依赖关系的方法有很多，如果对问题有着先验的知识，我们可以尝试<code>kernel method</code>，例如上图中的A，可以用极坐标表示数据。也可以直接去除变量间的<code>dependence</code>，这就是ICA的想法，可以用来解决上图中B的问题。</p>
<p>接下来就让我们介绍PCA的这种变体，也就是<code>Kernel PCA</code>。</p>
<h2 id="Kernel-Tutorial"><a href="#Kernel-Tutorial" class="headerlink" title="Kernel Tutorial"></a>Kernel Tutorial</h2><h2 id="Kernel-PCA"><a href="#Kernel-PCA" class="headerlink" title="Kernel PCA"></a>Kernel PCA</h2><p><img src="https://pic3.zhimg.com/v2-4f5ff09f278491a4ff6d397c3bdd493e_720w.jpg?source=172ae18b" style="zoom:80%;"></p>
<h2 id="PPCA"><a href="#PPCA" class="headerlink" title="PPCA"></a>PPCA</h2><h3 id="从最小二乘谈起"><a href="#从最小二乘谈起" class="headerlink" title="从最小二乘谈起"></a>从最小二乘谈起</h3><p>我们知道二次损失函数和高斯先验误差+MLE是等效的，具体的原因可以看：<a target="_blank" rel="noopener" href="https://stats.stackexchange.com/questions/288451/why-is-mean-squared-error-the-cross-entropy-between-the-empirical-distribution-a">link</a> and <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/342171447">link</a>、<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/37031188/answer/1151452917">link</a>。</p>
<p>但是最小二乘只是针对于<code>scale</code>的，而<code>vector</code>的情况会是怎么样的呢？不妨让我们将以上的思路进行推广，到了向量的多维空间，二次损失函数和高斯误差的联系在哪里，换句话说，PCA会不会可以从这个思路引出一个概率形式？</p>
<p><img src="https://s2.loli.net/2022/10/23/7AtWJmkcUavYGO1.png" alt="image-20221023161451243.png" style="zoom:33%;"></p>
<p>这样很自然地就从生成的角度去思考，更具体一些，也就是<code>continuous latent variable model</code>，隐变量的概念极大丰富了模型的可解释性和表达能力，这里默认你已经对<code>GMM</code>高斯混合模型有了解，你应该知道<code>GMM</code>是一种<code>discrete latene variable model</code>。所谓的<code>continuous</code>可以理解为隐变量是有一种连续的分布（默认你也理解了概率论的一些概念），那么有了这个idea，就让我们一步一步去尝试吧 :)</p>
<p>我们先引入隐变量 $\mathbf{z}$ ，对应的应该是主成分子空间。接下来定义隐变量上的高斯先验分布 $p(\mathbf{z})$ ，以及观测变量 $\mathbf{x}$ 在given $\mathbf{z}$ 下的高斯条件分布 $p(\mathbf{x} \mid \mathbf{z})$ 。 $\mathbf{z}$ 的先验高斯分布定义如下：</p>
<script type="math/tex; mode=display">
p(\mathbf{z})=\mathcal{N}(\mathbf{z} \mid \mathbf{0}, \mathbf{I})</script><p>类似的，我们定义条件分布：</p>
<script type="math/tex; mode=display">
p(\mathbf{x} \mid \mathbf{z})=\mathcal{N}\left(\mathbf{x} \mid \mathbf{W} \mathbf{z}+\boldsymbol{\mu}, \sigma^2 \mathbf{I}\right)</script><p> $\mathbf{x}$ 的中心是 $\mathbf{z}$ 的一个线性函数，由  $D \times M$ 矩阵 $\mathbf{W}$ 和 $D$  维向量 $\boldsymbol{\mu}$ 给出。 注意，可以关于 $\mathbf{x}$ 的各个元素进⾏分解，换句话说，这是朴素贝叶斯模型的⼀个例子。 $\mathbf{W}$ 的列在数据空间中生成了线性的主成分子空间， 这个模型中的另一个参数 $\sigma^2$ 控制着条件概率分布的方差注意，我们可以不失⼀般性地假设潜在变量分布 $p(\mathbf{z})$ 服从一个零均值单位协方差的高斯分布，因为更⼀般的高斯分布会产生⼀个等价的概率模型。</p>
<p>我们可以从生成式的观点看待概率PCA模型，其中观测值的⼀个采样值通过下面的方式获得：首先为潜在变量选择⼀个值，然后以这个潜在变量的值为条件，对观测变量采样。具体来说，$D$ 维观测变量 $\mathbf x$ 由 $M$ 维潜在变量 $z$ 的⼀个线性变换附加⼀个高斯“噪声”定义，即</p>
<script type="math/tex; mode=display">
\mathbf{x = Wz + u + \epsilon}</script><p>下面的图可以帮助你理解，如何把概率生成的过程，看作是一种transformation：</p>
<p><img src="https://miro.medium.com/max/1400/1*ILLVmIMVTiWTiBZcmeruDQ.png" style="zoom:80%;"></p>
<p>具体的数学推导我不会写了，包括PPCA的极大似然估计，EM算法等，具体可以看<code>PRML</code>去了解 :)</p>
<h2 id="Factor-Analysis"><a href="#Factor-Analysis" class="headerlink" title="Factor Analysis"></a>Factor Analysis</h2><p>从高斯分布拟合引入问题</p>
<p>GIVEN : an $N$-by- $D$ matrix $\mathbf{X}$<br>Assume the rows $\left{\mathbf{x}<em>i^T\right}</em>{i=1}^N$ are IID samples from an unknown $p(\mathbf{x})$.<br>GOAL : Estimate $p(\mathbf{x})$<br>Factor Analysis<br>Assume :</p>
<script type="math/tex; mode=display">
p\left(\mathbf{z}_i\right)=\mathcal{N}\left(\mathbf{z}_i \mid \mathbf{0}, \mathbf{I}\right) \quad p\left(\mathbf{x}_i \mid \mathbf{z}_i, \mathbf{W}, \boldsymbol{\mu}, \boldsymbol{\Psi}\right)=\mathcal{N}\left(\mathbf{x}_i \mid \mathbf{W} \mathbf{z}_i+\boldsymbol{\mu}, \boldsymbol{\Psi}\right)</script><p>where $\mathbf{z}<em>i$ is a length- $L$ vector, $\mathbf{W}$ is a $D$-by- $L$ matrix, $\boldsymbol{\mu}$ is length- $D$ and $\Psi$ is a diagonal matrix with $\left{\psi_d\right}</em>{d=1}^D$ along the diagonal.<br>If the z’s are ‘averaged out’ : $\quad p(\mathbf{x} \mid \mathbf{W}, \boldsymbol{\mu}, \Psi)=\mathcal{N}(\mathbf{x} \mid \boldsymbol{\mu}, \underbrace{\mathbf{W W}^T+\Psi}_{\text {Call this } \mathbf{C}})$</p>
<h2 id="ICA"><a href="#ICA" class="headerlink" title="ICA"></a>ICA</h2><h2 id="PGM"><a href="#PGM" class="headerlink" title="PGM"></a>PGM</h2><p>引入PGM</p>
<h2 id="Auto-Encoder"><a href="#Auto-Encoder" class="headerlink" title="Auto Encoder"></a>Auto Encoder</h2><p>AE</p>
<p>引入VAE，为GAN和Stable Diffusion model铺路。</p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">zxr</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://xurui314.github.io/2022/10/16/%E4%BD%A0%E7%9C%9F%E7%9A%84%E7%90%86%E8%A7%A3PCA%E4%B9%88/">https://xurui314.github.io/2022/10/16/%E4%BD%A0%E7%9C%9F%E7%9A%84%E7%90%86%E8%A7%A3PCA%E4%B9%88/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/PCA/">PCA</a></div><div class="post_share"><div class="social-share" data-image="https://s2.loli.net/2022/10/16/7S4fnGCBTi5jxtN.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer=""></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/10/23/Leetcode-%E8%AE%B0%E5%BD%95/"><img class="prev-cover" src="https://s2.loli.net/2022/10/23/sU6c8VavPgZLoYk.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">Leetcode 记录</div></div></a></div><div class="next-post pull-right"><a href="/2022/10/13/Tree-based-AI/"><img class="next-cover" src="https://s2.loli.net/2022/10/13/Z8Llvman5s1iGXz.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Tree based AI</div></div></a></div></nav><hr><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div><div id="comment-switch"><span class="first-comment">Valine</span><span class="switch-btn"></span><span class="second-comment">Disqus</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div><div><div id="disqus_thread"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://s2.loli.net/2021/12/08/yTYthVwXD4IPbJ9.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"></div><div class="author-info__name">zxr</div><div class="author-info__description">Think and Do like an MIT student</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">60</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">30</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">14</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/XuRui314"><i class="fab fa-github"></i><span>This is zxr!🚀</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/XuRui314" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://mail.qq.com/" target="_blank" title="Email-1977289398@qq.com"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">zxr的生活，math，编程记录,<div class="twopeople"><div class="container" style="height:200px;"><canvas class="illo" width="800" height="800" style="max-width: 200px; max-height: 200px; touch-action: none; width: 640px; height: 640px;"></canvas></div><script src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/js/twopeople1.js"></script><script src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/js/zdog.dist.js"></script><script id="rendered-js" src="https://cdn.jsdelivr.net/gh/Justlovesmile/CDN/js/twopeople.js"></script><style>.twopeople{margin: 0;align-items: center;justify-content: center;text-align: center;}canvas{display: block;margin: 0 auto;cursor: move;}</style></div><div class="twopeople"></div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Intuition"><span class="toc-number">2.</span> <span class="toc-text">Intuition</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduction"><span class="toc-number">3.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Linear-Algebra"><span class="toc-number">4.</span> <span class="toc-text">Linear Algebra</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5"><span class="toc-number">4.1.</span> <span class="toc-text">协方差矩阵</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SVD%E5%88%86%E8%A7%A3"><span class="toc-number">4.2.</span> <span class="toc-text">SVD分解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E5%8F%98%E6%8D%A2"><span class="toc-number">4.3.</span> <span class="toc-text">基变换</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PCA"><span class="toc-number">5.</span> <span class="toc-text">PCA</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Intuition-1"><span class="toc-number">5.1.</span> <span class="toc-text">Intuition</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%80%E5%A4%A7%E6%96%B9%E5%B7%AE"><span class="toc-number">5.2.</span> <span class="toc-text">最大方差</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%80%E5%B0%8F%E9%87%8D%E6%9E%84%E8%AF%AF%E5%B7%AE"><span class="toc-number">5.3.</span> <span class="toc-text">最小重构误差</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%9F%E4%B8%80%E7%9A%84%E8%A7%86%E8%A7%92"><span class="toc-number">5.4.</span> <span class="toc-text">统一的视角</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#High-Dimensional-data"><span class="toc-number">5.5.</span> <span class="toc-text">High Dimensional data</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Applications-of-PCA"><span class="toc-number">5.6.</span> <span class="toc-text">Applications of PCA</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Whitening"><span class="toc-number">5.6.1.</span> <span class="toc-text">Whitening</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Mahalanobis-Distance"><span class="toc-number">5.6.2.</span> <span class="toc-text">Mahalanobis Distance</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Limitations"><span class="toc-number">5.7.</span> <span class="toc-text">Limitations</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kernel-Tutorial"><span class="toc-number">6.</span> <span class="toc-text">Kernel Tutorial</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kernel-PCA"><span class="toc-number">7.</span> <span class="toc-text">Kernel PCA</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PPCA"><span class="toc-number">8.</span> <span class="toc-text">PPCA</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%8E%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E8%B0%88%E8%B5%B7"><span class="toc-number">8.1.</span> <span class="toc-text">从最小二乘谈起</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Factor-Analysis"><span class="toc-number">9.</span> <span class="toc-text">Factor Analysis</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ICA"><span class="toc-number">10.</span> <span class="toc-text">ICA</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PGM"><span class="toc-number">11.</span> <span class="toc-text">PGM</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Auto-Encoder"><span class="toc-number">12.</span> <span class="toc-text">Auto Encoder</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%8E%E8%AE%B0"><span class="toc-number">13.</span> <span class="toc-text">后记</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/10/25/EM-VI/" title="EM &amp; VI"><img src="https://sm.ms/image/UFRaWQTP7d6m1oC" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="EM &amp; VI"></a><div class="content"><a class="title" href="/2022/10/25/EM-VI/" title="EM &amp; VI">EM &amp; VI</a><time datetime="2022-10-25T02:15:20.000Z" title="Created 2022-10-25 10:15:20">2022-10-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/10/23/Kaggle-NLP/" title="Kaggle NLP"><img src="https://s2.loli.net/2022/10/23/2Kh1nNloGqswE76.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Kaggle NLP"></a><div class="content"><a class="title" href="/2022/10/23/Kaggle-NLP/" title="Kaggle NLP">Kaggle NLP</a><time datetime="2022-10-23T02:54:32.000Z" title="Created 2022-10-23 10:54:32">2022-10-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/10/23/PGM/" title="PGM"><img src="https://s2.loli.net/2022/10/23/r8QYdKZmW49PXTh.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="PGM"></a><div class="content"><a class="title" href="/2022/10/23/PGM/" title="PGM">PGM</a><time datetime="2022-10-23T02:54:05.000Z" title="Created 2022-10-23 10:54:05">2022-10-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/10/23/Leetcode-%E8%AE%B0%E5%BD%95/" title="Leetcode 记录"><img src="https://s2.loli.net/2022/10/23/sU6c8VavPgZLoYk.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Leetcode 记录"></a><div class="content"><a class="title" href="/2022/10/23/Leetcode-%E8%AE%B0%E5%BD%95/" title="Leetcode 记录">Leetcode 记录</a><time datetime="2022-10-23T02:53:31.000Z" title="Created 2022-10-23 10:53:31">2022-10-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/10/16/%E4%BD%A0%E7%9C%9F%E7%9A%84%E7%90%86%E8%A7%A3PCA%E4%B9%88/" title="你真的理解PCA么"><img src="https://s2.loli.net/2022/10/16/7S4fnGCBTi5jxtN.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="你真的理解PCA么"></a><div class="content"><a class="title" href="/2022/10/16/%E4%BD%A0%E7%9C%9F%E7%9A%84%E7%90%86%E8%A7%A3PCA%E4%B9%88/" title="你真的理解PCA么">你真的理解PCA么</a><time datetime="2022-10-16T15:27:37.000Z" title="Created 2022-10-16 23:27:37">2022-10-16</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">©2020 - 2022 By zxr</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="github-badge"><a style="color: #fff" rel="license" href="https://hexo.io/" target="_blank" title="由 Hexo 强力驱动"><span class="badge-subject">Powered</span><span class="badge-value bg-blue">Hexo</span></a><a style="color: #fff" rel="license" href="https://gitee.com/" target="_blank" title="静态网页托管于 GitHub Pages 和 Coding Pages 和 Gitee Pages"><span class="badge-subject">Hosted</span><span class="badge-value bg-brightgreen">GitHub &amp; Coding &amp; Gitee</span></a><a style="color: #fff" rel="license" href="https://www.jsdelivr.com/" target="_blank" title="jsDelivr 提供 CDN 加速服务"><span class="badge-subject">CDN</span><span class="badge-value bg-orange">jsDelivr</span></a><a style="color: #fff" rel="license" href="https://jerryc.me" target="_blank" title="站点使用 Butterfly主题"><span class="badge-subject">Theme</span><span class="badge-value bg-blue">Butterfly</span></a><a style="color: #fff" rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" title="本站点采用知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议进行许可"><span class="badge-subject"><i class="fa fa-copyright"></i></span><span class="badge-value bg-lightgrey">BY-NC-SA 4.0  </span></a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="Increase font size"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="Decrease font size"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = '[object Object]'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: '',
      appKey: '',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script>function loadDisqus () {
  var disqus_config = function () {
    this.page.url = 'https://xurui314.github.io/2022/10/16/%E4%BD%A0%E7%9C%9F%E7%9A%84%E7%90%86%E8%A7%A3PCA%E4%B9%88/'
    this.page.identifier = '2022/10/16/你真的理解PCA么/'
    this.page.title = '你真的理解PCA么'
  };

  window.disqusReset = () => {
    DISQUS.reset({
      reload: true,
      config: disqus_config
    })
  }

  if (window.DISQUS) disqusReset()
  else {
    (function() { 
      var d = document, s = d.createElement('script');
      s.src = 'https://.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  }
}

if ('Valine' === 'Disqus' || !false) {
  if (false) btf.loadComment(document.getElementById('disqus_thread'), loadDisqus)
  else loadDisqus()
} else {
  function loadOtherComment () {
    loadDisqus()
  }
}
</script></div><script src="https://cdn.jsdelivr.net/gh/XuRui314/live2d-widget@1.0.1/autoload.js"></script><script src="/js/title.js"></script><script src="/dist/nochocolate.js"></script><div id="aplayer"></div><script type="text/javascript" src="/dist/APlayer.min.js"></script><script type="text/javascript" src="/dist/music.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/gh/metowolf/MetingJS@1.2/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = [
  'title',
  '#config-diff',
  '#body-wrap',
  '#rightside-config-hide',
  '#rightside-config-show',
  '.js-pjax'
]

if (false) {
  pjaxSelectors.unshift('meta[property="og:image"]', 'meta[property="og:title"]', 'meta[property="og:url"]')
}

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.removeEventListener('scroll', window.tocScrollFn)
  window.removeEventListener('scroll', scrollCollect)

  typeof preloader === 'object' && preloader.initLoading()
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // Analytics
  if (false) {
    MtaH5.pgv()
  }

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async="" data-pjax="" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax="">if(document.getElementById('recent-posts') && (location.pathname ==='all'|| 'all' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/Math/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 zxrの数学世界 (13)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/算法学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 zxrの算法学习 (6)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/生活趣闻/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱‍👓 zxrの生活趣闻 (4)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/编程实例/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">👩‍💻 zxrの编程学习 (4)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/生活感悟/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🚴‍♂ zxrの生活感悟 (11)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://XuRui314.github.io/categories/Hexo/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">💌 zxrのBlog记录 (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="https://XuRui314.github.io/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style> <script data-pjax="">if(document.getElementById('recent-posts') && location.pathname =='/'){
    
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/09/17/9H5WSbTrVejOdkz.jpg" alt="https://i.loli.net/2021/09/17/9H5WSbTrVejOdkz.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-09-17</span><a class="blog-slider__title" href="2021/09/17/概率和测度/">概率和测度(ZJU大佬)</a><div class="blog-slider__text">来看看ZJU计科大佬解释概率和测度🥙</div><a class="blog-slider__button" href="2021/09/17/概率和测度/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/25/bPy5m3j9QAilwr2.jpg" alt="https://i.loli.net/2021/08/25/bPy5m3j9QAilwr2.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-08-26</span><a class="blog-slider__title" href="2021/08/26/算法题目练习/">AcWing-Oj-刷题学习记录(基础算法)</a><div class="blog-slider__text">来看算法蒟蒻的丢人日常啊👩‍🦽</div><a class="blog-slider__button" href="2021/08/26/算法题目练习/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/15/NYcSXrECnvzOiLP.jpg" alt="https://i.loli.net/2021/08/15/NYcSXrECnvzOiLP.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-08-15</span><a class="blog-slider__title" href="2021/08/15/两层神经网络识别手写数字/">两层神经网络识别手写数字</a><div class="blog-slider__text">识别手写数字最简单的实现🧦</div><a class="blog-slider__button" href="2021/08/15/两层神经网络识别手写数字/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/15/F8aP7R36IidpCt5.jpg" alt="https://i.loli.net/2021/08/15/F8aP7R36IidpCt5.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-08-14</span><a class="blog-slider__title" href="2021/08/14/神经网络搭建准备内容/">神经网络搭建准备内容</a><div class="blog-slider__text">如何识别手写🔢，zxr带你一步一步实现🎼</div><a class="blog-slider__button" href="2021/08/14/神经网络搭建准备内容/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/12/SJs3MgYC7x8IU26.jpg" alt="https://i.loli.net/2021/08/12/SJs3MgYC7x8IU26.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-08-12</span><a class="blog-slider__title" href="2021/08/12/xuperchain-solidity/">xuperchain&solidity</a><div class="blog-slider__text">区块链不止是挖币，还有v神和solidity🎈</div><a class="blog-slider__button" href="2021/08/12/xuperchain-solidity/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/07/27/6fy8mTCbAOWPkrq.png" alt="https://i.loli.net/2021/07/27/6fy8mTCbAOWPkrq.png"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-07-26</span><a class="blog-slider__title" href="2021/07/26/FFT/">FFT的详解</a><div class="blog-slider__text">这么好看的FFT，信号狗都馋哭了💦</div><a class="blog-slider__button" href="2021/07/26/FFT/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/09/zdt4YKoehQvR96S.jpg" alt="https://i.loli.net/2021/08/09/zdt4YKoehQvR96S.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-08-09</span><a class="blog-slider__title" href="2021/08/09/炒鸡好理解的测度论/">炒鸡好理解的测度论</a><div class="blog-slider__text">三段字，让你读懂测度论</div><a class="blog-slider__button" href="2021/08/09/炒鸡好理解的测度论/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/08/12/wF7TJlqxOLEWGQk.png" alt="https://i.loli.net/2021/08/12/wF7TJlqxOLEWGQk.png"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-07-27</span><a class="blog-slider__title" href="2021/07/27/FT/">傅里叶学习资料</a><div class="blog-slider__text">简单好学的傅里叶学习资料</div><a class="blog-slider__button" href="2021/07/27/FT/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src="https://i.loli.net/2021/07/27/f7jO8hlNpzWVXSP.jpg" alt="https://i.loli.net/2021/07/27/f7jO8hlNpzWVXSP.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-07-26</span><a class="blog-slider__title" href="2021/07/26/hello-world/">大鸟转转转酒吧内部绝密档案</a><div class="blog-slider__text">不要点进来QAQ！</div><a class="blog-slider__button" href="2021/07/26/hello-world/">详情</a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载swiper')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script>
<script data-pjax="" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper/swiper/swiper.min.js"></script>
<script data-pjax="" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper@0.18/swiper/swiperindex.js"></script>
<style></style><script data-pjax="">function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax="" src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script>
  <script data-pjax="" src="https://cdn.jsdelivr.net/gh/Zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script>
  <script data-pjax="">
        function GithubCalendarConfig(){
            var git_githubapiurl ="https://python-github-calendar-api.vercel.app/api?XuRui314";
            var git_color =['#ebedf0', '#fdcdec', '#fc9bd9', '#fa6ac5', '#f838b2', '#f5089f', '#c4067e', '#92055e', '#540336', '#48022f', '#30021f'];
            var git_user ="XuRui314";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="height:100%;display: flex;align-items: center;justify-content: center;"><svg style="height:50px" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>';
            if(parent_div_git && location.pathname =='/'){
                console.log('已挂载github calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // 有报错，但不影响使用(支持pjax跳转)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:248px}@media screen and (max-width:650px) {#github_container{background-image:;min-height:0px}}</style>
    <style></style><script async="" src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"live2d-widget-model-wanko"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.7},"log":false});</script></body></html>